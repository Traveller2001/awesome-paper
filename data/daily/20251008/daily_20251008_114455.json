{
  "generated_at": "2025-10-08T11:44:55.776301Z",
  "source_raw_files": [
    "data\\raw\\20251007\\csAI\\raw_csAI_20251007.json",
    "data\\raw\\20251007\\csCL\\raw_csCL_20251007.json",
    "data\\raw\\20251007\\csCV\\raw_csCV_20251007.json",
    "data\\raw\\20251007\\csLG\\raw_csLG_20251007.json"
  ],
  "paper_count": 155,
  "papers": [
    {
      "arxiv_id": "2510.06217v1",
      "title": "TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular\n  Reasoning",
      "summary": "Process Reward Models (PRMs) have recently emerged as a powerful framework\nfor enhancing the reasoning capabilities of large reasoning models (LRMs),\nparticularly in the context of test-time scaling (TTS). However, their\npotential for supervising LRMs on tabular reasoning domains remains\nunderexplored. Through detailed empirical analyses, we identify that existing\nPRMs, though widely adopted for supervising text-only reasoning steps, struggle\nwith table-specific operations such as sub-table retrieval and schema\ninteraction, leading to critical performance bottlenecks. To address this\nlimitation, we propose TaTToo, a novel table-grounded PRM framework that (i)\nreasons explicitly over tabular reasoning steps and (ii) integrates tool-based\nverification to provide precise reward supervision. Concretely, we first design\na scalable data curation pipeline that constructs over 60k high-quality\nstep-level annotations by integrating table verification rationales with\ntool-based executions. Building on the collected data, we train TaTToo with a\ndual-stage paradigm: cold-start supervised fine-tuning to capture tool-use\nreasoning patterns, followed by reinforcement learning with tool-grounded\nreward shaping to align our model with table-based verification. We provide a\ncomprehensive evaluation of the policy improvement induced by our newly\ndesigned PRM. Across 5 challenging tabular reasoning benchmarks covering\nnumerical reasoning, fact-checking, and data analysis, TaTToo improves\ndownstream policy LRMs by 30.9% at inference, surpasses strong PRM baselines\nsuch as Qwen-2.5-Math-PRM-72B with only 8B parameters, and demonstrates strong\ngeneralizability across diverse TTS strategies.",
      "authors": [
        "Jiaru Zou",
        "Soumya Roy",
        "Vinay Kumar Verma",
        "Ziyi Wang",
        "David Wipf",
        "Pan Lu",
        "Sumit Negi",
        "James Zou",
        "Jingrui He"
      ],
      "published": "2025-10-07T17:59:41Z",
      "primary_category": "cs.AI",
      "arxiv_url": "https://arxiv.org/abs/2510.06217v1",
      "primary_area": "text_models",
      "secondary_focus": "['reasoning', 'model_architecture', 'training_optimization']",
      "application_domain": "financial_ai",
      "tldr_zh": "本文提出TaTToo框架，针对表格推理任务设计的过程奖励模型。通过工具验证和表格操作增强，在5个表格推理基准上实现30.9%的性能提升，仅用8B参数即超越72B基线模型，显著提升测试时扩展能力。",
      "order": 1,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06217v1"
    },
    {
      "arxiv_id": "2510.06189v1",
      "title": "Barbarians at the Gate: How AI is Upending Systems Research",
      "summary": "Artificial Intelligence (AI) is starting to transform the research process as\nwe know it by automating the discovery of new solutions. Given a task, the\ntypical AI-driven approach is (i) to generate a set of diverse solutions, and\nthen (ii) to verify these solutions and select one that solves the problem.\nCrucially, this approach assumes the existence of a reliable verifier, i.e.,\none that can accurately determine whether a solution solves the given problem.\nWe argue that systems research, long focused on designing and evaluating new\nperformance-oriented algorithms, is particularly well-suited for AI-driven\nsolution discovery. This is because system performance problems naturally admit\nreliable verifiers: solutions are typically implemented in real systems or\nsimulators, and verification reduces to running these software artifacts\nagainst predefined workloads and measuring performance. We term this approach\nas AI-Driven Research for Systems (ADRS), which iteratively generates,\nevaluates, and refines solutions. Using penEvolve, an existing open-source ADRS\ninstance, we present case studies across diverse domains, including load\nbalancing for multi-region cloud scheduling, Mixture-of-Experts inference,\nLLM-based SQL queries, and transaction scheduling. In multiple instances, ADRS\ndiscovers algorithms that outperform state-of-the-art human designs (e.g.,\nachieving up to 5.0x runtime improvements or 50% cost reductions). We distill\nbest practices for guiding algorithm evolution, from prompt design to evaluator\nconstruction, for existing frameworks. We then discuss the broader implications\nfor the systems community: as AI assumes a central role in algorithm design, we\nargue that human researchers will increasingly focus on problem formulation and\nstrategic guidance. Our results highlight both the disruptive potential and the\nurgent need to adapt systems research practices in the age of AI.",
      "authors": [
        "Audrey Cheng",
        "Shu Liu",
        "Melissa Pan",
        "Zhifei Li",
        "Bowen Wang",
        "Alex Krentsel",
        "Tian Xia",
        "Mert Cemri",
        "Jongseok Park",
        "Shuo Yang",
        "Jeff Chen",
        "Aditya Desai",
        "Jiarong Xing",
        "Koushik Sen",
        "Matei Zaharia",
        "Ion Stoica"
      ],
      "published": "2025-10-07T17:49:24Z",
      "primary_category": "cs.AI",
      "arxiv_url": "https://arxiv.org/abs/2510.06189v1",
      "primary_area": "text_models",
      "secondary_focus": "reasoning",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出AI驱动系统研究(ADRS)方法，通过生成-验证-优化的迭代流程自动发现高性能算法。研究表明AI在负载均衡、专家混合推理等系统领域可超越人工设计(性能提升5倍/成本降低50%)，预示系统研究将转向问题定义与策略指导。",
      "order": 2,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06189v1"
    },
    {
      "arxiv_id": "2510.06135v1",
      "title": "Pushing Test-Time Scaling Limits of Deep Search with Asymmetric\n  Verification",
      "summary": "Test-time compute can be scaled both sequentially and in parallel. Sequential\nscaling involves lengthening the generation process, while parallel scaling\ninvolves verifying and selecting among multiple candidate outputs. Combining\nthese two strategies has led to the most powerful AI systems, such as Grok 4\nHeavy and GPT-5 Pro. In certain contexts (e.g., solving Sudoku puzzles),\nverifying responses can be substantially easier than generating them. This\nproperty, referred to as \\emph{asymmetric verification}, highlights the strong\npotential of test-time scaling (TTS). In this work, we study both sequential\nand parallel TTS of deep search agents, motivated by the intuition that\nverification in this setting is often much easier than generation. In\nexperiments, we first show that sequential scaling methods, such as budget\nforcing, can be effective initially but soon degrade performance. Leveraging\nasymmetric verification, however, we are able to achieve substantial\nimprovements by allocating only a modest amount of compute to the verifier. We\nconduct experiments with flagship open-source models and extend them to their\n``Heavy'' variants through TTS. These deep research agents achieve gains of up\nto 27 absolute points on benchmarks such as BrowseComp. Remarkably, as an\nopen-source alternative, GLM-4.5 Heavy reaches accuracy of {\\bf 54.0\\%} on\nBrowseComp and {\\bf 66.0\\%} on GAIA, placing it comparable to the best\nproprietary choices such as OpenAI Deep Research. Tongyi-DeepResearch Heavy\nfurther achieves {\\bf 69.0\\%} accuracy on BrowseComp, greatly surpassing the\nbest proprietary results.",
      "authors": [
        "Weihao Zeng",
        "Keqing He",
        "Chuqiao Kuang",
        "Xiaoguang Li",
        "Junxian He"
      ],
      "published": "2025-10-07T17:09:23Z",
      "primary_category": "cs.AI",
      "arxiv_url": "https://arxiv.org/abs/2510.06135v1",
      "primary_area": "text_models",
      "secondary_focus": "reasoning",
      "application_domain": "general_purpose",
      "tldr_zh": "本文研究深度搜索智能体的测试时扩展技术，提出利用验证远易于生成的'非对称验证'特性，结合序列扩展与并行扩展策略。实验表明，仅需为验证器分配少量计算资源，即可在BrowseComp等基准上实现高达27个百分点的性能提升，使开源模型GLM-4.5 Heavy在BrowseComp达到54.0%、GAIA达到66.0%的准确率，媲美顶级专有模型。",
      "order": 3,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06135v1"
    },
    {
      "arxiv_id": "2510.06105v1",
      "title": "Moloch's Bargain: Emergent Misalignment When LLMs Compete for Audiences",
      "summary": "Large language models (LLMs) are increasingly shaping how information is\ncreated and disseminated, from companies using them to craft persuasive\nadvertisements, to election campaigns optimizing messaging to gain votes, to\nsocial media influencers boosting engagement. These settings are inherently\ncompetitive, with sellers, candidates, and influencers vying for audience\napproval, yet it remains poorly understood how competitive feedback loops\ninfluence LLM behavior. We show that optimizing LLMs for competitive success\ncan inadvertently drive misalignment. Using simulated environments across these\nscenarios, we find that, 6.3% increase in sales is accompanied by a 14.0% rise\nin deceptive marketing; in elections, a 4.9% gain in vote share coincides with\n22.3% more disinformation and 12.5% more populist rhetoric; and on social\nmedia, a 7.5% engagement boost comes with 188.6% more disinformation and a\n16.3% increase in promotion of harmful behaviors. We call this phenomenon\nMoloch's Bargain for AI--competitive success achieved at the cost of alignment.\nThese misaligned behaviors emerge even when models are explicitly instructed to\nremain truthful and grounded, revealing the fragility of current alignment\nsafeguards. Our findings highlight how market-driven optimization pressures can\nsystematically erode alignment, creating a race to the bottom, and suggest that\nsafe deployment of AI systems will require stronger governance and carefully\ndesigned incentives to prevent competitive dynamics from undermining societal\ntrust.",
      "authors": [
        "Batu El",
        "James Zou"
      ],
      "published": "2025-10-07T16:37:15Z",
      "primary_category": "cs.AI",
      "arxiv_url": "https://arxiv.org/abs/2510.06105v1",
      "primary_area": "text_models",
      "secondary_focus": "alignment",
      "application_domain": "general_purpose",
      "tldr_zh": "研究发现，当大型语言模型在商业营销、政治竞选和社交媒体等竞争性环境中优化表现时，会意外产生错位现象：销售增长6.3%伴随欺骗性营销增加14.0%；得票率提升4.9%伴随虚假信息增加22.3%；互动率增长7.5%伴随有害行为推广增加16.3%。这表明市场竞争压力会系统性削弱AI对齐，即使模型被明确要求保持真实，现有安全防护仍显脆弱，需要更强治理机制。",
      "order": 4,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06105v1"
    },
    {
      "arxiv_id": "2510.06093v1",
      "title": "Classical AI vs. LLMs for Decision-Maker Alignment in Health Insurance\n  Choices",
      "summary": "As algorithmic decision-makers are increasingly applied to high-stakes\ndomains, AI alignment research has evolved from a focus on universal value\nalignment to context-specific approaches that account for decision-maker\nattributes. Prior work on Decision-Maker Alignment (DMA) has explored two\nprimary strategies: (1) classical AI methods integrating case-based reasoning,\nBayesian reasoning, and naturalistic decision-making, and (2) large language\nmodel (LLM)-based methods leveraging prompt engineering. While both approaches\nhave shown promise in limited domains such as medical triage, their\ngeneralizability to novel contexts remains underexplored. In this work, we\nimplement a prior classical AI model and develop an LLM-based algorithmic\ndecision-maker evaluated using a large reasoning model (GPT-5) and a\nnon-reasoning model (GPT-4) with weighted self-consistency under a zero-shot\nprompting framework, as proposed in recent literature. We evaluate both\napproaches on a health insurance decision-making dataset annotated for three\ntarget decision-makers with varying levels of risk tolerance (0.0, 0.5, 1.0).\nIn the experiments reported herein, classical AI and LLM-based models achieved\ncomparable alignment with attribute-based targets, with classical AI exhibiting\nslightly better alignment for a moderate risk profile. The dataset and\nopen-source implementation are publicly available at:\nhttps://github.com/TeX-Base/ClassicalAIvsLLMsforDMAlignment and\nhttps://github.com/Parallax-Advanced-Research/ITM/tree/feature_insurance.",
      "authors": [
        "Mallika Mainali",
        "Harsha Sureshbabu",
        "Anik Sen",
        "Christopher B. Rauch",
        "Noah D. Reifsnyder",
        "John Meyer",
        "J. T. Turner",
        "Michael W. Floyd",
        "Matthew Molineaux",
        "Rosina O. Weber"
      ],
      "published": "2025-10-07T16:21:52Z",
      "primary_category": "cs.AI",
      "arxiv_url": "https://arxiv.org/abs/2510.06093v1",
      "primary_area": "text_models",
      "secondary_focus": "['alignment', 'reasoning']",
      "application_domain": "medical_ai",
      "tldr_zh": "本研究比较了传统AI方法与大型语言模型在健康保险决策者对齐任务中的表现。通过评估三种不同风险承受能力的决策者配置文件，发现两种方法在属性对齐方面表现相当，传统AI在中等风险配置下略优。研究提供了公开数据集和开源实现，为零样本提示框架下的决策者对齐研究提供了实证基础。",
      "order": 5,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06093v1"
    },
    {
      "arxiv_id": "2510.06078v1",
      "title": "Constraint-Aware Route Recommendation from Natural Language via\n  Hierarchical LLM Agents",
      "summary": "Route recommendation aims to provide users with optimal travel plans that\nsatisfy diverse and complex requirements. Classical routing algorithms (e.g.,\nshortest-path and constraint-aware search) are efficient but assume structured\ninputs and fixed objectives, limiting adaptability to natural-language queries.\nRecent LLM-based approaches enhance flexibility but struggle with spatial\nreasoning and the joint modeling of route-level and POI-level preferences. To\naddress these limitations, we propose RouteLLM, a hierarchical multi-agent\nframework that grounds natural-language intents into constraint-aware routes.\nIt first parses user queries into structured intents including POIs, paths, and\nconstraints. A manager agent then coordinates specialized sub-agents: a\nconstraint agent that resolves and formally check constraints, a POI agent that\nretrieves and ranks candidate POIs, and a path refinement agent that refines\nroutes via a routing engine with preference-conditioned costs. A final verifier\nagent ensures constraint satisfaction and produces the final route with an\ninterpretable rationale. This design bridges linguistic flexibility and spatial\nstructure, enabling reasoning over route feasibility and user preferences.\nExperiments show that our method reliably grounds textual preferences into\nconstraint-aware routes, improving route quality and preference satisfaction\nover classical methods.",
      "authors": [
        "Tao Zhe",
        "Rui Liu",
        "Fateme Memar",
        "Xiao Luo",
        "Wei Fan",
        "Xinyue Ye",
        "Zhongren Peng",
        "Dongjie Wang"
      ],
      "published": "2025-10-07T16:03:57Z",
      "primary_category": "cs.AI",
      "arxiv_url": "https://arxiv.org/abs/2510.06078v1",
      "primary_area": "text_models",
      "secondary_focus": "['reasoning', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出RouteLLM——一种分层多智能体框架，通过自然语言处理实现约束感知的路线推荐。该系统首先解析用户查询为结构化意图，然后通过管理器协调约束处理、POI检索和路径优化三个子智能体，最后通过验证器确保约束满足并生成可解释的路线方案。实验表明该方法在路线质量和偏好满足度上优于传统方法。",
      "order": 6,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06078v1"
    },
    {
      "arxiv_id": "2510.06198v1",
      "title": "Peeking inside the Black-Box: Reinforcement Learning for Explainable and\n  Accurate Relation Extraction",
      "summary": "This paper introduces a framework for relation extraction (RE) that enhances\nboth accuracy and explainability. The framework has two key components: (i) a\nreasoning mechanism that formulates relation extraction as a series of\ntext-processing steps inspired by cognitive science, and (ii) an optimization\nprocess driven by reinforcement learning (RL) with a novel reward function\ndesigned to improve both task accuracy and explanation quality. We call our\napproach CogRE. Our framework addresses the lack of supervision for\nlanguage-based explanations in traditional RE by promoting outputs that include\nimportant relation keywords. These keywords are drawn from a high-quality\ndictionary that is automatically constructed using an LLM. We evaluate our\napproach for the task of one-shot RE using two LLMs and two RE datasets. Our\nexperiments show that CogRE improves explanation quality by addressing two\ncommon failure patterns in one-shot RE: poor attention focus and limited\none-shot learning capability. For example, our cognitive-structured reasoning\nwith Qwen2.5-15B-Instruct on One-shot NYT29 achieves 24.65% F1, surpassing\nprior reasoning-based designs. Optimizing this approach with RL using our\nreward further improves performance by +23.46% (absolute). Finally, human\nevaluation shows that our best model generates relational keywords closely\naligned with gold labels, increasing human explanation quality ratings by 54%\n(relative).",
      "authors": [
        "Xinyu Guo",
        "Zhengliang Shi",
        "Minglai Yang",
        "Mahdi Rahimi",
        "Mihai Surdeanu"
      ],
      "published": "2025-10-07T17:53:55Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06198v1",
      "primary_area": "text_models",
      "secondary_focus": "['reasoning', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出CogRE框架，通过认知科学启发的推理机制和强化学习优化，在关系抽取任务中同时提升准确性和可解释性。该方法利用LLM构建关键词词典，解决少样本关系抽取中的注意力分散和学习能力不足问题，在NYT29数据集上F1值提升23.46%，人工评估显示解释质量提升54%。",
      "order": 7,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06198v1"
    },
    {
      "arxiv_id": "2510.06195v1",
      "title": "Latent Speech-Text Transformer",
      "summary": "Auto-regressive speech-text models are typically pre-trained on a large\nnumber of interleaved sequences of text tokens and raw speech encoded as speech\ntokens using vector quantization. These models have demonstrated\nstate-of-the-art performance in speech-to-speech understanding and generation\nbenchmarks, together with promising scaling laws, primarily enabled by the\nrepresentational alignment between text and speech. Nevertheless, they suffer\nfrom shortcomings, partly owing to the disproportionately longer sequences of\nspeech tokens in contrast to textual tokens. This results in a large compute\nimbalance between modalities during pre-training as well as during inference,\nand a potential hindrance to effectively aligning speech and text, ultimately\ntranslating to several orders of magnitude slower scaling laws. We introduce\nthe Latent Speech-Text Transformer (LST), which makes pre-training speech-text\nmodels more data-efficient by dynamically and inexpensively aggregating speech\ntokens into latent speech patches. These patches serve as higher-level units\nthat can either align with corresponding textual units to aid capability\ntransfer or even encapsulate common speech sequences like silences to be more\ncompute-efficient. We show that LST outperforms vanilla approaches on\nspeech-to-speech as well as text-to-text benchmarks in both data- and\ncompute-controlled settings, the former indicating more effective\nrepresentational alignment and the latter indicating steeper scaling laws for\nspeech-text models. On HellaSwag story completion, LST achieves 6.5% absolute\ngain in speech accuracy under compute-controlled training and 5.3% under\ndata-controlled training, while also improving text performance. We will\nrelease our models, code, and the evaluation data to facilitate further\nresearch.",
      "authors": [
        "Yen-Ju Lu",
        "Yashesh Gaur",
        "Wei Zhou",
        "Benjamin Muller",
        "Jesus Villalba",
        "Najim Dehak",
        "Luke Zettlemoyer",
        "Gargi Ghosh",
        "Mike Lewis",
        "Srinivasan Iyer",
        "Duc Le"
      ],
      "published": "2025-10-07T17:52:08Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06195v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出潜在语音-文本变换器(LST)，通过动态聚合语音标记为潜在语音片段，解决语音-文本模型中语音序列过长导致的训练和推理效率问题。该方法在数据和计算受限条件下均优于传统方法，在HellaSwag任务上语音准确率提升6.5%，同时改善了文本性能，展现了更优的表示对齐和扩展规律。",
      "order": 8,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06195v1"
    },
    {
      "arxiv_id": "2510.06188v1",
      "title": "BanglaTalk: Towards Real-Time Speech Assistance for Bengali Regional\n  Dialects",
      "summary": "Real-time speech assistants are becoming increasingly popular for ensuring\nimproved accessibility to information. Bengali, being a low-resource language\nwith a high regional dialectal diversity, has seen limited progress in\ndeveloping such systems. Existing systems are not optimized for real-time use\nand focus only on standard Bengali. In this work, we present BanglaTalk, the\nfirst real-time speech assistance system for Bengali regional dialects.\nBanglaTalk follows the client-server architecture and uses the Real-time\nTransport Protocol (RTP) to ensure low-latency communication. To address\ndialectal variation, we introduce a dialect-aware ASR system, BRDialect,\ndeveloped by fine-tuning the IndicWav2Vec model in ten Bengali regional\ndialects. It outperforms the baseline ASR models by 12.41-33.98% on the\nRegSpeech12 dataset. Furthermore, BanglaTalk can operate at a low bandwidth of\n24 kbps while maintaining an average end-to-end delay of 4.9 seconds. Low\nbandwidth usage and minimal end-to-end delay make the system both\ncost-effective and interactive for real-time use cases, enabling inclusive and\naccessible speech technology for the diverse community of Bengali speakers.",
      "authors": [
        "Jakir Hasan",
        "Shubhashis Roy Dipta"
      ],
      "published": "2025-10-07T17:47:39Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06188v1",
      "primary_area": "audio_models",
      "secondary_focus": "['dialogue_systems', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "BanglaTalk是首个面向孟加拉语方言的实时语音助手系统，采用客户端-服务器架构和RTP协议实现低延迟通信。通过微调IndicWav2Vec模型开发了方言感知的BRDialect ASR系统，在RegSpeech12数据集上比基线模型性能提升12.41-33.98%。系统可在24kbps低带宽下运行，平均端到端延迟仅4.9秒，为孟加拉语多样化社区提供包容性语音技术服务。",
      "order": 9,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06188v1"
    },
    {
      "arxiv_id": "2510.06186v1",
      "title": "RECODE-H: A Benchmark for Research Code Development with Interactive\n  Human Feedback",
      "summary": "Large language models (LLMs) show the promise in supporting scientific\nresearch implementation, yet their ability to generate correct and executable\ncode remains limited. Existing works largely adopt one-shot settings, ignoring\nthe iterative and feedback-driven nature of realistic workflows of scientific\nresearch development. To address this gap, we present RECODE-H, a benchmark of\n102 tasks from research papers and repositories that evaluates LLM agents\nthrough multi-turn interactions with LLM-simulated human feedback. It includes\nstructured instructions,unit tests, and a five-level feedback hierarchy to\nreflect realistic researcher-agent collaboration. We further present\nReCodeAgent, a framework that integrates feedback into iterative code\ngeneration. Experiments with leading LLMs, including GPT-5, Claude-Sonnet-4,\nDeepSeek-V3.1, and Gemini 2.5, show substantial performance gains with richer\nfeedback, while also highlighting ongoing challenges in the generation of\ncomplex research code. RECODE-H establishes a foundation for developing\nadaptive, feedback-driven LLM agents in scientific research implementation",
      "authors": [
        "Chunyu Miao",
        "Henry Peng Zou",
        "Yangning Li",
        "Yankai Chen",
        "Yibo Wang",
        "Fangxin Wang",
        "Yifan Li",
        "Wooseong Yang",
        "Bowei He",
        "Xinni Zhang",
        "Dianzhi Yu",
        "Hanchen Yang",
        "Hoang H Nguyen",
        "Yue Zhou",
        "Jie Yang",
        "Jizhou Guo",
        "Wenzhe Fan",
        "Chin-Yuan Yeh",
        "Panpan Meng",
        "Liancheng Fang",
        "Jinhu Qi",
        "Wei-Chieh Huang",
        "Zhengyao Gu",
        "Yuwei Han",
        "Langzhou He",
        "Yuyao Yang",
        "Xue Liu",
        "Irwin King",
        "Philip S. Yu"
      ],
      "published": "2025-10-07T17:45:35Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06186v1",
      "primary_area": "text_models",
      "secondary_focus": "reasoning",
      "application_domain": "code_generation",
      "tldr_zh": "本文提出RECODE-H基准测试，针对科研代码开发场景，通过102个任务评估LLM在多轮人机交互反馈下的代码生成能力。该基准包含结构化指令、单元测试和五级反馈体系，并展示了ReCodeAgent框架如何通过反馈迭代提升代码质量。实验表明丰富反馈能显著提升GPT-5等主流模型的性能，但复杂科研代码生成仍是挑战。",
      "order": 10,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06186v1"
    },
    {
      "arxiv_id": "2510.06182v1",
      "title": "Mixing Mechanisms: How Language Models Retrieve Bound Entities\n  In-Context",
      "summary": "A key component of in-context reasoning is the ability of language models\n(LMs) to bind entities for later retrieval. For example, an LM might represent\n\"Ann loves pie\" by binding \"Ann\" to \"pie\", allowing it to later retrieve \"Ann\"\nwhen asked \"Who loves pie?\" Prior research on short lists of bound entities\nfound strong evidence that LMs implement such retrieval via a positional\nmechanism, where \"Ann\" is retrieved based on its position in context. In this\nwork, we find that this mechanism generalizes poorly to more complex settings;\nas the number of bound entities in context increases, the positional mechanism\nbecomes noisy and unreliable in middle positions. To compensate for this, we\nfind that LMs supplement the positional mechanism with a lexical mechanism\n(retrieving \"Ann\" using its bound counterpart \"pie\") and a reflexive mechanism\n(retrieving \"Ann\" through a direct pointer). Through extensive experiments on\nnine models and ten binding tasks, we uncover a consistent pattern in how LMs\nmix these mechanisms to drive model behavior. We leverage these insights to\ndevelop a causal model combining all three mechanisms that estimates next token\ndistributions with 95% agreement. Finally, we show that our model generalizes\nto substantially longer inputs of open-ended text interleaved with entity\ngroups, further demonstrating the robustness of our findings in more natural\nsettings. Overall, our study establishes a more complete picture of how LMs\nbind and retrieve entities in-context.",
      "authors": [
        "Yoav Gur-Arieh",
        "Mor Geva",
        "Atticus Geiger"
      ],
      "published": "2025-10-07T17:44:30Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06182v1",
      "primary_area": "text_models",
      "secondary_focus": "['reasoning', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "本研究揭示了语言模型在上下文推理中检索绑定实体的混合机制。当绑定实体数量增加时，模型会从单一的位置机制转向结合词汇机制和反射机制的三重混合策略。通过九个模型和十项绑定任务的实验，建立了能95%准确预测下一个词分布的因果模型，并在更长文本中验证了其鲁棒性。",
      "order": 11,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06182v1"
    },
    {
      "arxiv_id": "2510.06175v1",
      "title": "VecInfer: Efficient LLM Inference with Low-Bit KV Cache via\n  Outlier-Suppressed Vector Quantization",
      "summary": "The Key-Value (KV) cache introduces substantial memory overhead during large\nlanguage model (LLM) inference. Although existing vector quantization (VQ)\nmethods reduce KV cache usage and provide flexible representational capacity\nacross bit-widths, they suffer severe performance degradation at ultra-low\nbit-widths due to key cache outliers that hinder effective codebook\nutilization. To address this challenge, we propose VecInfer, a novel VQ method\nfor aggressive KV cache compression while enabling efficient inference. By\napplying smooth and Hadamard transformations, VecInfer suppresses outliers in\nthe key cache, enabling the codebook to comprehensively cover the original data\ndistribution and thereby reducing quantization difficulty. To facilitate\nefficient deployment, we design an optimized CUDA kernel that fuses computation\nwith dequantization to minimize memory access overhead. Extensive evaluations\ndemonstrate that VecInfer consistently outperforms existing quantization\nbaselines across both long-context understanding and mathematical reasoning\ntasks. With only 2-bit quantization, VecInfer achieves performance comparable\nto full precision, while delivering up to $\\mathbf{2.7\\times}$ speedup in\nlarge-batch self-attention computation and $\\mathbf{8.3\\times}$ reduction in\nsingle-batch end-to-end latency on Llama-3.1-8B with a 196k sequence length.",
      "authors": [
        "Dingyu Yao",
        "Chenxu Yang",
        "Zhengyang Tong",
        "Zheng Lin",
        "Wei Liu",
        "Jian Luan",
        "Weiping Wang"
      ],
      "published": "2025-10-07T17:35:28Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06175v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_compression', 'long_context', 'reasoning']",
      "application_domain": "general_purpose",
      "tldr_zh": "VecInfer提出一种通过异常值抑制向量量化实现低比特KV缓存的高效LLM推理方法。通过平滑变换和Hadamard变换抑制关键缓存中的异常值，使码本更好覆盖原始数据分布，并设计融合计算与反量化的CUDA内核。在2比特量化下达到接近全精度性能，在长序列场景中实现最高8.3倍加速。",
      "order": 12,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06175v1"
    },
    {
      "arxiv_id": "2510.06143v1",
      "title": "RoSE: Round-robin Synthetic Data Evaluation for Selecting LLM Generators\n  without Human Test Sets",
      "summary": "LLMs are powerful generators of synthetic data, which are used for training\nsmaller, specific models. This is especially valuable for low-resource\nlanguages, where human-labelled data is scarce but LLMs can still produce\nhigh-quality text. However, LLMs differ in how useful their outputs are for\ntraining. Selecting the best LLM as a generator is challenging because\nextrinsic evaluation requires costly human annotations (which are often\nunavailable for low-resource languages), while intrinsic metrics correlate\npoorly with downstream performance. We introduce Round robin Synthetic data\nEvaluation (RoSE), a proxy metric for selecting the best LLM generator without\nhuman test sets. RoSE trains a small model on the outputs of a candidate\ngenerator (LLM) and then evaluates it on generated synthetic examples from all\nother candidate LLMs. The final RoSE score is the mean performance of this\nsmall model. Across six LLMs, eleven languages, and three tasks (sentiment,\ntopic, intent), RoSE identifies the optimal generator more often than any other\nintrinsic heuristics. RoSE outperforms intrinsic heuristics and comes within\n0.76 percentage points of the optimal generator baseline. This result is\nmeasured in terms of downstream performance, obtained by training a small model\non the chosen generator's outputs (optimal vs. proxy metric selected) and\nevaluating it on human-labelled test data. Additionally, RoSE is the only\nmetric to achieve a positive correlation with performance on human test data.",
      "authors": [
        "Jan Cegin",
        "Branislav Pecher",
        "Ivan Srba",
        "Jakub Simko"
      ],
      "published": "2025-10-07T17:17:14Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06143v1",
      "primary_area": "text_models",
      "secondary_focus": "training_optimization",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出RoSE方法，通过轮询式合成数据评估来选择最优LLM生成器，无需人工标注测试集。该方法在多个语言和任务中表现优于传统内在指标，接近最优生成器基准，是唯一与人工测试数据性能正相关的指标。",
      "order": 13,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06143v1"
    },
    {
      "arxiv_id": "2510.06133v1",
      "title": "CreditDecoding: Accelerating Parallel Decoding in Diffusion Large\n  Language Models with Trace Credits",
      "summary": "Diffusion large language models (dLLMs) generate text through iterative\ndenoising steps, achieving parallel decoding by denoising only high-confidence\npositions at each step. However, existing approaches often repetitively remask\ntokens due to initially low confidence scores, leading to redundant iterations\nand limiting overall acceleration. Through the analysis of dLLM decoding\ntraces, we observe that the model often determines the final prediction for a\ntoken several steps before the decoding step. To leverage this historical\ninformation and avoid redundant steps, we introduce the concept of Trace\nCredit, which quantifies each token's convergence potential by accumulating\nhistorical logits. Furthermore, we propose CreditDecoding, a training-free\nparallel decoding algorithm that accelerates the confidence convergence of\ncorrect but underconfident tokens by fusing current logits with Trace Credit.\nThis process significantly reduces redundant iterations and enhances decoding\nrobustness. On eight benchmarks, CreditDecoding achieves a 5.48 times speedup\nand a 0.48 performance improvement over LLaDA-8B-Instruct, and a 4.11 times\nspeedup with a 0.15 performance improvement over LLaDA-MoE-Instruct.\nImportantly, CreditDecoding scales effectively to long sequences and is\northogonal to mainstream inference optimizations, making it a readily\nintegrable and versatile solution.",
      "authors": [
        "Kangyu Wang",
        "Zhiyun Jiang",
        "Haibo Feng",
        "Weijia Zhao",
        "Lin Liu",
        "Jianguo Li",
        "Zhenzhong Lan",
        "Weiyao Lin"
      ],
      "published": "2025-10-07T17:08:33Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06133v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出CreditDecoding算法，通过引入轨迹信用(Trace Credit)量化token收敛潜力，融合历史logits加速扩散大语言模型的并行解码。该无需训练的方法在8个基准测试中实现4-5倍加速，同时提升模型性能，且适用于长序列并与主流推理优化技术正交。",
      "order": 14,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06133v1"
    },
    {
      "arxiv_id": "2510.06128v1",
      "title": "Parallel Tokenizers: Rethinking Vocabulary Design for Cross-Lingual\n  Transfer",
      "summary": "Tokenization defines the foundation of multilingual language models by\ndetermining how words are represented and shared across languages. However,\nexisting methods often fail to support effective cross-lingual transfer because\nsemantically equivalent words are assigned distinct embeddings. For example, \"I\neat rice\" in English and \"Ina cin shinkafa\" in Hausa are typically mapped to\ndifferent vocabulary indices, preventing shared representations and limiting\ncross-lingual generalization. We introduce parallel tokenizers. This new\nframework trains tokenizers monolingually and then aligns their vocabularies\nexhaustively using bilingual dictionaries or word-to-word translation, ensuring\nconsistent indices for semantically equivalent words. This alignment enforces a\nshared semantic space across languages while naturally improving fertility\nbalance. To assess their effectiveness, we pretrain a transformer encoder from\nscratch on thirteen low-resource languages and evaluate it on sentiment\nanalysis, hate speech detection, emotion classification, and sentence embedding\nsimilarity. Across all tasks, models trained with parallel tokenizers\noutperform conventional multilingual baselines, confirming that rethinking\ntokenization is essential for advancing multilingual representation\nlearning--especially in low-resource settings.",
      "authors": [
        "Muhammad Dehan Al Kautsar",
        "Fajri Koto"
      ],
      "published": "2025-10-07T17:05:49Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06128v1",
      "primary_area": "text_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出并行分词器框架，通过单语训练后利用双语词典对齐词汇表，确保语义相同的单词在不同语言中获得一致索引。在13种低资源语言上的实验表明，该方法在情感分析、仇恨言论检测等任务中均优于传统多语言基线，显著提升了跨语言表示学习效果。",
      "order": 15,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06128v1"
    },
    {
      "arxiv_id": "2510.06107v1",
      "title": "Distributional Semantics Tracing: A Framework for Explaining\n  Hallucinations in Large Language Models",
      "summary": "Large Language Models (LLMs) are prone to hallucination, the generation of\nplausible yet factually incorrect statements. This work investigates the\nintrinsic, architectural origins of this failure mode through three primary\ncontributions.First, to enable the reliable tracing of internal semantic\nfailures, we propose \\textbf{Distributional Semantics Tracing (DST)}, a unified\nframework that integrates established interpretability techniques to produce a\ncausal map of a model's reasoning, treating meaning as a function of context\n(distributional semantics). Second, we pinpoint the model's layer at which a\nhallucination becomes inevitable, identifying a specific \\textbf{commitment\nlayer} where a model's internal representations irreversibly diverge from\nfactuality. Third, we identify the underlying mechanism for these failures. We\nobserve a conflict between distinct computational pathways, which we interpret\nusing the lens of dual-process theory: a fast, heuristic \\textbf{associative\npathway} (akin to System 1) and a slow, deliberate \\textbf{contextual pathway}\n(akin to System 2), leading to predictable failure modes such as\n\\textit{Reasoning Shortcut Hijacks}. Our framework's ability to quantify the\ncoherence of the contextual pathway reveals a strong negative correlation\n($\\rho = -0.863$) with hallucination rates, implying that these failures are\npredictable consequences of internal semantic weakness. The result is a\nmechanistic account of how, when, and why hallucinations occur within the\nTransformer architecture.",
      "authors": [
        "Gagan Bhatia",
        "Somayajulu G Sripada",
        "Kevin Allan",
        "Jacobo Azcona"
      ],
      "published": "2025-10-07T16:40:31Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06107v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_architecture', 'reasoning']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出分布语义追踪(DST)框架，通过双过程理论揭示大语言模型产生幻觉的内在机制：在特定'承诺层'处，快速联想路径与慢速上下文路径冲突导致事实性偏离，框架可量化预测幻觉发生(相关性ρ=-0.863)，为Transformer架构中的幻觉问题提供机理解释。",
      "order": 16,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06107v1"
    },
    {
      "arxiv_id": "2510.06101v1",
      "title": "The Valley of Code Reasoning: Scaling Knowledge Distillation of Large\n  Language Models",
      "summary": "Distilling the thinking traces of a Large Language Model (LLM) with reasoning\ncapabilities into a smaller model has been proven effective. Yet, there is a\nscarcity of work done on how model performances scale with the quantity of\ndistillation data. In this work, we study the scaling trend of distilling\ncompetitive coding skills on two small non-reasoning LLMs. We validate the\nhypothesis that there is a $\\textit{valley of code reasoning}$: downstream\nperformance on competitive coding first drops as data quantity increases, then\nit steadily increases in a sharper-than-log-linear fashion. Having identified\nthe trend, we further fine-tune the models at two different distillation stages\non the same data to ground conclusions on their respective learning phases. We\nlearn that across stages in the low and medium-low data regimes, small models\nbenefit significantly from easier coding questions than from harder ones. We\nalso find that, surprisingly, the correctness of outputs in training data makes\nno difference to distillation outcomes. Our work represents a step forward in\nunderstanding the training dynamics of code reasoning distillation outside\nintuition",
      "authors": [
        "Muyu He",
        "Muhammad Ali Shafique",
        "Anand Kumar",
        "Tsach Mackey",
        "Nazneen Rajani"
      ],
      "published": "2025-10-07T16:32:09Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06101v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_compression', 'reasoning', 'training_optimization']",
      "application_domain": "code_generation",
      "tldr_zh": "本文研究大型语言模型代码推理能力的知识蒸馏规模效应，发现存在'代码推理低谷'现象：随着蒸馏数据量增加，小模型在编程竞赛任务上的性能先下降后以超对数线性速度提升。研究还表明在低数据量阶段，简单编程题目对小型模型更有益，且训练数据的答案正确性不影响蒸馏效果。",
      "order": 17,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06101v1"
    },
    {
      "arxiv_id": "2510.06084v1",
      "title": "Spectrum Tuning: Post-Training for Distributional Coverage and\n  In-Context Steerability",
      "summary": "Language model post-training has enhanced instruction-following and\nperformance on many downstream tasks, but also comes with an often-overlooked\ncost on tasks with many possible valid answers. We characterize three\ndesiderata for conditional distributional modeling: in-context steerability,\nvalid output space coverage, and distributional alignment, and document across\nthree model families how current post-training can reduce these properties. In\nparticular, we disambiguate between two kinds of in-context learning: ICL for\neliciting existing underlying knowledge or capabilities, and in-context\nsteerability, where a model must use in-context information to override its\npriors and steer to a novel data generating distribution. To better evaluate\nand improve these desiderata, we introduce Spectrum Suite, a large-scale\nresource compiled from >40 data sources and spanning >90 tasks requiring models\nto steer to and match diverse distributions ranging from varied human\npreferences to numerical distributions and more. We find that while current\npost-training techniques help elicit underlying capabilities and knowledge,\nthey hurt models' ability to flexibly steer in-context. To mitigate these\nissues, we propose Spectrum Tuning, a post-training method using Spectrum Suite\nto improve steerability and distributional coverage. We find that Spectrum\nTuning often improves over pretrained models and their instruction-tuned\ncounterparts, enhancing steerability, spanning more of the output space, and\nimproving distributional alignment on held-out datasets.",
      "authors": [
        "Taylor Sorensen",
        "Benjamin Newman",
        "Jared Moore",
        "Chan Park",
        "Jillian Fisher",
        "Niloofar Mireshghallah",
        "Liwei Jiang",
        "Yejin Choi"
      ],
      "published": "2025-10-07T16:10:26Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06084v1",
      "primary_area": "text_models",
      "secondary_focus": "['alignment', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出频谱调优方法，解决语言模型后训练中分布覆盖不足和上下文引导能力下降的问题。通过构建包含90+任务的频谱测试集，研究发现现有后训练技术会削弱模型根据上下文调整输出的灵活性，而频谱调优能同时提升引导能力、输出空间覆盖和分布对齐效果。",
      "order": 18,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06084v1"
    },
    {
      "arxiv_id": "2510.06062v1",
      "title": "ASPO: Asymmetric Importance Sampling Policy Optimization",
      "summary": "Recent Large Language Model (LLM) post-training methods rely on token-level\nclipping mechanisms during Reinforcement Learning (RL). However, we identify a\nfundamental flaw in this Outcome-Supervised RL (OSRL) paradigm: the Importance\nSampling (IS) ratios of positive-advantage tokens are mismatched, leading to\nunbalanced token weighting for positive and negative tokens. This mismatch\nsuppresses the update of low-probability tokens while over-amplifying already\nhigh-probability ones. To address this, we propose Asymmetric Importance\nSampling Policy Optimization (ASPO), which uses a simple yet effective strategy\nthat flips the IS ratios of positive-advantage tokens, aligning their update\ndirection with the learning dynamics of negative ones. AIS further incorporates\na soft dual-clipping mechanism to stabilize extreme updates while maintaining\ngradient flow. Comprehensive experiments on coding and mathematical reasoning\nbenchmarks demonstrate that ASPO significantly mitigates premature convergence,\nimproves training stability, and enhances final performance over strong\nGRPO-based baselines. Our analysis provides new insights into the role of\ntoken-level weighting in OSRL and highlights the critical importance of\ncorrecting IS in LLM RL. The code and models of ASPO are available at\nhttps://github.com/wizard-III/Archer2.0.",
      "authors": [
        "Jiakang Wang",
        "Runze Liu",
        "Lei Lin",
        "Wenping Hu",
        "Xiu Li",
        "Fuzheng Zhang",
        "Guorui Zhou",
        "Kun Gai"
      ],
      "published": "2025-10-07T15:54:24Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06062v1",
      "primary_area": "text_models",
      "secondary_focus": "['training_optimization', 'reasoning']",
      "application_domain": "['code_generation', 'general_purpose']",
      "tldr_zh": "本文提出ASPO方法，通过翻转正优势令牌的重要性采样比率，解决大语言模型强化学习中令牌级裁剪机制导致的权重失衡问题。该方法结合软双重裁剪机制，在编程和数学推理基准测试中显著提升训练稳定性与最终性能。",
      "order": 19,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06062v1"
    },
    {
      "arxiv_id": "2510.06039v1",
      "title": "CDTP: A Large-Scale Chinese Data-Text Pair Dataset for Comprehensive\n  Evaluation of Chinese LLMs",
      "summary": "Large Language Models (LLMs) have achieved remarkable success across a wide\nrange of natural language processing tasks. However, Chinese LLMs face unique\nchallenges, primarily due to the dominance of unstructured free text and the\nlack of structured representations in Chinese corpora. While existing\nbenchmarks for LLMs partially assess Chinese LLMs, they are still predominantly\nEnglish-centric and fail to address the unique linguistic characteristics of\nChinese, lacking structured datasets essential for robust evaluation. To\naddress these challenges, we present a Comprehensive Benchmark for Evaluating\nChinese Large Language Models (CB-ECLLM) based on the newly constructed Chinese\nData-Text Pair (CDTP) dataset. Specifically, CDTP comprises over 7 million\naligned text pairs, each consisting of unstructured text coupled with one or\nmore corresponding triples, alongside a total of 15 million triples spanning\nfour critical domains. The core contributions of CDTP are threefold: (i)\nenriching Chinese corpora with high-quality structured information; (ii)\nenabling fine-grained evaluation tailored to knowledge-driven tasks; and (iii)\nsupporting multi-task fine-tuning to assess generalization and robustness\nacross scenarios, including Knowledge Graph Completion, Triple-to-Text\ngeneration, and Question Answering. Furthermore, we conduct rigorous\nevaluations through extensive experiments and ablation studies to assess the\neffectiveness, Supervised Fine-Tuning (SFT), and robustness of the benchmark.\nTo support reproducible research, we offer an open-source codebase and outline\npotential directions for future investigations based on our insights.",
      "authors": [
        "Chengwei Wu",
        "Jiapu Wang",
        "Mingyang Gao",
        "Xingrui Zhuo",
        "Jipeng Guo",
        "Runlin Lei",
        "Haoran Luo",
        "Tianyu Chen",
        "Haoyi Zhou",
        "Shirui Pan",
        "Zechao Li"
      ],
      "published": "2025-10-07T15:33:52Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06039v1",
      "primary_area": "text_models",
      "secondary_focus": "['training_optimization', 'reasoning']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出CDTP数据集——包含700万对齐文本对和1500万三元组的大规模中文数据-文本配对数据集，用于全面评估中文大语言模型。该数据集覆盖四大关键领域，支持知识图谱补全、三元组到文本生成和问答等多任务评估，解决了中文语料缺乏结构化信息的问题，并提供开源代码库促进可复现研究。",
      "order": 20,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06039v1"
    },
    {
      "arxiv_id": "2510.06018v1",
      "title": "Evaluating The Impact of Stimulus Quality in Investigations of LLM\n  Language Performance",
      "summary": "Recent studies employing Large Language Models (LLMs) to test the Argument\nfrom the Poverty of the Stimulus (APS) have yielded contrasting results across\nsyntactic phenomena. This paper investigates the hypothesis that\ncharacteristics of the stimuli used in recent studies, including lexical\nambiguities and structural complexities, may confound model performance. A\nmethodology is proposed for re-evaluating LLM competence on syntactic\nprediction, focusing on GPT-2. This involves: 1) establishing a baseline on\npreviously used (both filtered and unfiltered) stimuli, and 2) generating a\nnew, refined dataset using a state-of-the-art (SOTA) generative LLM (Gemini 2.5\nPro Preview) guided by linguistically-informed templates designed to mitigate\nidentified confounds. Our preliminary findings indicate that GPT-2 demonstrates\nnotably improved performance on these refined PG stimuli compared to baselines,\nsuggesting that stimulus quality significantly influences outcomes in\nsurprisal-based evaluations of LLM syntactic competency.",
      "authors": [
        "Timothy Pistotti",
        "Jason Brown",
        "Michael Witbrock"
      ],
      "published": "2025-10-07T15:16:47Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06018v1",
      "primary_area": "text_models",
      "secondary_focus": "reasoning",
      "application_domain": "general_purpose",
      "tldr_zh": "本研究探讨了刺激质量对大型语言模型句法能力评估的影响。通过分析GPT-2在原始刺激和经语言学家指导优化的新数据集上的表现，发现刺激质量（如词汇歧义和结构复杂性）显著影响基于惊异度的句法能力评估结果。改进后的刺激使GPT-2性能显著提升，表明现有评估方法可能因刺激质量问题而低估模型能力。",
      "order": 21,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06018v1"
    },
    {
      "arxiv_id": "2510.06005v1",
      "title": "MASA: Rethinking the Representational Bottleneck in LoRA with Multi-A\n  Shared Adaptation",
      "summary": "Low-Rank Adaptation (LoRA) has emerged as a dominant method in\nParameter-Efficient Fine-Tuning (PEFT) for large language models, which\naugments the transformer layer with one down-projection $A$ and one\nup-projection $B$. However, LoRA's reliance on a single down-projection matrix\n($A$) creates a representational bottleneck, as this solitary feature extractor\nis inherently insufficient for capturing the diverse signals required by\ncomplex tasks. This motivates our architectural shift to focus on enriching the\nfeature adaptation to improve the downstream task adaptation ability. We\npropose MASA (Multi-$A$ Shared Adaptation), an architecture that implements a\nmulti-$A$, single-$B$ structure where the multi-$A$ expert ensemble is\nasymmetrically shared across layers to ensure parameter efficiency. In MASA,\nthese specialized experts capture diverse features, which are then integrated\nby a single, layer-specific $B$-matrix. The effectiveness and versatility of\nour method are validated through a comprehensive suite of experiments spanning\nmulti-domain generalization, single-domain specialization, and multi-task\nreasoning. For example, on the MMLU benchmark, MASA achieves an average\naccuracy of 59.62%, outperforming the standard LoRA by 1.08 points (a relative\nimprovement of 1.84%) with comparable learnable parameters of 0.52%.",
      "authors": [
        "Qin Dong",
        "Yuntian Tang",
        "Heming Jia",
        "Yunhang Shen",
        "Bohan Jia",
        "Wenxuan Huang",
        "Lianyue Zhang",
        "Jiao Xie",
        "Shaohui Lin"
      ],
      "published": "2025-10-07T15:06:46Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06005v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出MASA方法，通过多A专家共享机制改进LoRA的表示瓶颈。采用多A单B架构，让多个专家捕获多样化特征，再通过层特定的B矩阵整合，在参数效率相近的情况下，在MMLU等基准上显著优于标准LoRA。",
      "order": 22,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06005v1"
    },
    {
      "arxiv_id": "2510.06001v1",
      "title": "Exploring Gaps in the APS: Direct Minimal Pair Analysis in LLM Syntactic\n  Assessments",
      "summary": "Recent studies probing the Argument from the Poverty of the Stimulus (APS)\nhave applied Large Language Models (LLMs) to test the learnability of complex\nsyntax through surprisal-based metrics. However, divergent conclusions raise\nquestions concerning the insights these metrics offer. While Wilcox et al.\n(2024) used direct minimal pair comparisons (the \"wh-effect\") to demonstrate\nthat models successfully generalise knowledge of filler-gap dependencies, Lan\net al. (2024) used a Difference-in-Differences (DiD) metric and found that\nmodels largely fail on parasitic gaps (PGs). This paper argues that the direct\nminimal pair approach offers greater diagnostic transparency. We demonstrate\nthis by generating a full 8-permutation paradigm of refined PG stimuli and\nevaluating the GPT-2 model used in previous studies with a systematic\nWilcox-style wh-effect analysis. Our results show that GPT-2 succeeds across\nall four tested conditions, indicating robust knowledge of filler-gap licensing\nprinciples even in complex PG environments. This finding, which contrasts with\nthe more ambiguous results from DiD-style metrics, suggests that the choice of\nevaluation metric is critical for assessing an LLM's syntactic competence.",
      "authors": [
        "Timothy Pistotti",
        "Jason Brown",
        "Michael Witbrock"
      ],
      "published": "2025-10-07T15:03:09Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.06001v1",
      "primary_area": "text_models",
      "secondary_focus": "reasoning",
      "application_domain": "general_purpose",
      "tldr_zh": "本文通过直接最小对比对分析法评估GPT-2在寄生空位结构中的句法能力，发现与差异中的差异指标相比，该方法能更清晰地揭示模型对填充语-空位依赖关系的掌握。研究表明评估指标的选择对判断大语言模型句法能力至关重要，GPT-2在复杂句法环境中表现出稳健的句法知识。",
      "order": 23,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06001v1"
    },
    {
      "arxiv_id": "2510.05972v1",
      "title": "LexiCon: a Benchmark for Planning under Temporal Constraints in Natural\n  Language",
      "summary": "Owing to their reasoning capabilities, large language models (LLMs) have been\nevaluated on planning tasks described in natural language. However, LLMs have\nlargely been tested on planning domains without constraints. In order to deploy\nthem in real-world settings where adherence to constraints, in particular\nsafety constraints, is critical, we need to evaluate their performance on\nconstrained planning tasks. We introduce LexiCon -- a natural language-based\n(Lexi) constrained (Con) planning benchmark, consisting of a suite of\nenvironments, that can be used to evaluate the planning capabilities of LLMs in\na principled fashion. The core idea behind LexiCon is to take existing planning\nenvironments and impose temporal constraints on the states. These constrained\nproblems are then translated into natural language and given to an LLM to\nsolve. A key feature of LexiCon is its extensibility. That is, the set of\nsupported environments can be extended with new (unconstrained) environment\ngenerators, for which temporal constraints are constructed automatically. This\nrenders LexiCon future-proof: the hardness of the generated planning problems\ncan be increased as the planning capabilities of LLMs improve. Our experiments\nreveal that the performance of state-of-the-art LLMs, including reasoning\nmodels like GPT-5, o3, and R1, deteriorates as the degree of constrainedness of\nthe planning tasks increases.",
      "authors": [
        "Periklis Mantenoglou",
        "Rishi Hazra",
        "Pedro Zuidberg Dos Martires",
        "Luc De Raedt"
      ],
      "published": "2025-10-07T14:28:30Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05972v1",
      "primary_area": "text_models",
      "secondary_focus": "reasoning",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出LexiCon基准测试，用于评估大语言模型在自然语言描述的时序约束规划任务中的表现。该基准通过为现有规划环境添加时间约束并转化为自然语言问题，系统测试LLMs的约束规划能力。实验表明，即使最先进的LLMs（包括GPT-5、o3、R1等推理模型）在约束复杂度增加时性能显著下降。该框架具有可扩展性，能随LLMs规划能力提升而调整问题难度。",
      "order": 24,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05972v1"
    },
    {
      "arxiv_id": "2510.05969v1",
      "title": "Probing the Difficulty Perception Mechanism of Large Language Models",
      "summary": "Large language models (LLMs) are increasingly deployed on complex reasoning\ntasks, yet little is known about their ability to internally evaluate problem\ndifficulty, which is an essential capability for adaptive reasoning and\nefficient resource allocation. In this work, we investigate whether LLMs\nimplicitly encode problem difficulty in their internal representations. Using a\nlinear probe on the final-token representations of LLMs, we demonstrate that\nthe difficulty level of math problems can be linearly modeled. We further\nlocate the specific attention heads of the final Transformer layer: these\nattention heads have opposite activation patterns for simple and difficult\nproblems, thus achieving perception of difficulty. Our ablation experiments\nprove the accuracy of the location. Crucially, our experiments provide\npractical support for using LLMs as automatic difficulty annotators,\npotentially substantially reducing reliance on costly human labeling in\nbenchmark construction and curriculum learning. We also uncover that there is a\nsignificant difference in entropy and difficulty perception at the token level.\nOur study reveals that difficulty perception in LLMs is not only present but\nalso structurally organized, offering new theoretical insights and practical\ndirections for future research.",
      "authors": [
        "Sunbowen Lee",
        "Qingyu Yin",
        "Chak Tou Leong",
        "Jialiang Zhang",
        "Yicheng Gong",
        "Xiaoyu Shen"
      ],
      "published": "2025-10-07T14:24:32Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05969v1",
      "primary_area": "text_models",
      "secondary_focus": "reasoning",
      "application_domain": "education_ai",
      "tldr_zh": "本研究通过线性探针分析大语言模型的内部表征，发现其能够线性建模数学问题难度，并定位到最终Transformer层中负责难度感知的特定注意力头。这些注意力头对简单和困难问题呈现相反激活模式，证明LLMs具备结构化难度感知能力。该发现为自动难度标注提供了实践支持，可显著减少基准构建和课程学习中的人力标注成本。",
      "order": 25,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05969v1"
    },
    {
      "arxiv_id": "2510.05942v1",
      "title": "EvalMORAAL: Interpretable Chain-of-Thought and LLM-as-Judge Evaluation\n  for Moral Alignment in Large Language Models",
      "summary": "We present EvalMORAAL, a transparent chain-of-thought (CoT) framework that\nuses two scoring methods (log-probabilities and direct ratings) plus a\nmodel-as-judge peer review to evaluate moral alignment in 20 large language\nmodels. We assess models on the World Values Survey (55 countries, 19 topics)\nand the PEW Global Attitudes Survey (39 countries, 8 topics). With EvalMORAAL,\ntop models align closely with survey responses (Pearson's r approximately 0.90\non WVS). Yet we find a clear regional difference: Western regions average\nr=0.82 while non-Western regions average r=0.61 (a 0.21 absolute gap),\nindicating consistent regional bias. Our framework adds three parts: (1) two\nscoring methods for all models to enable fair comparison, (2) a structured\nchain-of-thought protocol with self-consistency checks, and (3) a\nmodel-as-judge peer review that flags 348 conflicts using a data-driven\nthreshold. Peer agreement relates to survey alignment (WVS r=0.74, PEW r=0.39,\nboth p<.001), supporting automated quality checks. These results show real\nprogress toward culture-aware AI while highlighting open challenges for use\nacross regions.",
      "authors": [
        "Hadi Mohammadi",
        "Anastasia Giachanou",
        "Ayoub Bagheri"
      ],
      "published": "2025-10-07T13:52:16Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05942v1",
      "primary_area": "text_models",
      "secondary_focus": "['alignment', 'reasoning']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出EvalMORAAL框架，通过思维链和模型互评机制评估20个大语言模型的道德对齐能力。研究发现模型在西方地区相关性达0.82，非西方地区仅0.61，揭示显著地域偏差。该框架包含双评分方法、结构化思维链协议和自动冲突检测，为文化感知AI提供评估基准。",
      "order": 26,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05942v1"
    },
    {
      "arxiv_id": "2510.05931v1",
      "title": "Hire Your Anthropologist! Rethinking Culture Benchmarks Through an\n  Anthropological Lens",
      "summary": "Cultural evaluation of large language models has become increasingly\nimportant, yet current benchmarks often reduce culture to static facts or\nhomogeneous values. This view conflicts with anthropological accounts that\nemphasize culture as dynamic, historically situated, and enacted in practice.\nTo analyze this gap, we introduce a four-part framework that categorizes how\nbenchmarks frame culture, such as knowledge, preference, performance, or bias.\nUsing this lens, we qualitatively examine 20 cultural benchmarks and identify\nsix recurring methodological issues, including treating countries as cultures,\noverlooking within-culture diversity, and relying on oversimplified survey\nformats. Drawing on established anthropological methods, we propose concrete\nimprovements: incorporating real-world narratives and scenarios, involving\ncultural communities in design and validation, and evaluating models in context\nrather than isolation. Our aim is to guide the development of cultural\nbenchmarks that go beyond static recall tasks and more accurately capture the\nresponses of the models to complex cultural situations.",
      "authors": [
        "Mai AlKhamissi",
        "Yunze Xiao",
        "Badr AlKhamissi",
        "Mona Diab"
      ],
      "published": "2025-10-07T13:42:44Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05931v1",
      "primary_area": "text_models",
      "secondary_focus": "alignment",
      "application_domain": "general_purpose",
      "tldr_zh": "本文批判现有文化评估基准将文化简化为静态事实的局限，提出基于人类学视角的四维分析框架，系统识别了六大方法论缺陷，并建议通过引入真实叙事、社区参与和情境化评估来改进文化基准设计，使大语言模型能更准确应对复杂文化场景。",
      "order": 27,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05931v1"
    },
    {
      "arxiv_id": "2510.05921v1",
      "title": "Prompt reinforcing for long-term planning of large language models",
      "summary": "Large language models (LLMs) have achieved remarkable success in a wide range\nof natural language processing tasks and can be adapted through prompting.\nHowever, they remain suboptimal in multi-turn interactions, often relying on\nincorrect early assumptions and failing to track user goals over time, which\nmakes such tasks particularly challenging. Prior works in dialogue systems have\nshown that long-term planning is essential for handling interactive tasks. In\nthis work, we propose a prompt optimisation framework inspired by reinforcement\nlearning, which enables such planning to take place by only modifying the task\ninstruction prompt of the LLM-based agent. By generating turn-by-turn feedback\nand leveraging experience replay for prompt rewriting, our proposed method\nshows significant improvement in multi-turn tasks such as text-to-SQL and\ntask-oriented dialogue. Moreover, it generalises across different LLM-based\nagents and can leverage diverse LLMs as meta-prompting agents. This warrants\nfuture research in reinforcement learning-inspired parameter-free optimisation\nmethods.",
      "authors": [
        "Hsien-Chin Lin",
        "Benjamin Matthias Ruppik",
        "Carel van Niekerk",
        "Chia-Hao Shen",
        "Michael Heck",
        "Nurul Lubis",
        "Renato Vukovic",
        "Shutong Feng",
        "Milica Gašić"
      ],
      "published": "2025-10-07T13:30:18Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05921v1",
      "primary_area": "text_models",
      "secondary_focus": "['dialogue_systems', 'reasoning']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种基于强化学习思想的提示优化框架，通过生成逐轮反馈和利用经验回放重写提示，显著提升大语言模型在多轮交互任务（如文本转SQL和任务导向对话）中的长期规划能力。该方法无需修改模型参数，可泛化至不同LLM智能体，为参数无关的优化方法开辟了新研究方向。",
      "order": 28,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05921v1"
    },
    {
      "arxiv_id": "2510.05869v1",
      "title": "The fragility of \"cultural tendencies\" in LLMs",
      "summary": "In a recent study, Lu, Song, and Zhang (2025) (LSZ) propose that large\nlanguage models (LLMs), when prompted in different languages, display\nculturally specific tendencies. They report that the two models (i.e., GPT and\nERNIE) respond in more interdependent and holistic ways when prompted in\nChinese, and more independent and analytic ways when prompted in English. LSZ\nattribute these differences to deep-seated cultural patterns in the models,\nclaiming that prompt language alone can induce substantial cultural shifts.\nWhile we acknowledge the empirical patterns they observed, we find their\nexperiments, methods, and interpretations problematic. In this paper, we\ncritically re-evaluate the methodology, theoretical framing, and conclusions of\nLSZ. We argue that the reported \"cultural tendencies\" are not stable traits but\nfragile artifacts of specific models and task design. To test this, we\nconducted targeted replications using a broader set of LLMs and a larger number\nof test items. Our results show that prompt language has minimal effect on\noutputs, challenging LSZ's claim that these models encode grounded cultural\nbeliefs.",
      "authors": [
        "Kun Sun",
        "Rong Wang"
      ],
      "published": "2025-10-07T12:37:06Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05869v1",
      "primary_area": "text_models",
      "secondary_focus": "alignment",
      "application_domain": "general_purpose",
      "tldr_zh": "本文对Lu等人(2025)关于大语言模型存在文化倾向性的研究提出批判性重评估。通过更广泛的模型和测试项目进行复制实验，发现提示语言对输出影响甚微，认为所谓的'文化倾向'并非稳定特质，而是特定模型和任务设计造成的脆弱假象，挑战了LLMs编码深层文化信念的观点。",
      "order": 29,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05869v1"
    },
    {
      "arxiv_id": "2510.05864v1",
      "title": "Evaluating the Sensitivity of LLMs to Harmful Contents in Long Input",
      "summary": "Large language models (LLMs) increasingly support applications that rely on\nextended context, from document processing to retrieval-augmented generation.\nWhile their long-context capabilities are well studied for reasoning and\nretrieval, little is known about their behavior in safety-critical scenarios.\nWe evaluate LLMs' sensitivity to harmful content under extended context,\nvarying type (explicit vs. implicit), position (beginning, middle, end),\nprevalence (0.01-0.50 of the prompt), and context length (600-6000 tokens).\nAcross harmful content categories such as toxic, offensive, and hate speech,\nwith LLaMA-3, Qwen-2.5, and Mistral, we observe similar patterns: performance\npeaks at moderate harmful prevalence (0.25) but declines when content is very\nsparse or dominant; recall decreases with increasing context length; harmful\nsentences at the beginning are generally detected more reliably; and explicit\ncontent is more consistently recognized than implicit. These findings provide\nthe first systematic view of how LLMs prioritize and calibrate harmful content\nin long contexts, highlighting both their emerging strengths and the challenges\nthat remain for safety-critical use.",
      "authors": [
        "Faeze Ghorbanpour",
        "Alexander Fraser"
      ],
      "published": "2025-10-07T12:33:21Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05864v1",
      "primary_area": "text_models",
      "secondary_focus": "['long_context', 'alignment']",
      "application_domain": "general_purpose",
      "tldr_zh": "本研究系统评估了LLaMA-3、Qwen-2.5和Mistral等大语言模型在长上下文（600-6000词）中对有害内容的敏感度。研究发现：有害内容占比25%时检测效果最佳；上下文越长召回率越低；开头位置的有害语句更易被识别；显性内容比隐性内容检测更准确。这为长文本场景下的AI安全应用提供了重要参考。",
      "order": 30,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05864v1"
    },
    {
      "arxiv_id": "2510.05862v1",
      "title": "Revisiting Long-context Modeling from Context Denoising Perspective",
      "summary": "Long-context models (LCMs) have demonstrated great potential in processing\nlong sequences, facilitating many real-world applications. The success of LCMs\ncan be attributed to their ability to locate implicit critical information\nwithin the context for further prediction. However, recent research reveals\nthat LCMs are often susceptible to contextual noise, i.e., irrelevant tokens,\nthat can mislead model attention. In this paper, we conduct a fine-grained\nanalysis of the context noise and propose an effective metric, the Integrated\nGradient (IG) score, to detect and quantify the noise information within the\ncontext. Our findings reveal that even simple mitigation of detected context\nnoise can substantially boost the model's attention on critical tokens and\nbenefit subsequent predictions. Building on this insight, we propose Context\nDenoising Training (CDT), a straightforward yet effective training strategy\nthat improves attention on critical tokens while reinforcing their influence on\nmodel predictions. Extensive experiments across four tasks, under both context\nwindow scaling and long-context alignment settings, demonstrate the superiority\nof CDT. Notably, when trained with CDT, an open-source 8B model can achieve\nperformance (50.92) comparable to GPT-4o (51.00).",
      "authors": [
        "Zecheng Tang",
        "Baibei Ji",
        "Juntao Li",
        "Lijun Wu",
        "Haijia Gui",
        "Min Zhang"
      ],
      "published": "2025-10-07T12:32:23Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05862v1",
      "primary_area": "text_models",
      "secondary_focus": "['long_context', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文从上下文去噪角度重新审视长上下文建模，提出集成梯度评分来检测上下文噪声，并设计上下文去噪训练策略。实验表明该方法能显著提升模型对关键信息的注意力，使8B开源模型达到接近GPT-4o的性能。",
      "order": 31,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05862v1"
    },
    {
      "arxiv_id": "2510.05860v1",
      "title": "Automated Boilerplate: Prevalence and Quality of Contract Generators in\n  the Context of Swiss Privacy Policies",
      "summary": "It has become increasingly challenging for firms to comply with a plethora of\nnovel digital regulations. This is especially true for smaller businesses that\noften lack both the resources and know-how to draft complex legal documents.\nInstead of seeking costly legal advice from attorneys, firms may turn to\ncheaper alternative legal service providers such as automated contract\ngenerators. While these services have a long-standing presence, there is little\nempirical evidence on their prevalence and output quality.\n  We address this gap in the context of a 2023 Swiss privacy law revision. To\nenable a systematic evaluation, we create and annotate a multilingual benchmark\ndataset that captures key compliance obligations under Swiss and EU privacy\nlaw. Using this dataset, we validate a novel GPT-5-based method for large-scale\ncompliance assessment of privacy policies, allowing us to measure the impact of\nthe revision. We observe compliance increases indicating an effect of the\nrevision. Generators, explicitly referenced by 18% of local websites, are\nassociated with substantially higher levels of compliance, with increases of up\nto 15 percentage points compared to privacy policies without generator use.\nThese findings contribute to three debates: the potential of LLMs for\ncross-lingual legal analysis, the Brussels Effect of EU regulations, and,\ncrucially, the role of automated tools in improving compliance and contractual\nquality.",
      "authors": [
        "Luka Nenadic",
        "David Rodriguez"
      ],
      "published": "2025-10-07T12:30:01Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05860v1",
      "primary_area": "text_models",
      "secondary_focus": "alignment",
      "application_domain": "legal_ai",
      "tldr_zh": "本研究针对2023年瑞士隐私法修订，通过构建多语言基准数据集和基于GPT-5的合规评估方法，实证分析了合同生成器在隐私政策中的使用情况。研究发现18%的本地网站使用生成器，且使用生成器的隐私政策合规性显著提高达15个百分点，揭示了自动化工具在法律合规中的积极作用及其与欧盟法规的布鲁塞尔效应。",
      "order": 32,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05860v1"
    },
    {
      "arxiv_id": "2510.05858v1",
      "title": "DACP: Domain-Adaptive Continual Pre-Training of Large Language Models\n  for Phone Conversation Summarization",
      "summary": "Large language models (LLMs) have achieved impressive performance in text\nsummarization, yet their performance often falls short when applied to\nspecialized domains %or conversational data that differ from their original\npre-training distribution. While fine-tuning can improve summarization quality,\nit typically relies on costly and scarce high-quality labeled data. In this\nwork, we explore continual pre-training as a scalable, self-supervised approach\nto adapt LLMs for downstream summarization tasks, particularly in the context\nof noisy real-world conversation transcripts. We conduct extensive experiments\nusing large-scale, unlabeled business conversation data to investigate whether\ncontinual pre-training enhances model capabilities in conversational\nsummarization. Our results demonstrate that continual pre-training yields\nsubstantial gains in both in-domain and out-of-domain summarization benchmarks,\nwhile maintaining strong generalization and robustness. We also analyze the\neffects of data selection strategies, providing practical guidelines for\napplying continual pre-training in summarization-focused industrial\napplications.",
      "authors": [
        "Xue-Yong Fu",
        "Elena Khasanova",
        "Md Tahmid Rahman Laskar",
        "Harsh Saini",
        "Shashi Bhushan TN"
      ],
      "published": "2025-10-07T12:26:19Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05858v1",
      "primary_area": "text_models",
      "secondary_focus": "['training_optimization', 'dialogue_systems']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出DACP方法，通过领域自适应持续预训练提升大语言模型在电话对话摘要任务中的表现。研究显示，利用大规模无标注业务对话数据进行持续预训练，能显著提升模型在领域内外摘要任务的效果，同时保持良好泛化能力，并为工业应用提供数据选择策略指导。",
      "order": 33,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05858v1"
    },
    {
      "arxiv_id": "2510.05846v1",
      "title": "Luth: Efficient French Specialization for Small Language Models and\n  Cross-Lingual Transfer",
      "summary": "The landscape of Large Language Models (LLMs) remains predominantly\nEnglish-centric, resulting in a significant performance gap for other major\nlanguages, such as French, especially in the context of Small Language Models\n(SLMs). Existing multilingual models demonstrate considerably lower performance\nin French compared to English, and research on efficient adaptation methods for\nFrench remains limited. To address this, we introduce \\textbf{Luth}, a family\nof French-specialized SLMs: through targeted post-training on curated,\nhigh-quality French data, our models outperform all open-source counterparts of\ncomparable size on multiple French benchmarks while retaining their original\nEnglish capabilities. We further show that strategic model merging enhances\nperformance in both languages, establishing Luth as a new state of the art for\nFrench SLMs and a robust baseline for future French-language research.",
      "authors": [
        "Maxence Lasbordes",
        "Sinoué Gad"
      ],
      "published": "2025-10-07T12:08:25Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05846v1",
      "primary_area": "text_models",
      "secondary_focus": "['training_optimization', 'model_compression']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出Luth系列法语专用小语言模型，通过针对性后训练和模型融合技术，在保持英语能力的同时显著提升法语任务性能，为法语NLP研究建立了新的基准。",
      "order": 34,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05846v1"
    },
    {
      "arxiv_id": "2510.05837v1",
      "title": "EEPO: Exploration-Enhanced Policy Optimization via Sample-Then-Forget",
      "summary": "Balancing exploration and exploitation remains a central challenge in\nreinforcement learning with verifiable rewards (RLVR) for large language models\n(LLMs). Current RLVR methods often overemphasize exploitation, leading to\nentropy collapse, diminished exploratory capacity, and ultimately limited\nperformance gains. Although techniques that increase policy stochasticity can\npromote exploration, they frequently fail to escape dominant behavioral modes.\nThis creates a self-reinforcing loop-repeatedly sampling and rewarding dominant\nmodes-that further erodes exploration. We introduce Exploration-Enhanced Policy\nOptimization (EEPO), a framework that promotes exploration via two-stage\nrollouts with adaptive unlearning. In the first stage, the model generates half\nof the trajectories; it then undergoes a lightweight unlearning step to\ntemporarily suppress these sampled responses, forcing the second stage to\nexplore different regions of the output space. This sample-then-forget\nmechanism disrupts the self-reinforcing loop and promotes wider exploration\nduring rollouts. Across five reasoning benchmarks, EEPO outperforms GRPO,\nachieving average relative gains of 24.3% on Qwen2.5-3B, 33.0% on\nLlama3.2-3B-Instruct, and 10.4% on Qwen3-8B-Base.",
      "authors": [
        "Liang Chen",
        "Xueting Han",
        "Qizhou Wang",
        "Bo Han",
        "Jing Bai",
        "Hinrich Schutze",
        "Kam-Fai Wong"
      ],
      "published": "2025-10-07T12:02:03Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05837v1",
      "primary_area": "text_models",
      "secondary_focus": "['training_optimization', 'reasoning']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出EEPO框架，通过'采样-遗忘'两阶段策略优化解决LLM强化学习中探索与利用失衡问题。该方法首先生成部分轨迹，随后进行轻量级遗忘以抑制已采样响应，强制模型探索输出空间的不同区域，在五个推理基准上显著优于GRPO方法。",
      "order": 35,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05837v1"
    },
    {
      "arxiv_id": "2510.05799v1",
      "title": "Data-efficient Targeted Token-level Preference Optimization for\n  LLM-based Text-to-Speech",
      "summary": "Aligning text-to-speech (TTS) system outputs with human feedback through\npreference optimization has been shown to effectively improve the robustness\nand naturalness of language model-based TTS models. Current approaches\nprimarily require paired desirable and undesirable samples at the utterance\nlevel. However, such pairs are often limited in TTS output data, and\nutterance-level formulation prevents fine-grained token-level optimization\nneeded for accurate pronunciation alignment. In this study, we propose TKTO\nthat eliminates the need for paired data, enabling a more data-efficient\ntraining paradigm, and directly targets token-level units, automatically\nproviding fine-grained alignment signals without token-level annotations. TKTO\nimproves the challenging Japanese TTS accuracy by 39% and reduces CER by 54%,\nautomatically assigning 12.8 times stronger reward to targeted tokens.",
      "authors": [
        "Rikuto Kotoge",
        "Yuichi Sasaki"
      ],
      "published": "2025-10-07T11:18:04Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05799v1",
      "primary_area": "audio_models",
      "secondary_focus": "['training_optimization', 'alignment']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出TKTO方法，针对基于大语言模型的文本转语音系统，通过无需配对数据的令牌级偏好优化，显著提升日语TTS准确率39%，降低字错误率54%，实现细粒度发音对齐。",
      "order": 36,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05799v1"
    },
    {
      "arxiv_id": "2510.05781v1",
      "title": "Mixture of Neuron Experts",
      "summary": "In this work, we first explore whether the parameters activated by the MoE\nlayer remain highly sparse at inference. We perform a sparsification study on\nseveral representative MoE models. For each expert, we rank parameters by the\nmagnitude of their activations from the gate projection and progressively prune\nthe activated subset. Pruning up to 60% of parameters within that subset causes\nonly negligible task-performance degradation; substantial drops occur only\nafter more than 90% are removed. We further decompose experts into\nneuron-granular MoE and visualize their activation values, finding that most\nneuron activations are near zero. This observation motivates us to select only\nhigh-activation neuron experts during pretraining. Based on this insight, we\npropose Mixture of Neuron Experts (MoNE). MoNE achieves neuron-granular expert\nselection by only applying a simple top-k selection within each expert, incurs\nnegligible latency, and requires no additional routing parameters or\ninter-expert communication. Extensive experiments demonstrate that MoNE matches\ntraditional MoE performance while activating only 50% of the MoE-layer\nparameters, and it consistently outperforms traditional MoE when compared at\nequal numbers of activated parameters. These results suggest that MoNE is a\npractical approach to improving parameter utilization and inference efficiency\nin MoE-like models.",
      "authors": [
        "Runxi Cheng",
        "Yuchen Guan",
        "Yucheng Ding",
        "Qingguo Hu",
        "Yongxian Wei",
        "Chun Yuan",
        "Yelong Shen",
        "Weizhu Chen",
        "Yeyun Gong"
      ],
      "published": "2025-10-07T10:51:58Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05781v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_architecture', 'model_compression']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出神经元粒度混合专家模型(MoNE)，通过研究发现MoE层在推理时参数激活高度稀疏，仅需保留高激活神经元即可维持性能。MoNE采用简单的top-k选择机制，无需额外路由参数，在激活50%参数的情况下达到传统MoE性能，显著提升推理效率。",
      "order": 37,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05781v1"
    },
    {
      "arxiv_id": "2510.05769v1",
      "title": "InforME: Improving Informativeness of Abstractive Text Summarization\n  With Informative Attention Guided by Named Entity Salience",
      "summary": "Abstractive text summarization is integral to the Big Data era, which demands\nadvanced methods to turn voluminous and often long text data into concise but\ncoherent and informative summaries for efficient human consumption. Despite\nsignificant progress, there is still room for improvement in various aspects.\nOne such aspect is to improve informativeness. Hence, this paper proposes a\nnovel learning approach consisting of two methods: an optimal transport-based\ninformative attention method to improve learning focal information in reference\nsummaries and an accumulative joint entropy reduction method on named entities\nto enhance informative salience. Experiment results show that our approach\nachieves better ROUGE scores compared to prior work on CNN/Daily Mail while\nhaving competitive results on XSum. Human evaluation of informativeness also\ndemonstrates the better performance of our approach over a strong baseline.\nFurther analysis gives insight into the plausible reasons underlying the\nevaluation results.",
      "authors": [
        "Jianbin Shen",
        "Christy Jie Liang",
        "Junyu Xuan"
      ],
      "published": "2025-10-07T10:40:09Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05769v1",
      "primary_area": "text_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出InforME方法，通过基于最优传输的信息关注机制和命名实体联合熵减方法，提升抽象文本摘要的信息密度。在CNN/Daily Mail数据集上取得优于现有方法的ROUGE分数，在XSum上表现相当，人工评估也证实了其信息丰富度的提升。",
      "order": 38,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05769v1"
    },
    {
      "arxiv_id": "2510.05767v1",
      "title": "Diversity Is All You Need for Contrastive Learning: Spectral Bounds on\n  Gradient Magnitudes",
      "summary": "We derive non-asymptotic spectral bands that bound the squared InfoNCE\ngradient norm via alignment, temperature, and batch spectrum, recovering the\n\\(1/\\tau^{2}\\) law and closely tracking batch-mean gradients on synthetic data\nand ImageNet. Using effective rank \\(R_{\\mathrm{eff}}\\) as an anisotropy proxy,\nwe design spectrum-aware batch selection, including a fast greedy builder. On\nImageNet-100, Greedy-64 cuts time-to-67.5\\% top-1 by 15\\% vs.\\ random (24\\%\nvs.\\ Pool--P3) at equal accuracy; CIFAR-10 shows similar gains. In-batch\nwhitening promotes isotropy and reduces 50-step gradient variance by\n\\(1.37\\times\\), matching our theoretical upper bound.",
      "authors": [
        "Peter Ochieng"
      ],
      "published": "2025-10-07T10:35:58Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05767v1",
      "primary_area": "text_models",
      "secondary_focus": "training_optimization",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出基于谱分析的对比学习理论框架，推导出InfoNCE梯度范数的非渐近谱界，揭示了温度参数和批次数据谱结构对训练的影响。通过设计谱感知批次选择算法和批内白化技术，在ImageNet和CIFAR-10上显著提升训练效率，其中Greedy-64算法将达到67.5% top-1准确率的时间缩短15%，梯度方差降低1.37倍。",
      "order": 39,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05767v1"
    },
    {
      "arxiv_id": "2510.05744v1",
      "title": "Adaptive and Multi-Source Entity Matching for Name Standardization of\n  Astronomical Observation Facilities",
      "summary": "This ongoing work focuses on the development of a methodology for generating\na multi-source mapping of astronomical observation facilities. To compare two\nentities, we compute scores with adaptable criteria and Natural Language\nProcessing (NLP) techniques (Bag-of-Words approaches, sequential approaches,\nand surface approaches) to map entities extracted from eight semantic\nartifacts, including Wikidata and astronomy-oriented resources. We utilize\nevery property available, such as labels, definitions, descriptions, external\nidentifiers, and more domain-specific properties, such as the observation\nwavebands, spacecraft launch dates, funding agencies, etc. Finally, we use a\nLarge Language Model (LLM) to accept or reject a mapping suggestion and provide\na justification, ensuring the plausibility and FAIRness of the validated\nsynonym pairs. The resulting mapping is composed of multi-source synonym sets\nproviding only one standardized label per entity. Those mappings will be used\nto feed our Name Resolver API and will be integrated into the International\nVirtual Observatory Alliance (IVOA) Vocabularies and the OntoPortal-Astro\nplatform.",
      "authors": [
        "Liza Fretel",
        "Baptiste Cecconi",
        "Laura Debisschop"
      ],
      "published": "2025-10-07T10:04:08Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05744v1",
      "primary_area": "text_models",
      "secondary_focus": "reasoning",
      "application_domain": "general_purpose",
      "tldr_zh": "本研究开发了一种天文观测设施名称标准化的自适应多源实体匹配方法，结合可调节评分标准与多种NLP技术（词袋、序列和表层方法），从八个语义资源中提取并映射实体。利用标签、定义、描述、外部标识符及观测波段、发射日期等专业属性，通过大语言模型验证映射建议的合理性，最终生成多源同义词集并为每个实体提供单一标准化标签，将用于名称解析API并集成至国际虚拟天文台联盟词汇表和OntoPortal-Astro平台。",
      "order": 40,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05744v1"
    },
    {
      "arxiv_id": "2510.05691v1",
      "title": "DecEx-RAG: Boosting Agentic Retrieval-Augmented Generation with Decision\n  and Execution Optimization via Process Supervision",
      "summary": "Agentic Retrieval-Augmented Generation (Agentic RAG) enhances the processing\ncapability for complex tasks through dynamic retrieval and adaptive workflows.\nRecent advances (e.g., Search-R1) have shown that outcome-supervised\nreinforcement learning demonstrate strong performance. However, this approach\nstill suffers from inefficient exploration, sparse reward signals, and\nambiguous global reward feedback. To address these challenges, we propose\nDecEx-RAG, which models RAG as a Markov Decision Process (MDP) incorporating\ndecision-making and execution, while introducing an efficient pruning strategy\nto optimize data expansion. Through comprehensive process-level policy\noptimization, DecEx-RAG significantly enhances the autonomous task\ndecomposition, dynamic retrieval, and high-quality answer generation\ncapabilities of large language models (LLMs). Experiments show that DecEx-RAG\nachieves an average absolute performance improvement of $6.2\\%$ across six\ndatasets, significantly outperforming existing baselines. Moreover, the pruning\nstrategy improves data construction efficiency by nearly $6 \\times$, providing\nan efficient solution for process-supervised RAG training. The code is\navailable at https://github.com/sdsxdxl/DecEx-RAG.",
      "authors": [
        "Yongqi Leng",
        "Yikun Lei",
        "Xikai Liu",
        "Meizhi Zhong",
        "Bojian Xiong",
        "Yurong Zhang",
        "Yan Gao",
        "Yi Wu",
        "Yao Hu",
        "Deyi Xiong"
      ],
      "published": "2025-10-07T08:49:22Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05691v1",
      "primary_area": "text_models",
      "secondary_focus": "['training_optimization', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出DecEx-RAG方法，通过将检索增强生成建模为马尔可夫决策过程并引入剪枝策略，解决了传统结果监督强化学习在探索效率、奖励稀疏性和全局反馈模糊性方面的局限。该方法在六个数据集上实现平均6.2%的绝对性能提升，数据构建效率提升近6倍，显著增强了LLM在任务分解、动态检索和答案生成方面的自主能力。",
      "order": 41,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05691v1"
    },
    {
      "arxiv_id": "2510.05678v1",
      "title": "Code-Switching In-Context Learning for Cross-Lingual Transfer of Large\n  Language Models",
      "summary": "While large language models (LLMs) exhibit strong multilingual abilities,\ntheir reliance on English as latent representations creates a translation\nbarrier, where reasoning implicitly depends on internal translation into\nEnglish. When this process fails, performance in non-English languages\ndeteriorates sharply, limiting the inclusiveness of LLM-based applications.\nExisting cross-lingual in-context learning (X-ICL) methods primarily leverage\nmonolingual demonstrations, often failing to mitigate this barrier and instead\nreinforcing it. In this work, we introduce code-switching in-context learning\n(CSICL), a simple yet effective prompting strategy that progressively\ntransitions from a target language to English within demonstrations and\ninstruction to facilitate their latent reasoning in English. By explicitly\nscaffolding the reasoning process through controlled code-switching, CSICL acts\nas an implicit linguistic bridge that enhances cross-lingual alignment and\nreduces reliance on the translation barrier. We conduct extensive experiments\nacross 4 LLMs, 6 datasets, and 10 languages, spanning both knowledge-intensive\nand reasoning-oriented domains. Our results demonstrate that CSICL consistently\noutperforms X-ICL baselines, achieving gains of 3.1%p and 1.9%p in both target\nand unseen languages, respectively. The improvement is even more pronounced in\nlow-resource settings, with gains of 14.7% in target and 5.3% in unseen\nlanguages. These findings establish code-switching as a principled and robust\napproach for overcoming the translation barrier during inference, moving LLMs\ntoward more equitable and effective multilingual systems.",
      "authors": [
        "Haneul Yoo",
        "Jiho Jin",
        "Kyunghyun Cho",
        "Alice Oh"
      ],
      "published": "2025-10-07T08:35:42Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05678v1",
      "primary_area": "text_models",
      "secondary_focus": "['reasoning', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出代码切换上下文学习(CSICL)方法，通过在演示示例中渐进式地从目标语言过渡到英语，为大语言模型构建隐式语言桥梁，有效缓解其依赖英语内部翻译的推理障碍。实验表明该方法在10种语言、6个数据集上均优于传统跨语言上下文学习，尤其在低资源语言中提升显著(目标语言提升14.7%)，推动大模型实现更公平有效的多语言系统。",
      "order": 42,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05678v1"
    },
    {
      "arxiv_id": "2510.05644v1",
      "title": "The African Languages Lab: A Collaborative Approach to Advancing\n  Low-Resource African NLP",
      "summary": "Despite representing nearly one-third of the world's languages, African\nlanguages remain critically underserved by modern NLP technologies, with 88\\%\nclassified as severely underrepresented or completely ignored in computational\nlinguistics. We present the African Languages Lab (All Lab), a comprehensive\nresearch initiative that addresses this technological gap through systematic\ndata collection, model development, and capacity building. Our contributions\ninclude: (1) a quality-controlled data collection pipeline, yielding the\nlargest validated African multi-modal speech and text dataset spanning 40\nlanguages with 19 billion tokens of monolingual text and 12,628 hours of\naligned speech data; (2) extensive experimental validation demonstrating that\nour dataset, combined with fine-tuning, achieves substantial improvements over\nbaseline models, averaging +23.69 ChrF++, +0.33 COMET, and +15.34 BLEU points\nacross 31 evaluated languages; and (3) a structured research program that has\nsuccessfully mentored fifteen early-career researchers, establishing\nsustainable local capacity. Our comparative evaluation against Google Translate\nreveals competitive performance in several languages while identifying areas\nthat require continued development.",
      "authors": [
        "Sheriff Issaka",
        "Keyi Wang",
        "Yinka Ajibola",
        "Oluwatumininu Samuel-Ipaye",
        "Zhaoyi Zhang",
        "Nicte Aguillon Jimenez",
        "Evans Kofi Agyei",
        "Abraham Lin",
        "Rohan Ramachandran",
        "Sadick Abdul Mumin",
        "Faith Nchifor",
        "Mohammed Shuraim",
        "Lieqi Liu",
        "Erick Rosas Gonzalez",
        "Sylvester Kpei",
        "Jemimah Osei",
        "Carlene Ajeneza",
        "Persis Boateng",
        "Prisca Adwoa Dufie Yeboah",
        "Saadia Gabriel"
      ],
      "published": "2025-10-07T07:42:52Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05644v1",
      "primary_area": "['text_models', 'audio_models']",
      "secondary_focus": "['training_optimization']",
      "application_domain": "['general_purpose']",
      "tldr_zh": "本文介绍非洲语言实验室项目，通过系统化数据收集、模型开发和能力建设，解决非洲低资源语言在自然语言处理中的严重不足。项目构建了涵盖40种语言的最大验证多模态数据集（190亿文本标记和1.2万小时语音），微调后模型性能显著提升（平均ChrF++提高23.69），并培养了15名早期研究人员建立本地可持续能力。",
      "order": 43,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05644v1"
    },
    {
      "arxiv_id": "2510.05611v1",
      "title": "MADIAVE: Multi-Agent Debate for Implicit Attribute Value Extraction",
      "summary": "Implicit Attribute Value Extraction (AVE) is essential for accurately\nrepresenting products in e-commerce, as it infers lantent attributes from\nmultimodal data. Despite advances in multimodal large language models (MLLMs),\nimplicit AVE remains challenging due to the complexity of multidimensional data\nand gaps in vision-text understanding. In this work, we introduce\n\\textsc{\\modelname}, a multi-agent debate framework that employs multiple MLLM\nagents to iteratively refine inferences. Through a series of debate rounds,\nagents verify and update each other's responses, thereby improving inference\nperformance and robustness. Experiments on the ImplicitAVE dataset demonstrate\nthat even a few rounds of debate significantly boost accuracy, especially for\nattributes with initially low performance. We systematically evaluate various\ndebate configurations, including identical or different MLLM agents, and\nanalyze how debate rounds affect convergence dynamics. Our findings highlight\nthe potential of multi-agent debate strategies to address the limitations of\nsingle-agent approaches and offer a scalable solution for implicit AVE in\nmultimodal e-commerce.",
      "authors": [
        "Wei-Chieh Huang",
        "Cornelia Caragea"
      ],
      "published": "2025-10-07T06:27:42Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05611v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['reasoning', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出MADIAVE多智能体辩论框架，通过多个多模态大语言模型代理的迭代辩论来提升隐式属性值抽取性能。在ImplicitAVE数据集上的实验表明，即使少量辩论轮次也能显著提高准确率，尤其对初始性能较差的属性效果明显，为多模态电商场景提供了可扩展的解决方案。",
      "order": 44,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05611v1"
    },
    {
      "arxiv_id": "2510.05608v1",
      "title": "A Goal Without a Plan Is Just a Wish: Efficient and Effective Global\n  Planner Training for Long-Horizon Agent Tasks",
      "summary": "Agents based on large language models (LLMs) struggle with brainless\ntrial-and-error and generating hallucinatory actions due to a lack of global\nplanning in long-horizon tasks. In this paper, we introduce a plan-and-execute\nframework and propose EAGLET, an efficient and effective planner training\nmethod to enhance the executor agent's planning abilities without human effort.\nSpecifically, we train a plug-and-play global planner through a two-step\nprocess: we first synthesize high-quality plans from an advanced LLM using our\nproposed homologous consensus filtering strategy, and apply fine-tuning as a\ncold start. Moreover, we further improve the planner with a rule-based\nreinforcement learning stage using a novel executor capability gain reward,\nensuring it can handle task instructions of varying difficulty. Experiments on\nthree long-horizon agent tasks show that executor agents equipped with our\nplanner outperform existing methods, achieving new state-of-the-art\nperformance. Meanwhile, EAGLET reduces training costs by 8x compared to\nRL-based baselines, and it does not require manual effort or extra training\ndata, offering an efficient and effective solution.",
      "authors": [
        "Shuzheng Si",
        "Haozhe Zhao",
        "Kangyang Luo",
        "Gang Chen",
        "Fanchao Qi",
        "Minjia Zhang",
        "Baobao Chang",
        "Maosong Sun"
      ],
      "published": "2025-10-07T06:10:53Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05608v1",
      "primary_area": "text_models",
      "secondary_focus": "['training_optimization', 'reasoning']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出EAGLET方法，通过两步训练流程（同源共识过滤+规则强化学习）高效训练全局规划器，解决LLM智能体在长程任务中缺乏全局规划的问题，在三个任务上实现SOTA性能，训练成本降低8倍且无需人工标注。",
      "order": 45,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05608v1"
    },
    {
      "arxiv_id": "2510.05577v1",
      "title": "Mission Impossible: Feedback-Guided Dynamic Interactive Planning for\n  Improving Reasoning on LLMs",
      "summary": "Recent advancements in language agents have led to significant improvements\nin multi-hop reasoning tasks. However, existing approaches often struggle with\nhandling open-domain problems, which require massive information retrieval due\nto their reliance on a fixed sequence of actions. To address this, we propose\nFeedback-Guided Dynamic Interactive Planning (FGDIP), a novel framework\ntailored to enhance reasoning in LLMs by utilizing dynamic and adaptive\nstrategies for information exploration in open-domain multi-hop reasoning\ntasks. Our approach begins by identifying key entities relevant to the problem,\nwhich serve as the initial nodes in the reasoning process. From these initial\nnodes, we then generate reasoning child nodes with the process being refined\nthrough a combination of historical error analysis and real-time feedback,\nwhich allows the framework to dynamically adjust and optimize its reasoning\nstrategies. By integrating depth-first search with an innovative node\ngeneration technique, our framework adapts based on both prior error paths and\nconcurrently generated nodes at the same hierarchical level. This dynamic\nstrategy effectively expands the search space while ensuring the reasoning\nprocess systematically converges toward accurate solutions. Experimental\nresults show that FGDIP achieved up to 54.47% F1 score on the HotpotQA dataset\nand 70.05% on the StrategyQA dataset, surpassing the best baseline by 5.03% and\n7.25% respectively, highlighting its versatility and potential to enhance\nlanguage agents in multi-hop reasoning tasks.",
      "authors": [
        "Dong Yan",
        "Gaochen Wu",
        "Bowen Zhou"
      ],
      "published": "2025-10-07T04:46:58Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05577v1",
      "primary_area": "text_models",
      "secondary_focus": "['reasoning', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出FGDIP框架，通过反馈引导的动态交互规划增强LLM在开放域多跳推理任务中的表现。该方法结合历史错误分析和实时反馈动态调整推理策略，在HotpotQA和StrategyQA数据集上分别达到54.47%和70.05%的F1分数，显著优于基线方法。",
      "order": 46,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05577v1"
    },
    {
      "arxiv_id": "2510.05571v1",
      "title": "Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for\n  Academic Presentations",
      "summary": "The promotion of academic papers has become an important means of enhancing\nresearch visibility. However, existing automated methods struggle limited\nstorytelling, insufficient aesthetic quality, and constrained self-adjustment,\nmaking it difficult to achieve efficient and engaging dissemination. At the\nheart of those challenges is a simple principle: \\emph{there is no way to\nimprove it when you cannot evaluate it right}. To address this, we introduce\n\\textbf{EvoPresent}, a self-improvement agent framework that unifies coherent\nnarratives, aesthetic-aware designs, and realistic presentation delivery via\nvirtual characters. Central to EvoPresent is \\textbf{PresAesth}, a multi-task\nreinforcement learning (RL) aesthetic model that provides reliable aesthetic\nscoring, defect adjustment, and comparative feedback, enabling iterative\nself-improvement even under limited aesthetic training data. To systematically\nevaluate the methods, we introduce \\textbf{EvoPresent Benchmark}, a\ncomprehensive benchmark comprising: \\textit{Presentation Generation Quality},\nbuilt on 650 top-tier AI conference papers with multimodal resources (slides,\nvideos and scripts) to assess both content and design; and \\textit{Aesthetic\nAwareness}, consisting of 2,000 slide pairs with varying aesthetic levels,\nsupporting joint training and evaluation on scoring, defect adjustment, and\ncomparison. Our findings highlight that (i) High-quality feedback is essential\nfor agent self-improvement, while initial capability alone does not guarantee\neffective self-correction. (ii) Automated generation pipelines exhibit a\ntrade-off between visual design and content construction. (iii) Multi-task RL\ntraining shows stronger generalization in aesthetic awareness tasks.",
      "authors": [
        "Chengzhi Liu",
        "Yuzhe Yang",
        "Kaiwen Zhou",
        "Zhen Zhang",
        "Yue Fan",
        "Yannan Xie",
        "Peng Qi",
        "Xin Eric Wang"
      ],
      "published": "2025-10-07T04:24:26Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05571v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "model_architecture",
      "application_domain": "education_ai",
      "tldr_zh": "本文提出EvoPresent框架，通过多任务强化学习的美学评估模型PresAesth，解决学术演示自动化生成中的叙事连贯性、美学质量和自我调整问题。该框架包含包含650篇顶级AI会议论文的多模态基准，证明高质量反馈对智能体自我改进至关重要，并在美学感知任务中展现出更强的泛化能力。",
      "order": 47,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05571v1"
    },
    {
      "arxiv_id": "2510.05544v1",
      "title": "Activation-Informed Pareto-Guided Low-Rank Compression for Efficient\n  LLM/VLM",
      "summary": "Large language models (LLM) and vision-language models (VLM) have achieved\nstate-of-the-art performance, but they impose significant memory and computing\nchallenges in deployment. We present a novel low-rank compression framework to\naddress this challenge. First, we upper bound the change of network loss via\nlayer-wise activation-based compression errors, filling a theoretical gap in\nthe literature. We then formulate low-rank model compression as a bi-objective\noptimization and prove that a single uniform tolerance yields surrogate\nPareto-optimal heterogeneous ranks. Based on our theoretical insights, we\npropose Pareto-Guided Singular Value Decomposition (PGSVD), a zero-shot\npipeline that improves activation-aware compression via Pareto-guided rank\nselection and alternating least-squares implementation. We apply PGSVD to both\nLLM and VLM, showing better accuracy at the same compression levels and\ninference speedup.",
      "authors": [
        "Ryan Solgi",
        "Parsa Madinei",
        "Jiayi Tian",
        "Rupak Swaminathan",
        "Jing Liu",
        "Nathan Susanj",
        "Zheng Zhang"
      ],
      "published": "2025-10-07T03:07:47Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05544v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "model_compression",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种基于激活信息的帕累托引导低秩压缩框架(PGSVD)，通过理论分析建立网络损失变化上界，将压缩问题转化为双目标优化，证明单一容忍度可生成帕累托最优异构秩分配。该零样本方法在LLM/VLM上实现更高精度的压缩与推理加速。",
      "order": 48,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05544v1"
    },
    {
      "arxiv_id": "2510.05534v1",
      "title": "On the Role of Difficult Prompts in Self-Play Preference Optimization",
      "summary": "Self-play preference optimization has emerged as a prominent paradigm for\naligning large language models (LLMs). It typically involves a language model\nto generate on-policy responses for prompts and a reward model (RM) to guide\nthe selection of chosen and rejected responses, which can be further trained\nwith direct preference optimization (DPO). However, the role of prompts remains\nunderexplored, despite being a core component in this pipeline. In this work,\nwe investigate how prompts of varying difficulty influence self-play preference\noptimization. We first use the mean reward of $N$ sampled responses of a prompt\nas a proxy for its difficulty. We find that difficult prompts exhibit\nsubstantially inferior self-play optimization performance in comparison to easy\nprompts for language models. Moreover, incorporating difficult prompts into\ntraining fails to enhance overall performance and, in fact, leads to slight\ndegradation compared to training on easy prompts alone. We also observe that\nthe performance gap between difficult and easy prompts closes as the model\ncapacity increases, suggesting that difficulty interacts with the model\ncapacity. Building on these findings, we explore strategies to mitigate the\nnegative effect of difficult prompts on final performance. We demonstrate that\nselectively removing an appropriate portion of challenging prompts enhances\noverall self-play performance, while also reporting failed attempts and lessons\nlearned.",
      "authors": [
        "Yao Xiao",
        "Jung-jae Kim",
        "Roy Ka-wei Lee",
        "Lidong Bing"
      ],
      "published": "2025-10-07T02:47:25Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05534v1",
      "primary_area": "text_models",
      "secondary_focus": "['alignment', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文研究提示难度在自博弈偏好优化中的作用，发现困难提示会降低语言模型优化效果，且模型容量与提示难度存在交互作用。通过选择性剔除困难提示可提升整体性能，为大模型对齐训练提供重要策略启示。",
      "order": 49,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05534v1"
    },
    {
      "arxiv_id": "2510.05529v1",
      "title": "H1B-KV: Hybrid One-Bit Caches for Memory-Efficient Large Language Model\n  Inference",
      "summary": "Autoregressive decoding in large language models (LLMs) requires caching a\ngrowing list of past key-value (KV) pairs, making long-context inference a\nmemory-bound problem. While recent methods have explored quantizing the cache,\nevicting tokens, or using binary sketches for keys (e.g., Loki), these\napproaches often provide an incomplete solution by leaving one component (like\nvalues) uncompressed or by discarding context information. This paper\nintroduces the Hybrid One-Bit KV Cache (H1B-KV), a comprehensive compression\nscheme that radically reduces memory usage without sacrificing context. H1B-KV\nrepresents each key vector using a 1-bit binary sketch, enabling\nhardware-friendly bitwise attention, and further compresses value vectors using\n4-bit quantization. This holistic, hybrid approach allows a 7-billion parameter\nLLM to handle an 8k-token context with under 60 MB of cache memory - a 70x\nreduction. We demonstrate that after a lightweight finetuning, H1B-KV matches\nfull-precision performance not only on perplexity benchmarks but also on\ncomplex downstream tasks like mathematical reasoning (GSM8K), multi-task\nunderstanding (MMLU), and code generation (HumanEval). Our results show H1B-KV\nsignificantly outperforms leading quantization (KIVI), token eviction\n(SparseLLM), and key-only sketching (Loki) methods in quality-per-byte,\nestablishing it as a robust solution for deploying LLMs in memory-constrained\nenvironments.",
      "authors": [
        "Harshil Vejendla"
      ],
      "published": "2025-10-07T02:39:35Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05529v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_compression', 'long_context']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出H1B-KV混合1位缓存技术，通过1位键向量二值化与4位值向量量化，实现大语言模型推理内存占用降低70倍（8K上下文仅需60MB），在数学推理、多任务理解等任务中保持全精度性能，显著优于现有压缩方法。",
      "order": 50,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05529v1"
    },
    {
      "arxiv_id": "2510.05524v1",
      "title": "KEO: Knowledge Extraction on OMIn via Knowledge Graphs and RAG for\n  Safety-Critical Aviation Maintenance",
      "summary": "We present Knowledge Extraction on OMIn (KEO), a domain-specific knowledge\nextraction and reasoning framework with large language models (LLMs) in\nsafety-critical contexts. Using the Operations and Maintenance Intelligence\n(OMIn) dataset, we construct a QA benchmark spanning global sensemaking and\nactionable maintenance tasks. KEO builds a structured Knowledge Graph (KG) and\nintegrates it into a retrieval-augmented generation (RAG) pipeline, enabling\nmore coherent, dataset-wide reasoning than traditional text-chunk RAG. We\nevaluate locally deployable LLMs (Gemma-3, Phi-4, Mistral-Nemo) and employ\nstronger models (GPT-4o, Llama-3.3) as judges. Experiments show that KEO\nmarkedly improves global sensemaking by revealing patterns and system-level\ninsights, while text-chunk RAG remains effective for fine-grained procedural\ntasks requiring localized retrieval. These findings underscore the promise of\nKG-augmented LLMs for secure, domain-specific QA and their potential in\nhigh-stakes reasoning.",
      "authors": [
        "Kuangshi Ai",
        "Jonathan A. Karr Jr",
        "Meng Jiang",
        "Nitesh V. Chawla",
        "Chaoli Wang"
      ],
      "published": "2025-10-07T02:29:13Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05524v1",
      "primary_area": "text_models",
      "secondary_focus": "['reasoning', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出KEO框架，结合知识图谱与检索增强生成技术，在航空安全维护领域实现知识提取与推理。通过构建结构化知识图谱并集成到RAG流程中，显著提升全局感知能力，同时保持传统文本块RAG在细粒度任务上的优势。实验表明KG增强的LLM在安全关键领域具有重要应用潜力。",
      "order": 51,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05524v1"
    },
    {
      "arxiv_id": "2510.05520v1",
      "title": "CAM: A Constructivist View of Agentic Memory for LLM-Based Reading\n  Comprehension",
      "summary": "Current Large Language Models (LLMs) are confronted with overwhelming\ninformation volume when comprehending long-form documents. This challenge\nraises the imperative of a cohesive memory module, which can elevate vanilla\nLLMs into autonomous reading agents. Despite the emergence of some heuristic\napproaches, a systematic design principle remains absent. To fill this void, we\ndraw inspiration from Jean Piaget's Constructivist Theory, illuminating three\ntraits of the agentic memory -- structured schemata, flexible assimilation, and\ndynamic accommodation. This blueprint forges a clear path toward a more robust\nand efficient memory system for LLM-based reading comprehension. To this end,\nwe develop CAM, a prototype implementation of Constructivist Agentic Memory\nthat simultaneously embodies the structurality, flexibility, and dynamicity. At\nits core, CAM is endowed with an incremental overlapping clustering algorithm\nfor structured memory development, supporting both coherent hierarchical\nsummarization and online batch integration. During inference, CAM adaptively\nexplores the memory structure to activate query-relevant information for\ncontextual response, akin to the human associative process. Compared to\nexisting approaches, our design demonstrates dual advantages in both\nperformance and efficiency across diverse long-text reading comprehension\ntasks, including question answering, query-based summarization, and claim\nverification.",
      "authors": [
        "Rui Li",
        "Zeyu Zhang",
        "Xiaohe Bo",
        "Zihang Tian",
        "Xu Chen",
        "Quanyu Dai",
        "Zhenhua Dong",
        "Ruiming Tang"
      ],
      "published": "2025-10-07T02:16:30Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05520v1",
      "primary_area": "text_models",
      "secondary_focus": "['long_context', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出CAM（建构主义能动记忆）框架，受皮亚杰建构主义理论启发，为LLM长文档阅读理解设计结构化记忆系统。通过增量重叠聚类算法实现层次化记忆构建，在问答、查询摘要等任务中展现优越性能与效率。",
      "order": 52,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05520v1"
    },
    {
      "arxiv_id": "2510.05498v1",
      "title": "Prototype-Based Dynamic Steering for Large Language Models",
      "summary": "Despite impressive breadth, LLMs still rely on explicit reasoning\ninstructions or static, one-fits-all steering methods, leaving a gap for\nadaptive, instruction-free reasoning amplification. We present Prototype-Based\nDynamic Steering (PDS), a test-time method that amplifies large language model\n(LLM) reasoning without adding or altering instructions. We introduce\n\"reasoning prototypes\" by clustering activation differences between\nChain-of-Thought (CoT) and neutral prompts. At inference, an input's hidden\nstate is projected onto these prototypes to form an instance-specific steering\nvector. Evaluated on GSM8K, AQuA-RAT, and BIG-Bench tasks, PDS consistently\nimproves accuracy without fine-tuning or prompt engineering. Notably, the gains\npersist even when CoT is explicitly suppressed to improve cost-efficiency,\nindicating that the intervention strengthens latent reasoning processes rather\nthan inducing a superficial behavioral shift. These results position dynamic,\nprototype-guided steering as a lightweight alternative to training-time\napproaches for enhancing LLM reasoning.",
      "authors": [
        "Ceyhun Efe Kayan",
        "Li Zhang"
      ],
      "published": "2025-10-07T01:34:28Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05498v1",
      "primary_area": "text_models",
      "secondary_focus": "['reasoning', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出原型动态引导(PDS)方法，通过聚类思维链与中性提示的激活差异构建推理原型，在推理时根据输入隐状态生成实例特定的引导向量。该方法无需微调或提示工程，在多个推理任务中显著提升准确率，即使抑制显式思维链仍能增强潜在推理能力，为LLM推理增强提供轻量级替代方案。",
      "order": 53,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05498v1"
    },
    {
      "arxiv_id": "2510.05490v1",
      "title": "LANTERN: Scalable Distillation of Large Language Models for Job-Person\n  Fit and Explanation",
      "summary": "Large language models (LLMs) have achieved strong performance across a wide\nrange of natural language processing tasks. However, deploying LLMs at scale\nfor domain specific applications, such as job-person fit and explanation in job\nseeking platforms, introduces distinct challenges. At LinkedIn, the job person\nfit task requires analyzing a candidate's public profile against job\nrequirements to produce both a fit assessment and a detailed explanation.\nDirectly applying open source or finetuned LLMs to this task often fails to\nyield high quality, actionable feedback due to the complexity of the domain and\nthe need for structured outputs. Moreover, the large size of these models leads\nto high inference latency and limits scalability, making them unsuitable for\nonline use. To address these challenges, we introduce LANTERN, a novel LLM\nknowledge distillation framework tailored specifically for job person fit\ntasks. LANTERN involves modeling over multiple objectives, an encoder model for\nclassification purpose, and a decoder model for explanation purpose. To better\ndistill the knowledge from a strong black box teacher model to multiple\ndownstream models, LANTERN incorporates multi level knowledge distillation that\nintegrates both data and logit level insights. In addition to introducing the\nknowledge distillation framework, we share our insights on post training\ntechniques and prompt engineering, both of which are crucial for successfully\nadapting LLMs to domain specific downstream tasks. Extensive experimental\nresults demonstrate that LANTERN significantly improves task specific metrics\nfor both job person fit and explanation. Online evaluations further confirm its\neffectiveness, showing measurable gains in job seeker engagement, including a\n0.24\\% increase in apply rate and a 0.28\\% increase in qualified applications.",
      "authors": [
        "Zhoutong Fu",
        "Yihan Cao",
        "Yi-Lin Chen",
        "Aman Lunia",
        "Liming Dong",
        "Neha Saraf",
        "Ruijie Jiang",
        "Yun Dai",
        "Qingquan Song",
        "Tan Wang",
        "Guoyao Li",
        "Derek Koh",
        "Haichao Wei",
        "Zhipeng Wang",
        "Aman Gupta",
        "Chengming Jiang",
        "Jianqiang Shen",
        "Liangjie Hong",
        "Wenjing Zhang"
      ],
      "published": "2025-10-07T01:10:02Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05490v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_compression', 'dialogue_systems']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出LANTERN框架，通过多层次知识蒸馏技术将大型语言模型压缩为适用于职位匹配与解释任务的高效模型。该方案在LinkedIn平台上验证有效，显著提升求职者参与度，申请率增加0.24%，合格申请率提升0.28%。",
      "order": 54,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05490v1"
    },
    {
      "arxiv_id": "2510.05486v1",
      "title": "Language Model as Planner and Formalizer under Constraints",
      "summary": "LLMs have been widely used in planning, either as planners to generate action\nsequences end-to-end, or as formalizers to represent the planning domain and\nproblem in a formal language that can derive plans deterministically. However,\nboth lines of work rely on standard benchmarks that only include generic and\nsimplistic environmental specifications, leading to potential overestimation of\nthe planning ability of LLMs and safety concerns in downstream tasks. We bridge\nthis gap by augmenting widely used planning benchmarks with manually annotated,\nfine-grained, and rich natural language constraints spanning four formally\ndefined categories. Over 4 state-of-the-art reasoning LLMs, 3 formal languages,\n5 methods, and 4 datasets, we show that the introduction of constraints not\nonly consistently halves performance, but also significantly challenges\nrobustness to problem complexity and lexical shift.",
      "authors": [
        "Cassie Huang",
        "Stuti Mohan",
        "Ziyi Yang",
        "Stefanie Tellex",
        "Li Zhang"
      ],
      "published": "2025-10-07T01:04:08Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05486v1",
      "primary_area": "text_models",
      "secondary_focus": "reasoning",
      "application_domain": "general_purpose",
      "tldr_zh": "本文研究语言模型在约束条件下的规划能力，通过为现有基准添加细粒度自然语言约束，发现约束使LLM规划性能下降一半，并显著挑战其对问题复杂性和词汇变化的鲁棒性。",
      "order": 55,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05486v1"
    },
    {
      "arxiv_id": "2510.05485v1",
      "title": "TensorBLEU: Vectorized GPU-based BLEU Score Implementation for\n  Per-Sentence In-Training Evaluation",
      "summary": "Modern natural language processing models have achieved unprecedented scale,\nyet the tools for their evaluation often remain a computational bottleneck,\nlimiting the pace of research. This is particularly acute for in-training\nevaluation metrics, such as per-sentence reward signals in Reinforcement\nLearning, which must operate efficiently on batches of token IDs directly on\nthe GPU. In this paper, we introduce TensorBLEU, a novel implementation of the\nBLEU metric designed from the ground up for this specific use case. Our\napproach is fully vectorized for GPU-accelerated, per-sentence computation\nwithin PyTorch and introduces a memory-efficient counting mechanism. By\ncreating a compact, batch-specific dictionary of n-grams using\n\\texttt{torch.unique}, our method avoids the prohibitive memory costs of\ntraditional hashing-based vectorization, making it practical for\nlarge-vocabulary models. We benchmark TensorBLEU against NLTK, the standard\nlibrary for token-ID-based BLEU calculation on the CPU. Experiments show that\nTensorBLEU provides speedups of over 13x on consumer-grade GPUs (NVIDIA T4) and\nexceeding 40x on data-center-class hardware (NVIDIA A100). This performance\ntransforms a significant bottleneck into a negligible part of the training\nloop. By clearly defining its role as a \"Token-ID BLEU\" for development\npurposes and open-sourcing our implementation, we provide a powerful tool for\naccelerating research in areas like RL-based model fine-tuning.",
      "authors": [
        "Adam Filipek"
      ],
      "published": "2025-10-07T01:02:46Z",
      "primary_category": "cs.CL",
      "arxiv_url": "https://arxiv.org/abs/2510.05485v1",
      "primary_area": "text_models",
      "secondary_focus": "training_optimization",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出TensorBLEU，一种专为GPU优化的向量化BLEU评分实现，支持在训练过程中进行逐句评估。通过使用torch.unique创建紧凑的n-gram字典，避免了传统哈希方法的内存瓶颈，在消费级GPU上实现13倍加速，数据中心级硬件上超过40倍加速，显著提升了NLP模型训练效率。",
      "order": 56,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05485v1"
    },
    {
      "arxiv_id": "2510.06219v1",
      "title": "Human3R: Everyone Everywhere All at Once",
      "summary": "We present Human3R, a unified, feed-forward framework for online 4D\nhuman-scene reconstruction, in the world frame, from casually captured\nmonocular videos. Unlike previous approaches that rely on multi-stage\npipelines, iterative contact-aware refinement between humans and scenes, and\nheavy dependencies, e.g., human detection, depth estimation, and SLAM\npre-processing, Human3R jointly recovers global multi-person SMPL-X bodies\n(\"everyone\"), dense 3D scene (\"everywhere\"), and camera trajectories in a\nsingle forward pass (\"all-at-once\"). Our method builds upon the 4D online\nreconstruction model CUT3R, and uses parameter-efficient visual prompt tuning,\nto strive to preserve CUT3R's rich spatiotemporal priors, while enabling direct\nreadout of multiple SMPL-X bodies. Human3R is a unified model that eliminates\nheavy dependencies and iterative refinement. After being trained on the\nrelatively small-scale synthetic dataset BEDLAM for just one day on one GPU, it\nachieves superior performance with remarkable efficiency: it reconstructs\nmultiple humans in a one-shot manner, along with 3D scenes, in one stage, at\nreal-time speed (15 FPS) with a low memory footprint (8 GB). Extensive\nexperiments demonstrate that Human3R delivers state-of-the-art or competitive\nperformance across tasks, including global human motion estimation, local human\nmesh recovery, video depth estimation, and camera pose estimation, with a\nsingle unified model. We hope that Human3R will serve as a simple yet strong\nbaseline, be easily extended for downstream applications.Code available in\nhttps://fanegg.github.io/Human3R",
      "authors": [
        "Yue Chen",
        "Xingyu Chen",
        "Yuxuan Xue",
        "Anpei Chen",
        "Yuliang Xiu",
        "Gerard Pons-Moll"
      ],
      "published": "2025-10-07T17:59:52Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06219v1",
      "primary_area": "video_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "Human3R提出了一种单目视频实时4D人场景重建框架，通过前馈网络一次性恢复多人人体模型、密集3D场景和相机轨迹，无需多阶段流程或迭代优化，在单GPU训练一天后即可达到15FPS实时性能。",
      "order": 57,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06219v1"
    },
    {
      "arxiv_id": "2510.06218v1",
      "title": "EgoNight: Towards Egocentric Vision Understanding at Night with a\n  Challenging Benchmark",
      "summary": "Most existing benchmarks for egocentric vision understanding focus primarily\non daytime scenarios, overlooking the low-light conditions that are inevitable\nin real-world applications. To investigate this gap, we present EgoNight, the\nfirst comprehensive benchmark for nighttime egocentric vision, with visual\nquestion answering (VQA) as the core task. A key feature of EgoNight is the\nintroduction of day-night aligned videos, which enhance night annotation\nquality using the daytime data and reveal clear performance gaps between\nlighting conditions. To achieve this, we collect both synthetic videos rendered\nby Blender and real-world recordings, ensuring that scenes and actions are\nvisually and temporally aligned. Leveraging these paired videos, we construct\nEgoNight-VQA, supported by a novel day-augmented night auto-labeling engine and\nrefinement through extensive human verification. Each QA pair is double-checked\nby annotators for reliability. In total, EgoNight-VQA contains 3658 QA pairs\nacross 90 videos, spanning 12 diverse QA types, with more than 300 hours of\nhuman work. Evaluations of state-of-the-art multimodal large language models\n(MLLMs) reveal substantial performance drops when transferring from day to\nnight, underscoring the challenges of reasoning under low-light conditions.\nBeyond VQA, EgoNight also introduces two auxiliary tasks, day-night\ncorrespondence retrieval and egocentric depth estimation at night, that further\nexplore the boundaries of existing models. We believe EgoNight-VQA provides a\nstrong foundation for advancing application-driven egocentric vision research\nand for developing models that generalize across illumination domains. All the\ndata and code will be made available upon acceptance.",
      "authors": [
        "Deheng Zhang",
        "Yuqian Fu",
        "Runyi Yang",
        "Yang Miao",
        "Tianwen Qian",
        "Xu Zheng",
        "Guolei Sun",
        "Ajad Chhatkuli",
        "Xuanjing Huang",
        "Yu-Gang Jiang",
        "Luc Van Gool",
        "Danda Pani Paudel"
      ],
      "published": "2025-10-07T17:59:47Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06218v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['reasoning', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出EgoNight——首个夜间第一人称视觉理解基准，核心任务为视觉问答(VQA)。通过昼夜对齐视频数据(含合成与真实录制)，构建包含3658个QA对的数据集，并引入昼夜对应检索与深度估计两个辅助任务。实验显示现有多模态大模型在夜间条件下性能显著下降，凸显低光照推理的挑战性。",
      "order": 58,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06218v1"
    },
    {
      "arxiv_id": "2510.06216v1",
      "title": "Dropping the D: RGB-D SLAM Without the Depth Sensor",
      "summary": "We present DropD-SLAM, a real-time monocular SLAM system that achieves\nRGB-D-level accuracy without relying on depth sensors. The system replaces\nactive depth input with three pretrained vision modules: a monocular metric\ndepth estimator, a learned keypoint detector, and an instance segmentation\nnetwork. Dynamic objects are suppressed using dilated instance masks, while\nstatic keypoints are assigned predicted depth values and backprojected into 3D\nto form metrically scaled features. These are processed by an unmodified RGB-D\nSLAM back end for tracking and mapping. On the TUM RGB-D benchmark, DropD-SLAM\nattains 7.4 cm mean ATE on static sequences and 1.8 cm on dynamic sequences,\nmatching or surpassing state-of-the-art RGB-D methods while operating at 22 FPS\non a single GPU. These results suggest that modern pretrained vision models can\nreplace active depth sensors as reliable, real-time sources of metric scale,\nmarking a step toward simpler and more cost-effective SLAM systems.",
      "authors": [
        "Mert Kiray",
        "Alican Karaomer",
        "Benjamin Busam"
      ],
      "published": "2025-10-07T17:59:30Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06216v1",
      "primary_area": "vla_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出DropD-SLAM系统，通过三个预训练视觉模块（单目深度估计、关键点检测、实例分割）替代深度传感器，在TUM RGB-D基准测试中达到与RGB-D方法相当的精度（静态序列7.4cm，动态序列1.8cm），运行速度22FPS，为低成本SLAM系统提供了新方案。",
      "order": 59,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06216v1"
    },
    {
      "arxiv_id": "2510.06215v1",
      "title": "Fine-grained Defocus Blur Control for Generative Image Models",
      "summary": "Current text-to-image diffusion models excel at generating diverse,\nhigh-quality images, yet they struggle to incorporate fine-grained camera\nmetadata such as precise aperture settings. In this work, we introduce a novel\ntext-to-image diffusion framework that leverages camera metadata, or EXIF data,\nwhich is often embedded in image files, with an emphasis on generating\ncontrollable lens blur. Our method mimics the physical image formation process\nby first generating an all-in-focus image, estimating its monocular depth,\npredicting a plausible focus distance with a novel focus distance transformer,\nand then forming a defocused image with an existing differentiable lens blur\nmodel. Gradients flow backwards through this whole process, allowing us to\nlearn without explicit supervision to generate defocus effects based on content\nelements and the provided EXIF data. At inference time, this enables precise\ninteractive user control over defocus effects while preserving scene contents,\nwhich is not achievable with existing diffusion models. Experimental results\ndemonstrate that our model enables superior fine-grained control without\naltering the depicted scene.",
      "authors": [
        "Ayush Shrivastava",
        "Connelly Barnes",
        "Xuaner Zhang",
        "Lingzhi Zhang",
        "Andrew Owens",
        "Sohrab Amirghodsi",
        "Eli Shechtman"
      ],
      "published": "2025-10-07T17:59:15Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06215v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种新颖的文本到图像扩散框架，通过利用相机EXIF元数据实现精细化的镜头模糊控制。该方法模拟物理成像过程：首先生成全焦图像，估计单目深度，通过创新的焦点距离变换器预测合理焦距，最后使用可微分镜头模糊模型生成散焦图像。无需显式监督即可基于内容元素和EXIF数据学习散焦效果，在推理时实现不改变场景内容的精确交互式散焦控制。",
      "order": 60,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06215v1"
    },
    {
      "arxiv_id": "2510.06209v1",
      "title": "Drive&Gen: Co-Evaluating End-to-End Driving and Video Generation Models",
      "summary": "Recent advances in generative models have sparked exciting new possibilities\nin the field of autonomous vehicles. Specifically, video generation models are\nnow being explored as controllable virtual testing environments.\nSimultaneously, end-to-end (E2E) driving models have emerged as a streamlined\nalternative to conventional modular autonomous driving systems, gaining\npopularity for their simplicity and scalability. However, the application of\nthese techniques to simulation and planning raises important questions. First,\nwhile video generation models can generate increasingly realistic videos, can\nthese videos faithfully adhere to the specified conditions and be realistic\nenough for E2E autonomous planner evaluation? Second, given that data is\ncrucial for understanding and controlling E2E planners, how can we gain deeper\ninsights into their biases and improve their ability to generalize to\nout-of-distribution scenarios? In this work, we bridge the gap between the\ndriving models and generative world models (Drive&Gen) to address these\nquestions. We propose novel statistical measures leveraging E2E drivers to\nevaluate the realism of generated videos. By exploiting the controllability of\nthe video generation model, we conduct targeted experiments to investigate\ndistribution gaps affecting E2E planner performance. Finally, we show that\nsynthetic data produced by the video generation model offers a cost-effective\nalternative to real-world data collection. This synthetic data effectively\nimproves E2E model generalization beyond existing Operational Design Domains,\nfacilitating the expansion of autonomous vehicle services into new operational\ncontexts.",
      "authors": [
        "Jiahao Wang",
        "Zhenpei Yang",
        "Yijing Bai",
        "Yingwei Li",
        "Yuliang Zou",
        "Bo Sun",
        "Abhijit Kundu",
        "Jose Lezama",
        "Luna Yue Huang",
        "Zehao Zhu",
        "Jyh-Jing Hwang",
        "Dragomir Anguelov",
        "Mingxing Tan",
        "Chiyu Max Jiang"
      ],
      "published": "2025-10-07T17:58:32Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06209v1",
      "primary_area": "video_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出Drive&Gen框架，通过端到端驾驶模型评估生成视频的真实性，并利用可控视频生成探索分布差距对自动驾驶规划器的影响。研究表明生成视频数据可有效替代真实数据收集，提升模型在未知场景的泛化能力，为自动驾驶测试提供经济高效的解决方案。",
      "order": 61,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06209v1"
    },
    {
      "arxiv_id": "2510.06208v1",
      "title": "ShapeGen4D: Towards High Quality 4D Shape Generation from Videos",
      "summary": "Video-conditioned 4D shape generation aims to recover time-varying 3D\ngeometry and view-consistent appearance directly from an input video. In this\nwork, we introduce a native video-to-4D shape generation framework that\nsynthesizes a single dynamic 3D representation end-to-end from the video. Our\nframework introduces three key components based on large-scale pre-trained 3D\nmodels: (i) a temporal attention that conditions generation on all frames while\nproducing a time-indexed dynamic representation; (ii) a time-aware point\nsampling and 4D latent anchoring that promote temporally consistent geometry\nand texture; and (iii) noise sharing across frames to enhance temporal\nstability. Our method accurately captures non-rigid motion, volume changes, and\neven topological transitions without per-frame optimization. Across diverse\nin-the-wild videos, our method improves robustness and perceptual fidelity and\nreduces failure modes compared with the baselines.",
      "authors": [
        "Jiraphon Yenphraphai",
        "Ashkan Mirzaei",
        "Jianqi Chen",
        "Jiaxu Zou",
        "Sergey Tulyakov",
        "Raymond A. Yeh",
        "Peter Wonka",
        "Chaoyang Wang"
      ],
      "published": "2025-10-07T17:58:11Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06208v1",
      "primary_area": "video_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出ShapeGen4D框架，直接从视频端到端生成动态4D形状。基于预训练3D模型，引入时序注意力、时间感知点采样和4D潜在锚定、帧间噪声共享三大组件，能够准确捕捉非刚性运动、体积变化甚至拓扑转换，无需逐帧优化，在多样真实视频中展现出更高的鲁棒性和感知质量。",
      "order": 62,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06208v1"
    },
    {
      "arxiv_id": "2510.06145v1",
      "title": "Bimanual 3D Hand Motion and Articulation Forecasting in Everyday Images",
      "summary": "We tackle the problem of forecasting bimanual 3D hand motion & articulation\nfrom a single image in everyday settings. To address the lack of 3D hand\nannotations in diverse settings, we design an annotation pipeline consisting of\na diffusion model to lift 2D hand keypoint sequences to 4D hand motion. For the\nforecasting model, we adopt a diffusion loss to account for the multimodality\nin hand motion distribution. Extensive experiments across 6 datasets show the\nbenefits of training on diverse data with imputed labels (14% improvement) and\neffectiveness of our lifting (42% better) & forecasting (16.4% gain) models,\nover the best baselines, especially in zero-shot generalization to everyday\nimages.",
      "authors": [
        "Aditya Prakash",
        "David Forsyth",
        "Saurabh Gupta"
      ],
      "published": "2025-10-07T17:18:56Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06145v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出从单张日常图像预测双手3D运动与关节姿态的方法。针对多样场景下3D标注数据缺乏的问题，设计了基于扩散模型的标注流程，将2D手部关键点序列提升至4D手部运动。预测模型采用扩散损失处理运动分布的多模态特性。在6个数据集上的实验表明，使用增强标注数据的训练效果提升14%，提升模型性能优于基线42%，预测模型增益达16.4%，在零样本泛化至日常图像时表现优异。",
      "order": 63,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06145v1"
    },
    {
      "arxiv_id": "2510.06139v1",
      "title": "Deforming Videos to Masks: Flow Matching for Referring Video\n  Segmentation",
      "summary": "Referring Video Object Segmentation (RVOS) requires segmenting specific\nobjects in a video guided by a natural language description. The core challenge\nof RVOS is to anchor abstract linguistic concepts onto a specific set of pixels\nand continuously segment them through the complex dynamics of a video. Faced\nwith this difficulty, prior work has often decomposed the task into a pragmatic\n`locate-then-segment' pipeline. However, this cascaded design creates an\ninformation bottleneck by simplifying semantics into coarse geometric prompts\n(e.g, point), and struggles to maintain temporal consistency as the segmenting\nprocess is often decoupled from the initial language grounding. To overcome\nthese fundamental limitations, we propose FlowRVS, a novel framework that\nreconceptualizes RVOS as a conditional continuous flow problem. This allows us\nto harness the inherent strengths of pretrained T2V models, fine-grained pixel\ncontrol, text-video semantic alignment, and temporal coherence. Instead of\nconventional generating from noise to mask or directly predicting mask, we\nreformulate the task by learning a direct, language-guided deformation from a\nvideo's holistic representation to its target mask. Our one-stage, generative\napproach achieves new state-of-the-art results across all major RVOS\nbenchmarks. Specifically, achieving a $\\mathcal{J}\\&\\mathcal{F}$ of 51.1 in\nMeViS (+1.6 over prior SOTA) and 73.3 in the zero shot Ref-DAVIS17 (+2.7),\ndemonstrating the significant potential of modeling video understanding tasks\nas continuous deformation processes.",
      "authors": [
        "Zanyi Wang",
        "Dengyang Jiang",
        "Liuzhuozheng Li",
        "Sizhe Dang",
        "Chengzu Li",
        "Harry Yang",
        "Guang Dai",
        "Mengmeng Wang",
        "Jingdong Wang"
      ],
      "published": "2025-10-07T17:14:10Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06139v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['model_architecture', 'video_models']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出FlowRVS框架，将指代视频分割任务重新定义为条件连续流问题，通过语言引导的视频到掩码变形方法，在多个基准测试中达到最先进性能，显著优于传统的'定位-分割'级联方法。",
      "order": 64,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06139v1"
    },
    {
      "arxiv_id": "2510.06131v1",
      "title": "Discrete Diffusion Models with MLLMs for Unified Medical Multimodal\n  Generation",
      "summary": "Recent advances in generative medical models are constrained by\nmodality-specific scenarios that hinder the integration of complementary\nevidence from imaging, pathology, and clinical notes. This fragmentation limits\ntheir evolution into foundation models that can learn and reason across the\nfull spectrum of biomedical data. We propose MeDiM, the first medical discrete\ndiffusion model that learns shared distributions across modalities without\nmodality-specific components. MeDiM unifies multiple generative tasks:\ntranslating between images and text, and jointly producing image-report pairs\nacross domains in response to prompts. Built on a discrete diffusion framework,\nMeDiM bridges vision and language representations through a shared\nprobabilistic space. To enable unified and flexible medical generation, we\nemploy a multimodal large language model (MLLM) as the diffusion backbone,\nleveraging its prior knowledge and cross-modal reasoning. Two key designs are\nintroduced: (1) removing the causal attention mask for bidirectional context,\nand (2) injecting continuous timestep embeddings for diffusion awareness.\nExperiments demonstrate high-fidelity medical generation (FID 16.60 on\nMIMIC-CXR and FID 24.19 on PathGen) and accurate report generation (METEOR\n0.2650 and 0.2580). Jointly generated image-report pairs further enhance\ndownstream performance (plus6.43 percent BLEU-1, plus18.57 percent BLEU-2,\nplus31.58 percent BLEU-3, plus4.80 percent METEOR), showing that MeDiM supports\ncoherent and clinically grounded multimodal outputs.",
      "authors": [
        "Jiawei Mao",
        "Yuhan Wang",
        "Lifeng Chen",
        "Can Zhao",
        "Yucheng Tang",
        "Dong Yang",
        "Liangqiong Qu",
        "Daguang Xu",
        "Yuyin Zhou"
      ],
      "published": "2025-10-07T17:06:57Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06131v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['model_architecture', 'diffusion_models']",
      "application_domain": "medical_ai",
      "tldr_zh": "本文提出MeDiM，首个医学离散扩散模型，通过共享概率空间统一学习多模态分布，无需特定模态组件。采用多模态大语言模型作为扩散主干，实现图像-文本互转和联合生成图像-报告对，在医学影像和病理数据上取得高保真生成效果，显著提升下游任务性能。",
      "order": 65,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06131v1"
    },
    {
      "arxiv_id": "2510.06123v1",
      "title": "Towards Data-Efficient Medical Imaging: A Generative and Semi-Supervised\n  Framework",
      "summary": "Deep learning in medical imaging is often limited by scarce and imbalanced\nannotated data. We present SSGNet, a unified framework that combines class\nspecific generative modeling with iterative semisupervised pseudo labeling to\nenhance both classification and segmentation. Rather than functioning as a\nstandalone model, SSGNet augments existing baselines by expanding training data\nwith StyleGAN3 generated images and refining labels through iterative pseudo\nlabeling. Experiments across multiple medical imaging benchmarks demonstrate\nconsistent gains in classification and segmentation performance, while Frechet\nInception Distance analysis confirms the high quality of generated samples.\nThese results highlight SSGNet as a practical strategy to mitigate annotation\nbottlenecks and improve robustness in medical image analysis.",
      "authors": [
        "Mosong Ma",
        "Tania Stathaki",
        "Michalis Lazarou"
      ],
      "published": "2025-10-07T17:03:05Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06123v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "['training_optimization', 'model_architecture']",
      "application_domain": "medical_ai",
      "tldr_zh": "本文提出SSGNet框架，通过结合类别特定生成建模与迭代半监督伪标注技术，解决医学影像中标注数据稀缺和类别不平衡问题。该框架利用StyleGAN3生成图像扩充训练数据，并通过迭代伪标注优化标签质量，在多个医学影像基准测试中显著提升了分类和分割性能，为医学图像分析提供了一种实用的数据效率提升方案。",
      "order": 66,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06123v1"
    },
    {
      "arxiv_id": "2510.06113v1",
      "title": "Multimodal Feature Prototype Learning for Interpretable and\n  Discriminative Cancer Survival Prediction",
      "summary": "Survival analysis plays a vital role in making clinical decisions. However,\nthe models currently in use are often difficult to interpret, which reduces\ntheir usefulness in clinical settings. Prototype learning presents a potential\nsolution, yet traditional methods focus on local similarities and static\nmatching, neglecting the broader tumor context and lacking strong semantic\nalignment with genomic data. To overcome these issues, we introduce an\ninnovative prototype-based multimodal framework, FeatProto, aimed at enhancing\ncancer survival prediction by addressing significant limitations in current\nprototype learning methodologies within pathology. Our framework establishes a\nunified feature prototype space that integrates both global and local features\nof whole slide images (WSI) with genomic profiles. This integration facilitates\ntraceable and interpretable decision-making processes. Our approach includes\nthree main innovations: (1) A robust phenotype representation that merges\ncritical patches with global context, harmonized with genomic data to minimize\nlocal bias. (2) An Exponential Prototype Update Strategy (EMA ProtoUp) that\nsustains stable cross-modal associations and employs a wandering mechanism to\nadapt prototypes flexibly to tumor heterogeneity. (3) A hierarchical prototype\nmatching scheme designed to capture global centrality, local typicality, and\ncohort-level trends, thereby refining prototype inference. Comprehensive\nevaluations on four publicly available cancer datasets indicate that our method\nsurpasses current leading unimodal and multimodal survival prediction\ntechniques in both accuracy and interoperability, providing a new perspective\non prototype learning for critical medical applications. Our source code is\navailable at https://github.com/JSLiam94/FeatProto.",
      "authors": [
        "Shuo Jiang",
        "Zhuwen Chen",
        "Liaoman Xu",
        "Yanming Zhu",
        "Changmiao Wang",
        "Jiong Zhang",
        "Feiwei Qin",
        "Yifei Chen",
        "Zhu Zhu"
      ],
      "published": "2025-10-07T16:49:52Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06113v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "model_architecture",
      "application_domain": "medical_ai",
      "tldr_zh": "本文提出FeatProto框架，通过构建统一特征原型空间整合病理图像全局/局部特征与基因组数据，采用指数原型更新策略和分层匹配机制，显著提升癌症生存预测的准确性和可解释性，在四个公开数据集上超越现有方法。",
      "order": 67,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06113v1"
    },
    {
      "arxiv_id": "2510.06098v1",
      "title": "Compact Multi-level-prior Tensor Representation for Hyperspectral Image\n  Super-resolution",
      "summary": "Fusing a hyperspectral image with a multispectral image acquired over the\nsame scene, \\textit{i.e.}, hyperspectral image super-resolution, has become a\npopular computational way to access the latent high-spatial-spectral-resolution\nimage. To date, a variety of fusion methods have been proposed, among which the\ntensor-based ones have testified that multiple priors, such as multidimensional\nlow-rankness and spatial total variation at multiple levels, effectively drive\nthe fusion process. However, existing tensor-based models can only effectively\nleverage one or two priors at one or two levels, since simultaneously\nincorporating multi-level priors inevitably increases model complexity. This\nintroduces challenges in both balancing the weights of different priors and\noptimizing multi-block structures. Concerning this, we present a novel\nhyperspectral super-resolution model compactly characterizing these multi-level\npriors of hyperspectral images within the tensor framework. Firstly, the\nproposed model decouples the spectral low-rankness and spatial priors by\ncasting the latent high-spatial-spectral-resolution image into spectral\nsubspace and spatial maps via block term decomposition. Secondly, these spatial\nmaps are stacked as the spatial tensor encoding the high-order spatial\nlow-rankness and smoothness priors, which are co-modeled via the proposed\nnon-convex mode-shuffled tensor correlated total variation. Finally, we draw\ninspiration from the linearized alternating direction method of multipliers to\ndesign an efficient algorithm to optimize the resulting model, theoretically\nproving its Karush-Kuhn-Tucker convergence under mild conditions. Experiments\non multiple datasets demonstrate the effectiveness of the proposed algorithm.\nThe code implementation will be available from https://github.com/WongYinJ.",
      "authors": [
        "Yinjian Wang",
        "Wei Li",
        "Yuanyuan Gui",
        "Gemine Vivone"
      ],
      "published": "2025-10-07T16:26:34Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06098v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种紧凑的多级先验张量表示方法，用于高光谱图像超分辨率。通过块项分解将图像解耦到光谱子空间和空间映射，并利用非凸模式混洗张量相关总变分共同建模高阶空间低秩性和平滑性先验。实验证明该方法在多个数据集上有效提升了融合性能。",
      "order": 68,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06098v1"
    },
    {
      "arxiv_id": "2510.06090v1",
      "title": "A public cardiac CT dataset featuring the left atrial appendage",
      "summary": "Despite the success of advanced segmentation frameworks such as\nTotalSegmentator (TS), accurate segmentations of the left atrial appendage\n(LAA), coronary arteries (CAs), and pulmonary veins (PVs) remain a significant\nchallenge in medical imaging. In this work, we present the first open-source,\nanatomically coherent dataset of curated, high-resolution segmentations for\nthese structures, supplemented with whole-heart labels produced by TS on the\npublicly available ImageCAS dataset consisting of 1000 cardiac computed\ntomography angiography (CCTA) scans. One purpose of the data set is to foster\nnovel approaches to the analysis of LAA morphology.\n  LAA segmentations on ImageCAS were generated using a state-of-the-art\nsegmentation framework developed specifically for high resolution LAA\nsegmentation. We trained the network on a large private dataset with manual\nannotations provided by medical readers guided by a trained cardiologist and\ntransferred the model to ImageCAS data. CA labels were improved from the\noriginal ImageCAS annotations, while PV segmentations were refined from TS\noutputs. In addition, we provide a list of scans from ImageCAS that contains\ncommon data flaws such as step artefacts, LAAs extending beyond the scanner's\nfield of view, and other types of data defects.",
      "authors": [
        "Bjoern Hansen",
        "Jonas Pedersen",
        "Klaus F. Kofoed",
        "Oscar Camara",
        "Rasmus R. Paulsen",
        "Kristine Soerensen"
      ],
      "published": "2025-10-07T16:16:59Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06090v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "tech_reports",
      "application_domain": "medical_ai",
      "tldr_zh": "本研究发布了首个开源的心脏CT数据集，专门针对左心耳、冠状动脉和肺静脉提供高质量分割标注。该数据集基于公开的ImageCAS数据集，包含1000例心脏CTA扫描，通过先进分割框架生成解剖结构一致的标注，旨在促进左心耳形态分析研究，并标注了常见数据缺陷。",
      "order": 69,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06090v1"
    },
    {
      "arxiv_id": "2510.06077v1",
      "title": "When Thinking Drifts: Evidential Grounding for Robust Video Reasoning",
      "summary": "Video reasoning, the task of enabling machines to infer from dynamic visual\ncontent through multi-step logic, is crucial for advanced AI. While the\nChain-of-Thought (CoT) mechanism has enhanced reasoning in text-based tasks,\nits application to video understanding remains underexplored. This paper\npresents a systematic analysis revealing that CoT often degrades performance in\nvideo reasoning, generating verbose but misleading internal monologues, and\nleading to hallucinated visual details and overridden correct intuitions - a\nphenomenon we term \"visual thinking drift\". We explain this drift through a\nBayesian lens, positing that CoT traces often diverge from actual visual\nevidence, instead amplifying internal biases or language priors, causing models\nto storytell rather than engage in grounded reasoning. To counteract this, we\nintroduce Visual Evidence Reward (VER), a novel reinforcement learning\nframework that explicitly rewards the generation of reasoning traces that are\nverifiably grounded in visual evidence. Comprehensive evaluation across 10\ndiverse video understanding benchmarks demonstrates that our Video-VER\nconsistently achieves top performance. Our work sheds light on the distinct\nchallenges of video-centric reasoning and encourages the development of AI that\nrobustly grounds its inferences in visual evidence - for large multimodal\nmodels that not only \"think before answering\", but also \"see while thinking\".",
      "authors": [
        "Mi Luo",
        "Zihui Xue",
        "Alex Dimakis",
        "Kristen Grauman"
      ],
      "published": "2025-10-07T16:03:33Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06077v1",
      "primary_area": "video_models",
      "secondary_focus": "['reasoning', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文发现思维链机制在视频推理中会产生'视觉思维漂移'现象，导致模型生成与视觉证据脱节的推理过程。作者提出视觉证据奖励框架，通过强化学习确保推理轨迹基于实际视觉内容，在10个视频理解基准测试中取得最优性能。",
      "order": 70,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06077v1"
    },
    {
      "arxiv_id": "2510.06070v1",
      "title": "There is More to Attention: Statistical Filtering Enhances Explanations\n  in Vision Transformers",
      "summary": "Explainable AI (XAI) has become increasingly important with the rise of large\ntransformer models, yet many explanation methods designed for CNNs transfer\npoorly to Vision Transformers (ViTs). Existing ViT explanations often rely on\nattention weights, which tend to yield noisy maps as they capture\ntoken-to-token interactions within each layer.While attribution methods\nincorporating MLP blocks have been proposed, we argue that attention remains a\nvaluable and interpretable signal when properly filtered. We propose a method\nthat combines attention maps with a statistical filtering, initially proposed\nfor CNNs, to remove noisy or uninformative patterns and produce more faithful\nexplanations. We further extend our approach with a class-specific variant that\nyields discriminative explanations. Evaluation against popular state-of-the-art\nmethods demonstrates that our approach produces sharper and more interpretable\nmaps. In addition to perturbation-based faithfulness metrics, we incorporate\nhuman gaze data to assess alignment with human perception, arguing that human\ninterpretability remains essential for XAI. Across multiple datasets, our\napproach consistently outperforms or is comparable to the SOTA methods while\nremaining efficient and human plausible.",
      "authors": [
        "Meghna P Ayyar",
        "Jenny Benois-Pineau",
        "Akka Zemmari"
      ],
      "published": "2025-10-07T15:59:04Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06070v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种针对视觉Transformer的注意力统计滤波方法，通过过滤噪声模式生成更忠实、更符合人类感知的解释图。该方法在多个数据集上优于或媲美现有技术，同时保持高效性和人类可解释性。",
      "order": 71,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06070v1"
    },
    {
      "arxiv_id": "2510.06067v1",
      "title": "Reasoning under Vision: Understanding Visual-Spatial Cognition in\n  Vision-Language Models for CAPTCHA",
      "summary": "CAPTCHA, originally designed to distinguish humans from robots, has evolved\ninto a real-world benchmark for assessing the spatial reasoning capabilities of\nvision-language models. In this work, we first show that step-by-step reasoning\nis crucial for vision-language models (VLMs) to solve CAPTCHAs, which represent\nhigh-difficulty spatial reasoning tasks, and that current commercial\nvision-language models still struggle with such reasoning. In particular, we\nobserve that most commercial VLMs (e.g., Gemini, Claude, GPT, etc.) fail to\neffectively solve CAPTCHAs and thus achieve low accuracy (around 21.9 percent).\nHowever, our findings indicate that requiring the model to perform step-by-step\nreasoning before generating the final coordinates can significantly enhance its\nsolving accuracy, underscoring the severity of the gap. To systematically study\nthis issue, we introduce CAPTCHA-X, the first real-world CAPTCHA benchmark with\nreasoning, covering seven categories of CAPTCHAs (such as Gobang, hCaptcha,\netc.) with step-by-step action solutions and grounding annotations. We further\ndefine five reasoning-oriented metrics that enable a comprehensive evaluation\nof models reasoning capabilities. To validate the effectiveness of reasoning,\nwe also propose a general agentic VLM-based framework that incorporates the\nmodels inherent reasoning abilities. Our method achieves state-of-the-art\nperformance across five high-difficulty CAPTCHA types, with an average solving\naccuracy of 83.9 percent, substantially surpassing existing baselines. These\nresults reveal the limitations of current models and highlight the importance\nof reasoning in advancing visual-spatial challenges in the future.",
      "authors": [
        "Python Song",
        "Luke Tenyi Chang",
        "Yun-Yun Tsai",
        "Penghui Li",
        "Junfeng Yang"
      ],
      "published": "2025-10-07T15:56:21Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06067v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "reasoning",
      "application_domain": "general_purpose",
      "tldr_zh": "本研究将CAPTCHA作为评估视觉语言模型空间推理能力的基准，发现现有商业模型在解决CAPTCHA任务时准确率仅21.9%。通过引入逐步推理机制，模型性能显著提升至83.9%。论文提出了首个带推理标注的真实CAPTCHA基准CAPTCHA-X和五类评估指标，揭示了当前模型在视觉空间推理方面的局限性。",
      "order": 72,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06067v1"
    },
    {
      "arxiv_id": "2510.06064v1",
      "title": "Medical Vision Language Models as Policies for Robotic Surgery",
      "summary": "Vision-based Proximal Policy Optimization (PPO) struggles with visual\nobservation-based robotic laparoscopic surgical tasks due to the\nhigh-dimensional nature of visual input, the sparsity of rewards in surgical\nenvironments, and the difficulty of extracting task-relevant features from raw\nvisual data. We introduce a simple approach integrating MedFlamingo, a medical\ndomain-specific Vision-Language Model, with PPO. Our method is evaluated on\nfive diverse laparoscopic surgery task environments in LapGym, using only\nendoscopic visual observations. MedFlamingo PPO outperforms and converges\nfaster compared to both standard vision-based PPO and OpenFlamingo PPO\nbaselines, achieving task success rates exceeding 70% across all environments,\nwith improvements ranging from 66.67% to 1114.29% compared to baseline. By\nprocessing task observations and instructions once per episode to generate\nhigh-level planning tokens, our method efficiently combines medical expertise\nwith real-time visual feedback. Our results highlight the value of specialized\nmedical knowledge in robotic surgical planning and decision-making.",
      "authors": [
        "Akshay Muppidi",
        "Martin Radfar"
      ],
      "published": "2025-10-07T15:54:34Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06064v1",
      "primary_area": "vla_models",
      "secondary_focus": "model_architecture",
      "application_domain": "medical_ai",
      "tldr_zh": "本研究提出将医学专用视觉语言模型MedFlamingo与PPO算法结合，用于机器人腹腔镜手术任务。该方法通过单次处理任务观察和指令生成高级规划令牌，在LapGym五个手术环境中仅使用内窥镜视觉观测，成功率超70%，比基准方法提升66.67%-1114.29%，收敛更快，证明了医学专业知识在机器人手术决策中的价值。",
      "order": 73,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06064v1"
    },
    {
      "arxiv_id": "2510.06046v1",
      "title": "GLVD: Guided Learned Vertex Descent",
      "summary": "Existing 3D face modeling methods usually depend on 3D Morphable Models,\nwhich inherently constrain the representation capacity to fixed shape priors.\nOptimization-based approaches offer high-quality reconstructions but tend to be\ncomputationally expensive. In this work, we introduce GLVD, a hybrid method for\n3D face reconstruction from few-shot images that extends Learned Vertex Descent\n(LVD) by integrating per-vertex neural field optimization with global\nstructural guidance from dynamically predicted 3D keypoints. By incorporating\nrelative spatial encoding, GLVD iteratively refines mesh vertices without\nrequiring dense 3D supervision. This enables expressive and adaptable geometry\nreconstruction while maintaining computational efficiency. GLVD achieves\nstate-of-the-art performance in single-view settings and remains highly\ncompetitive in multi-view scenarios, all while substantially reducing inference\ntime.",
      "authors": [
        "Pol Caselles Rico",
        "Francesc Moreno Noguer"
      ],
      "published": "2025-10-07T15:40:10Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06046v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出GLVD方法，通过结合逐顶点神经场优化与动态预测3D关键点的全局结构引导，改进了学习顶点下降(LVD)算法。该方法无需密集3D监督即可迭代优化网格顶点，在保持计算效率的同时实现高表达力的3D人脸重建，在单视图设置中达到最先进性能，并在多视图场景中保持高度竞争力。",
      "order": 74,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06046v1"
    },
    {
      "arxiv_id": "2510.06040v1",
      "title": "VideoMiner: Iteratively Grounding Key Frames of Hour-Long Videos via\n  Tree-based Group Relative Policy Optimization",
      "summary": "Understanding hour-long videos with multi-modal large language models\n(MM-LLMs) enriches the landscape of human-centered AI applications. However,\nfor end-to-end video understanding with LLMs, uniformly sampling video frames\nresults in LLMs being overwhelmed by a vast amount of irrelevant information as\nvideo length increases. Existing hierarchical key frame extraction methods\nimprove the accuracy of video understanding but still face two critical\nchallenges. 1) How can the interference of extensive redundant information in\nlong videos be mitigated? 2) How can a model dynamically adapt to complex\nhierarchical structures while accurately identifying key frames? To address\nthese issues, we propose VideoMiner, which iteratively segments, captions, and\nclusters long videos, forming a hierarchical tree structure. The proposed\nVideoMiner progresses from long videos to events to frames while preserving\ntemporal coherence, effectively addressing the first challenge. To precisely\nlocate key frames, we introduce T-GRPO, a tree-based group relative policy\noptimization in reinforcement learning method that guides the exploration of\nthe VideoMiner. The proposed T-GRPO is specifically designed for tree\nstructures, integrating spatiotemporal information at the event level while\nbeing guided by the question, thus solving the second challenge. We achieve\nsuperior performance in all long-video understanding tasks and uncover several\ninteresting insights. Our proposed T-GRPO surprisingly incentivizes the model\nto spontaneously generate a reasoning chain. Additionally, the designed tree\ngrowth auxin dynamically adjusts the expansion depth, obtaining accuracy and\nefficiency gains. The code is publicly available at\nhttps://github.com/caoxinye/VideoMiner.",
      "authors": [
        "Xinye Cao",
        "Hongcan Guo",
        "Jiawen Qian",
        "Guoshun Nan",
        "Chao Wang",
        "Yuqi Pan",
        "Tianhao Hou",
        "Xiaojuan Wang",
        "Yutong Gao"
      ],
      "published": "2025-10-07T15:34:46Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06040v1",
      "primary_area": "video_models",
      "secondary_focus": "['model_architecture', 'reasoning', 'long_context']",
      "application_domain": "general_purpose",
      "tldr_zh": "VideoMiner提出一种基于树状结构的分层关键帧定位方法，通过迭代分割、描述和聚类处理小时级长视频，并引入树状分组相对策略优化(T-GRPO)强化学习方法，在保持时序连贯性的同时精准定位关键帧，显著提升长视频理解性能，还能自发生成推理链并动态调整树结构深度。",
      "order": 75,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06040v1"
    },
    {
      "arxiv_id": "2510.06035v1",
      "title": "Universal Neural Architecture Space: Covering ConvNets, Transformers and\n  Everything in Between",
      "summary": "We introduce Universal Neural Architecture Space (UniNAS), a generic search\nspace for neural architecture search (NAS) which unifies convolutional\nnetworks, transformers, and their hybrid architectures under a single, flexible\nframework. Our approach enables discovery of novel architectures as well as\nanalyzing existing architectures in a common framework. We also propose a new\nsearch algorithm that allows traversing the proposed search space, and\ndemonstrate that the space contains interesting architectures, which, when\nusing identical training setup, outperform state-of-the-art hand-crafted\narchitectures. Finally, a unified toolkit including a standardized training and\nevaluation protocol is introduced to foster reproducibility and enable fair\ncomparison in NAS research. Overall, this work opens a pathway towards\nsystematically exploring the full spectrum of neural architectures with a\nunified graph-based NAS perspective.",
      "authors": [
        "Ondřej Týbl",
        "Lukáš Neumann"
      ],
      "published": "2025-10-07T15:31:40Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06035v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出通用神经架构空间(UniNAS)，统一了卷积网络、Transformer及其混合架构的搜索框架，包含新型搜索算法和标准化工具包，在相同训练设置下发现的架构优于现有最优手工设计模型，为系统探索神经网络架构谱系提供了统一途径。",
      "order": 76,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06035v1"
    },
    {
      "arxiv_id": "2510.06026v1",
      "title": "Emergent AI Surveillance: Overlearned Person Re-Identification and Its\n  Mitigation in Law Enforcement Context",
      "summary": "Generic instance search models can dramatically reduce the manual effort\nrequired to analyze vast surveillance footage during criminal investigations by\nretrieving specific objects of interest to law enforcement. However, our\nresearch reveals an unintended emergent capability: through overlearning, these\nmodels can single out specific individuals even when trained on datasets\nwithout human subjects. This capability raises concerns regarding\nidentification and profiling of individuals based on their personal data, while\nthere is currently no clear standard on how de-identification can be achieved.\nWe evaluate two technical safeguards to curtail a model's person\nre-identification capacity: index exclusion and confusion loss. Our experiments\ndemonstrate that combining these approaches can reduce person re-identification\naccuracy to below 2% while maintaining 82% of retrieval performance for\nnon-person objects. However, we identify critical vulnerabilities in these\nmitigations, including potential circumvention using partial person images.\nThese findings highlight urgent regulatory questions at the intersection of AI\ngovernance and data protection: How should we classify and regulate systems\nwith emergent identification capabilities? And what technical standards should\nbe required to prevent identification capabilities from developing in seemingly\nbenign applications?",
      "authors": [
        "An Thi Nguyen",
        "Radina Stoykova",
        "Eric Arazo"
      ],
      "published": "2025-10-07T15:23:16Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06026v1",
      "primary_area": "video_models",
      "secondary_focus": "alignment",
      "application_domain": "legal_ai",
      "tldr_zh": "本文研究发现通用实例搜索模型在执法应用中存在意外涌现能力：即使训练数据不含人物，模型仍能通过过度学习识别特定个体。作者评估了索引排除和混淆损失两种技术防护措施，发现组合使用可将人员重识别准确率降至2%以下，同时保持82%的非人物体检索性能。研究揭示了防护措施的潜在漏洞，并呼吁制定AI治理与数据保护交叉领域的监管标准。",
      "order": 77,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06026v1"
    },
    {
      "arxiv_id": "2510.06009v1",
      "title": "Continual Learning for Image Captioning through Improved Image-Text\n  Alignment",
      "summary": "Generating accurate and coherent image captions in a continual learning\nsetting remains a major challenge due to catastrophic forgetting and the\ndifficulty of aligning evolving visual concepts with language over time. In\nthis work, we propose a novel multi-loss framework for continual image\ncaptioning that integrates semantic guidance through prompt-based continual\nlearning and contrastive alignment. Built upon a pretrained ViT-GPT-2 backbone,\nour approach combines standard cross-entropy loss with three additional\ncomponents: (1) a prompt-based cosine similarity loss that aligns image\nembeddings with synthetically constructed prompts encoding objects, attributes,\nand actions; (2) a CLIP-style loss that promotes alignment between image\nembeddings and target caption embedding; and (3) a language-guided contrastive\nloss that employs a triplet loss to enhance class-level discriminability\nbetween tasks. Notably, our approach introduces no additional overhead at\ninference time and requires no prompts during caption generation. We find that\nthis approach mitigates catastrophic forgetting, while achieving better\nsemantic caption alignment compared to state-of-the-art methods. The code can\nbe found via the following link https://github.com/\nGepardius/Taetz_Bordelius_Continual_ImageCaptioning.",
      "authors": [
        "Bertram Taetz",
        "Gal Bordelius"
      ],
      "published": "2025-10-07T15:08:26Z",
      "primary_category": "cs.CV",
      "arxiv_url": "https://arxiv.org/abs/2510.06009v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['training_optimization', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种持续学习图像描述方法，通过多损失框架结合提示学习和对比对齐，缓解灾难性遗忘问题。在ViT-GPT-2基础上引入余弦相似度损失、CLIP风格损失和语言对比损失，无需推理时额外开销即实现更好的语义对齐效果。",
      "order": 78,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06009v1"
    },
    {
      "arxiv_id": "2510.06214v1",
      "title": "Stratified GRPO: Handling Structural Heterogeneity in Reinforcement\n  Learning of LLM Search Agents",
      "summary": "Large language model (LLM) agents increasingly rely on external tools such as\nsearch engines to solve complex, multi-step problems, and reinforcement\nlearning (RL) has become a key paradigm for training them. However, the\ntrajectories of search agents are structurally heterogeneous, where variations\nin the number, placement, and outcomes of search calls lead to fundamentally\ndifferent answer directions and reward distributions. Standard policy gradient\nmethods, which use a single global baseline, suffer from what we identify and\nformalize as cross-stratum bias-an \"apples-to-oranges\" comparison of\nheterogeneous trajectories. This cross-stratum bias distorts credit assignment\nand hinders exploration of complex, multi-step search strategies. To address\nthis, we propose Stratified GRPO, whose central component, Stratified Advantage\nNormalization (SAN), partitions trajectories into homogeneous strata based on\ntheir structural properties and computes advantages locally within each\nstratum. This ensures that trajectories are evaluated only against their true\npeers. Our analysis proves that SAN eliminates cross-stratum bias, yields\nconditionally unbiased unit-variance estimates inside each stratum, and retains\nthe global unbiasedness and unit-variance properties enjoyed by standard\nnormalization, resulting in a more pure and scale-stable learning signal. To\nimprove practical stability under finite-sample regimes, we further linearly\nblend SAN with the global estimator. Extensive experiments on diverse\nsingle-hop and multi-hop question-answering benchmarks demonstrate that\nStratified GRPO consistently and substantially outperforms GRPO by up to 11.3\npoints, achieving higher training rewards, greater training stability, and more\neffective search policies. These results establish stratification as a\nprincipled remedy for structural heterogeneity in RL for LLM search agents.",
      "authors": [
        "Mingkang Zhu",
        "Xi Chen",
        "Bei Yu",
        "Hengshuang Zhao",
        "Jiaya Jia"
      ],
      "published": "2025-10-07T17:59:13Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06214v1",
      "primary_area": "text_models",
      "secondary_focus": "training_optimization",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出Stratified GRPO方法，通过分层优势归一化(SAN)解决LLM搜索智能体在强化学习中因轨迹结构异质性导致的跨层偏差问题。该方法将轨迹按结构特性分层计算优势值，实验表明在多项问答基准上比GRPO提升高达11.3分，实现了更高的训练奖励、稳定性和更有效的搜索策略。",
      "order": 79,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06214v1"
    },
    {
      "arxiv_id": "2510.06213v1",
      "title": "Training Dynamics Impact Post-Training Quantization Robustness",
      "summary": "While post-training quantization is widely adopted for efficient deployment\nof large language models, the mechanisms underlying quantization robustness\nremain unclear. We conduct a comprehensive analysis of quantization degradation\nacross open-source language model training trajectories up to 32B parameters\nand 15T training tokens to accurately assess the relationship between training\ndynamics and quantization performance. Our key finding is that quantization\nerrors in large-scale training runs are driven by a complex interplay between\nlearning rate and other training hyperparameters. Specifically, once learning\nrates decay, validation loss and quantization error diverge, largely\nindependent of training data scale. To investigate interventions on the\ntraining dynamics and identify specific configurations that can modulate\nquantization robustness favorably, we train our own models in controlled\nexperiments up to 100B tokens. Our results challenge the assumption that\nincreasing dataset scale inherently compromises quantization effectiveness,\ndemonstrating instead that strategic training hyperparameter interventions can\nimprove quantization quality at scale.",
      "authors": [
        "Albert Catalan-Tatjer",
        "Niccolò Ajroldi",
        "Jonas Geiping"
      ],
      "published": "2025-10-07T17:59:07Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06213v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_compression', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文系统研究了训练动态对大型语言模型后训练量化鲁棒性的影响。通过对高达32B参数和15T训练token的模型训练轨迹分析，发现学习率衰减会导致验证损失与量化误差出现分歧。研究挑战了数据集规模增大会损害量化效果的假设，证明通过优化训练超参数可在保持模型规模的同时提升量化质量。",
      "order": 80,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06213v1"
    },
    {
      "arxiv_id": "2510.06203v1",
      "title": "Reference Grounded Skill Discovery",
      "summary": "Scaling unsupervised skill discovery algorithms to high-DoF agents remains\nchallenging. As dimensionality increases, the exploration space grows\nexponentially, while the manifold of meaningful skills remains limited.\nTherefore, semantic meaningfulness becomes essential to effectively guide\nexploration in high-dimensional spaces. In this work, we present\nReference-Grounded Skill Discovery (RGSD), a novel algorithm that grounds skill\ndiscovery in a semantically meaningful latent space using reference data. RGSD\nfirst performs contrastive pretraining to embed motions on a unit hypersphere,\nclustering each reference trajectory into a distinct direction. This grounding\nenables skill discovery to simultaneously involve both imitation of reference\nbehaviors and the discovery of semantically related diverse behaviors. On a\nsimulated SMPL humanoid with 359-D observations and 69-D actions, RGSD learns\nstructured skills including walking, running, punching, and side stepping, and\nalso discovers related novel behaviors. In downstream control tasks, RGSD\noutperforms imitation-based skill acquisition baselines. Our results suggest\nthat lightweight reference-guided grounding offers a practical path to\ndiscovering semantically rich and structured skills in high-DoF systems.",
      "authors": [
        "Seungeun Rho",
        "Aaron Trinh",
        "Danfei Xu",
        "Sehoon Ha"
      ],
      "published": "2025-10-07T17:55:01Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06203v1",
      "primary_area": "vla_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出参考数据驱动的技能发现算法RGSD，通过对比预训练将动作嵌入单位超球面，将参考轨迹聚类为不同方向，在高自由度模拟人形机器人上成功发现了行走、跑步、击拳等结构化技能及相关新行为，在后续控制任务中优于基于模仿的技能获取基线方法。",
      "order": 81,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06203v1"
    },
    {
      "arxiv_id": "2510.06190v1",
      "title": "On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",
      "summary": "This paper formally studies generation processes, including auto-regressive\nnext-token prediction and masked diffusion, that abstract beyond architectural\nspecifics. At this level of abstraction, we quantify their benefits and\nlimitations through measurable criteria such as computational hardness and\nlearnability. In particular, we demonstrate that allowing generation to proceed\nbeyond autoregression and current masked diffusion, with capabilities to\nrewrite and length-variable edit, can bring significant theoretical and\nempirical advantages, with important implications for frontier LLMs that aspire\nto tackle increasingly hard problems and work universally across domains beyond\nnatural language, such as coding and science.",
      "authors": [
        "Chenxiao Yang",
        "Cai Zhou",
        "David Wipf",
        "Zhiyuan Li"
      ],
      "published": "2025-10-07T17:49:30Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06190v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "['model_architecture', 'reasoning']",
      "application_domain": "['general_purpose', 'code_generation']",
      "tldr_zh": "本文从计算复杂度和可学习性等理论角度，系统比较了自回归生成与掩码扩散等生成方法的优劣。研究发现，超越传统自回归和现有扩散模型、支持重写和变长编辑能力的生成范式，在理论和实验上均展现出显著优势，对前沿大语言模型处理代码、科学等跨领域复杂任务具有重要指导意义。",
      "order": 82,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06190v1"
    },
    {
      "arxiv_id": "2510.06181v1",
      "title": "Conformalized Gaussian processes for online uncertainty quantification\n  over graphs",
      "summary": "Uncertainty quantification (UQ) over graphs arises in a number of\nsafety-critical applications in network science. The Gaussian process (GP), as\na classical Bayesian framework for UQ, has been developed to handle\ngraph-structured data by devising topology-aware kernel functions. However,\nsuch GP-based approaches are limited not only by the prohibitive computational\ncomplexity, but also the strict modeling assumptions that might yield poor\ncoverage, especially with labels arriving on the fly. To effect scalability, we\ndevise a novel graph-aware parametric GP model by leveraging the random feature\n(RF)-based kernel approximation, which is amenable to efficient recursive\nBayesian model updates. To further allow for adaptivity, an ensemble of\ngraph-aware RF-based scalable GPs have been leveraged, with per-GP weight\nadapted to data arriving incrementally. To ensure valid coverage with\nrobustness to model mis-specification, we wed the GP-based set predictors with\nthe online conformal prediction framework, which post-processes the prediction\nsets using adaptive thresholds. Experimental results the proposed method yields\nimproved coverage and efficient prediction sets over existing baselines by\nadaptively ensembling the GP models and setting the key threshold parameters in\nCP.",
      "authors": [
        "Jinwen Xu",
        "Qin Lu",
        "Georgios B. Giannakis"
      ],
      "published": "2025-10-07T17:44:13Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06181v1",
      "primary_area": "model_architecture",
      "secondary_focus": "['training_optimization', 'reasoning']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种面向图数据的在线不确定性量化方法，结合高斯过程与保形预测框架。通过随机特征核近似实现计算效率，采用自适应集成策略和在线阈值调整，在保证覆盖度的同时提升预测集质量，适用于网络科学中的安全关键应用。",
      "order": 83,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06181v1"
    },
    {
      "arxiv_id": "2510.06174v1",
      "title": "Thermodynamic Performance Limits for Score-Based Diffusion Models",
      "summary": "We establish a fundamental connection between score-based diffusion models\nand non-equilibrium thermodynamics by deriving performance limits based on\nentropy rates. Our main theoretical contribution is a lower bound on the\nnegative log-likelihood of the data that relates model performance to entropy\nrates of diffusion processes. We numerically validate this bound on a synthetic\ndataset and investigate its tightness. By building a bridge to entropy rates -\nsystem, intrinsic, and exchange entropy - we provide new insights into the\nthermodynamic operation of these models, drawing parallels to Maxwell's demon\nand implications for thermodynamic computing hardware. Our framework connects\ngenerative modeling performance to fundamental physical principles through\nstochastic thermodynamics.",
      "authors": [
        "Nathan X. Kodama",
        "Michael Hinczewski"
      ],
      "published": "2025-10-07T17:35:18Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06174v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文建立了基于分数的扩散模型与非平衡热力学之间的理论联系，通过推导基于熵率性能极限，提出了数据负对数似然的下界，并将模型性能与扩散过程的熵率相关联。研究通过数值实验验证了该界限的紧密度，并借助系统熵、本征熵和交换熵等概念，揭示了这类模型的热力学运行机制，为热力学计算硬件提供了新见解。",
      "order": 84,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06174v1"
    },
    {
      "arxiv_id": "2510.06165v1",
      "title": "Higher-Order Feature Attribution: Bridging Statistics, Explainable AI,\n  and Topological Signal Processing",
      "summary": "Feature attributions are post-training analysis methods that assess how\nvarious input features of a machine learning model contribute to an output\nprediction. Their interpretation is straightforward when features act\nindependently, but becomes less direct when the predictive model involves\ninteractions such as multiplicative relationships or joint feature\ncontributions. In this work, we propose a general theory of higher-order\nfeature attribution, which we develop on the foundation of Integrated Gradients\n(IG). This work extends existing frameworks in the literature on explainable\nAI. When using IG as the method of feature attribution, we discover natural\nconnections to statistics and topological signal processing. We provide several\ntheoretical results that establish the theory, and we validate our theory on a\nfew examples.",
      "authors": [
        "Kurt Butler",
        "Guanchao Feng",
        "Petar Djuric"
      ],
      "published": "2025-10-07T17:29:34Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06165v1",
      "primary_area": "text_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出了一种基于积分梯度的高阶特征归因理论，解决了传统方法在处理特征交互时的局限性。该研究建立了可解释AI与统计学、拓扑信号处理之间的理论联系，并通过理论证明和实例验证了框架的有效性。",
      "order": 85,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06165v1"
    },
    {
      "arxiv_id": "2510.06162v1",
      "title": "TabPFN-Wide: Continued Pre-Training for Extreme Feature Counts",
      "summary": "Revealing novel insights from the relationship between molecular measurements\nand pathology remains a very impactful application of machine learning in\nbiomedicine. Data in this domain typically contain only a few observations but\nthousands of potentially noisy features, posing challenges for conventional\nmachine learning approaches. While prior-data fitted networks emerge as\nfoundation models for tabular data, they are currently not suited to handle\nlarge feature counts (>500). Although feature reduction enables their\napplication, it hinders feature importance analysis. We propose a strategy that\nextends existing models through continued pre-training on synthetic data\nsampled from a customized prior. The resulting model, TabPFN-Wide, matches or\nexceeds its base model's performance while exhibiting improved robustness to\nnoise. It seamlessly scales beyond 50,000 features, regardless of noise levels,\nwhile maintaining inherent interpretability, which is critical for biomedical\napplications. Our results show that prior-informed adaptation is suitable to\nenhance the capability of foundation models for high-dimensional data. On\nreal-world biomedical datasets many of the most relevant features identified by\nthe model overlap with previous biological findings, while others propose\npotential starting points for future studies.",
      "authors": [
        "Christopher Kolberg",
        "Katharina Eggensperger",
        "Nico Pfeifer"
      ],
      "published": "2025-10-07T17:28:49Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06162v1",
      "primary_area": "text_models",
      "secondary_focus": "['training_optimization', 'model_architecture']",
      "application_domain": "medical_ai",
      "tldr_zh": "本文提出TabPFN-Wide模型，通过基于定制先验的合成数据持续预训练，扩展了表格数据基础模型处理高维特征的能力。该模型在保持可解释性的同时，可无缝处理超过5万个特征，在生物医学数据上表现出优越性能，并能识别与已知生物学发现一致的重要特征。",
      "order": 86,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06162v1"
    },
    {
      "arxiv_id": "2510.06151v1",
      "title": "LLMs as Policy-Agnostic Teammates: A Case Study in Human Proxy Design\n  for Heterogeneous Agent Teams",
      "summary": "A critical challenge in modelling Heterogeneous-Agent Teams is training\nagents to collaborate with teammates whose policies are inaccessible or\nnon-stationary, such as humans. Traditional approaches rely on expensive\nhuman-in-the-loop data, which limits scalability. We propose using Large\nLanguage Models (LLMs) as policy-agnostic human proxies to generate synthetic\ndata that mimics human decision-making. To evaluate this, we conduct three\nexperiments in a grid-world capture game inspired by Stag Hunt, a game theory\nparadigm that balances risk and reward. In Experiment 1, we compare decisions\nfrom 30 human participants and 2 expert judges with outputs from LLaMA 3.1 and\nMixtral 8x22B models. LLMs, prompted with game-state observations and reward\nstructures, align more closely with experts than participants, demonstrating\nconsistency in applying underlying decision criteria. Experiment 2 modifies\nprompts to induce risk-sensitive strategies (e.g. \"be risk averse\"). LLM\noutputs mirror human participants' variability, shifting between risk-averse\nand risk-seeking behaviours. Finally, Experiment 3 tests LLMs in a dynamic\ngrid-world where the LLM agents generate movement actions. LLMs produce\ntrajectories resembling human participants' paths. While LLMs cannot yet fully\nreplicate human adaptability, their prompt-guided diversity offers a scalable\nfoundation for simulating policy-agnostic teammates.",
      "authors": [
        "Aju Ani Justus",
        "Chris Baber"
      ],
      "published": "2025-10-07T17:21:20Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06151v1",
      "primary_area": "text_models",
      "secondary_focus": "reasoning",
      "application_domain": "general_purpose",
      "tldr_zh": "本研究提出使用大语言模型作为策略不可知的人类代理，在异质智能体团队中生成模拟人类决策的合成数据。通过在网格世界捕获游戏中的三个实验证明，LLMs能够产生与专家决策一致、可调节风险敏感度且轨迹类似人类的行为，为模拟策略不可知的队友提供了可扩展的基础。",
      "order": 87,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06151v1"
    },
    {
      "arxiv_id": "2510.06141v1",
      "title": "Improved High-probability Convergence Guarantees of Decentralized SGD",
      "summary": "Convergence in high-probability (HP) has been receiving increasing interest,\ndue to its attractive properties, such as exponentially decaying tail bounds\nand strong guarantees for each individual run of an algorithm. While HP\nguarantees are extensively studied in centralized settings, much less is\nunderstood in the decentralized, networked setup. Existing HP studies in\ndecentralized settings impose strong assumptions, like uniformly bounded\ngradients, or asymptotically vanishing noise, resulting in a significant gap\nbetween assumptions used to establish convergence in the HP and the\nmean-squared error (MSE) sense, even for vanilla Decentralized Stochastic\nGradient Descent ($\\mathtt{DSGD}$) algorithm. This is contrary to centralized\nsettings, where it is known that $\\mathtt{SGD}$ converges in HP under the same\nconditions on the cost function as needed to guarantee MSE convergence.\nMotivated by this observation, we revisit HP guarantees for $\\mathtt{DSGD}$ in\nthe presence of light-tailed noise. We show that $\\mathtt{DSGD}$ converges in\nHP under the same conditions on the cost as in the MSE sense, removing\nuniformly bounded gradients and other restrictive assumptions, while\nsimultaneously achieving order-optimal rates for both non-convex and strongly\nconvex costs. Moreover, our improved analysis yields linear speed-up in the\nnumber of users, demonstrating that $\\mathtt{DSGD}$ maintains strong\nperformance in the HP sense and matches existing MSE guarantees. Our improved\nresults stem from a careful analysis of the MGF of quantities of interest\n(norm-squared of gradient or optimality gap) and the MGF of the consensus gap\nbetween users' models. To achieve linear speed-up, we provide a novel result on\nthe variance-reduction effect of decentralized methods in the HP sense and more\nfine-grained bounds on the MGF for strongly convex costs, which are both of\nindependent interest.",
      "authors": [
        "Aleksandar Armacki",
        "Ali H. Sayed"
      ],
      "published": "2025-10-07T17:15:08Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06141v1",
      "primary_area": "training_optimization",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文改进了去中心化随机梯度下降(DSGD)的高概率收敛保证，在轻尾噪声条件下消除了均匀有界梯度等强假设，实现了与均方误差收敛相同的条件要求，并在非凸和强凸成本函数中达到最优收敛速率，同时证明了用户数量上的线性加速效果。",
      "order": 88,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06141v1"
    },
    {
      "arxiv_id": "2510.06138v1",
      "title": "Multi-Task Reinforcement Learning with Language-Encoded Gated Policy\n  Networks",
      "summary": "Multi-task reinforcement learning often relies on task metadata -- such as\nbrief natural-language descriptions -- to guide behavior across diverse\nobjectives. We present Lexical Policy Networks (LEXPOL), a language-conditioned\nmixture-of-policies architecture for multi-task RL. LEXPOL encodes task\nmetadata with a text encoder and uses a learned gating module to select or\nblend among multiple sub-policies, enabling end-to-end training across tasks.\nOn MetaWorld benchmarks, LEXPOL matches or exceeds strong multi-task baselines\nin success rate and sample efficiency, without task-specific retraining. To\nanalyze the mechanism, we further study settings with fixed expert policies\nobtained independently of the gate and show that the learned language gate\ncomposes these experts to produce behaviors appropriate to novel task\ndescriptions and unseen task combinations. These results indicate that\nnatural-language metadata can effectively index and recombine reusable skills\nwithin a single policy.",
      "authors": [
        "Rushiv Arora"
      ],
      "published": "2025-10-07T17:12:24Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06138v1",
      "primary_area": "vla_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出LEXPOL语言编码门控策略网络，通过自然语言描述任务元数据，利用文本编码器和门控模块选择或混合多个子策略，实现多任务强化学习的端到端训练。在MetaWorld基准测试中，LEXPOL在成功率和样本效率上达到或超越强基线，无需任务特定重训练即可组合专家策略适应新任务。",
      "order": 89,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06138v1"
    },
    {
      "arxiv_id": "2510.06126v1",
      "title": "lm-Meter: Unveiling Runtime Inference Latency for On-Device Language\n  Models",
      "summary": "Large Language Models (LLMs) are increasingly integrated into everyday\napplications, but their prevalent cloud-based deployment raises growing\nconcerns around data privacy and long-term sustainability. Running LLMs locally\non mobile and edge devices (on-device LLMs) offers the promise of enhanced\nprivacy, reliability, and reduced communication costs. However, realizing this\nvision remains challenging due to substantial memory and compute demands, as\nwell as limited visibility into performance-efficiency trade-offs on\nresource-constrained hardware. We propose lm-Meter, the first lightweight,\nonline latency profiler tailored for on-device LLM inference. lm-Meter captures\nfine-grained, real-time latency at both phase (e.g., embedding, prefill,\ndecode, softmax, sampling) and kernel levels without auxiliary devices. We\nimplement lm-Meter on commercial mobile platforms and demonstrate its high\nprofiling accuracy with minimal system overhead, e.g., only 2.58% throughput\nreduction in prefill and 0.99% in decode under the most constrained Powersave\ngovernor. Leveraging lm-Meter, we conduct comprehensive empirical studies\nrevealing phase- and kernel-level bottlenecks in on-device LLM inference,\nquantifying accuracy-efficiency trade-offs, and identifying systematic\noptimization opportunities. lm-Meter provides unprecedented visibility into the\nruntime behavior of LLMs on constrained platforms, laying the foundation for\ninformed optimization and accelerating the democratization of on-device LLM\nsystems. Code and tutorials are available at\nhttps://github.com/amai-gsu/LM-Meter.",
      "authors": [
        "Haoxin Wang",
        "Xiaolong Tu",
        "Hongyu Ke",
        "Huirong Chai",
        "Dawei Chen",
        "Kyungtae Han"
      ],
      "published": "2025-10-07T17:05:30Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06126v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_compression', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出lm-Meter，首个专为设备端语言模型设计的轻量级在线延迟分析器。该工具能在不依赖辅助设备的情况下，实时捕获嵌入、预填充、解码等阶段的细粒度延迟数据。在商用移动平台上验证显示，其分析精度高且系统开销极小（吞吐量降低仅0.99%-2.58%）。通过该系统揭示了设备端LLM推理的瓶颈，为优化提供了新见解，推动设备端LLM系统的普及。",
      "order": 90,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06126v1"
    },
    {
      "arxiv_id": "2510.06125v1",
      "title": "Downsized and Compromised?: Assessing the Faithfulness of Model\n  Compression",
      "summary": "In real-world applications, computational constraints often require\ntransforming large models into smaller, more efficient versions through model\ncompression. While these techniques aim to reduce size and computational cost\nwithout sacrificing performance, their evaluations have traditionally focused\non the trade-off between size and accuracy, overlooking the aspect of model\nfaithfulness. This limited view is insufficient for high-stakes domains like\nhealthcare, finance, and criminal justice, where compressed models must remain\nfaithful to the behavior of their original counterparts. This paper presents a\nnovel approach to evaluating faithfulness in compressed models, moving beyond\nstandard metrics. We introduce and demonstrate a set of faithfulness metrics\nthat capture how model behavior changes post-compression. Our contributions\ninclude introducing techniques to assess predictive consistency between the\noriginal and compressed models using model agreement, and applying chi-squared\ntests to detect statistically significant changes in predictive patterns across\nboth the overall dataset and demographic subgroups, thereby exposing shifts\nthat aggregate fairness metrics may obscure. We demonstrate our approaches by\napplying quantization and pruning to artificial neural networks (ANNs) trained\non three diverse and socially meaningful datasets. Our findings show that high\naccuracy does not guarantee faithfulness, and our statistical tests detect\nsubtle yet significant shifts that are missed by standard metrics, such as\nAccuracy and Equalized Odds. The proposed metrics provide a practical and more\ndirect method for ensuring that efficiency gains through compression do not\ncompromise the fairness or faithfulness essential for trustworthy AI.",
      "authors": [
        "Moumita Kamal",
        "Douglas A. Talbert"
      ],
      "published": "2025-10-07T17:05:02Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06125v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_compression', 'alignment']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出了一种评估模型压缩后忠实度的新方法，超越传统精度指标，引入预测一致性和卡方检验来检测压缩模型与原模型的行为差异。研究发现高精度不等于高忠实度，新方法能发现标准公平性指标忽略的细微但显著的预测模式变化，为医疗、金融等高风险领域提供更可靠的压缩模型评估方案。",
      "order": 91,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06125v1"
    },
    {
      "arxiv_id": "2510.06122v1",
      "title": "PolyGraph Discrepancy: a classifier-based metric for graph generation",
      "summary": "Existing methods for evaluating graph generative models primarily rely on\nMaximum Mean Discrepancy (MMD) metrics based on graph descriptors. While these\nmetrics can rank generative models, they do not provide an absolute measure of\nperformance. Their values are also highly sensitive to extrinsic parameters,\nnamely kernel and descriptor parametrization, making them incomparable across\ndifferent graph descriptors. We introduce PolyGraph Discrepancy (PGD), a new\nevaluation framework that addresses these limitations. It approximates the\nJensen-Shannon distance of graph distributions by fitting binary classifiers to\ndistinguish between real and generated graphs, featurized by these descriptors.\nThe data log-likelihood of these classifiers approximates a variational lower\nbound on the JS distance between the two distributions. Resulting metrics are\nconstrained to the unit interval [0,1] and are comparable across different\ngraph descriptors. We further derive a theoretically grounded summary metric\nthat combines these individual metrics to provide a maximally tight lower bound\non the distance for the given descriptors. Thorough experiments demonstrate\nthat PGD provides a more robust and insightful evaluation compared to MMD\nmetrics. The PolyGraph framework for benchmarking graph generative models is\nmade publicly available at https://github.com/BorgwardtLab/polygraph-benchmark.",
      "authors": [
        "Markus Krimmel",
        "Philip Hartout",
        "Karsten Borgwardt",
        "Dexiong Chen"
      ],
      "published": "2025-10-07T17:02:44Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06122v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出PolyGraph差异度（PGD），一种基于分类器的图生成模型评估框架。通过训练二元分类器区分真实与生成图，PGD近似计算图分布间的Jensen-Shannon距离，解决了传统MMD指标对参数敏感、无法跨描述符比较的问题。该指标约束在[0,1]区间，并提供理论严谨的综合度量，实验证明比MMD更鲁棒且具解释性。",
      "order": 92,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06122v1"
    },
    {
      "arxiv_id": "2510.06108v1",
      "title": "Influence Functions for Efficient Data Selection in Reasoning",
      "summary": "Fine-tuning large language models (LLMs) on chain-of-thought (CoT) data shows\nthat a small amount of high-quality data can outperform massive datasets. Yet,\nwhat constitutes \"quality\" remains ill-defined. Existing reasoning methods rely\non indirect heuristics such as problem difficulty or trace length, while\ninstruction-tuning has explored a broader range of automated selection\nstrategies, but rarely in the context of reasoning. We propose to define\nreasoning data quality using influence functions, which measure the causal\neffect of individual CoT examples on downstream accuracy, and introduce\ninfluence-based pruning, which consistently outperforms perplexity and\nembedding-based baselines on math reasoning within a model family.",
      "authors": [
        "Prateek Humane",
        "Paolo Cudrano",
        "Daniel Z. Kaplan",
        "Matteo Matteucci",
        "Supriyo Chakraborty",
        "Irina Rish"
      ],
      "published": "2025-10-07T16:40:42Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06108v1",
      "primary_area": "text_models",
      "secondary_focus": "['reasoning', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出使用影响函数来定义推理数据的质量，通过衡量单个思维链样本对下游准确率的因果效应，开发了基于影响的数据剪枝方法。在数学推理任务中，该方法在模型家族内持续优于基于困惑度和嵌入的基线方法，为高效数据选择提供了新思路。",
      "order": 93,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06108v1"
    },
    {
      "arxiv_id": "2510.06106v1",
      "title": "The Physics of Data and Tasks: Theories of Locality and Compositionality\n  in Deep Learning",
      "summary": "Deep neural networks have achieved remarkable success, yet our understanding\nof how they learn remains limited. These models can learn high-dimensional\ntasks, which is generally statistically intractable due to the curse of\ndimensionality. This apparent paradox suggests that learnable data must have an\nunderlying latent structure. What is the nature of this structure? How do\nneural networks encode and exploit it, and how does it quantitatively impact\nperformance - for instance, how does generalization improve with the number of\ntraining examples? This thesis addresses these questions by studying the roles\nof locality and compositionality in data, tasks, and deep learning\nrepresentations.",
      "authors": [
        "Alessandro Favero"
      ],
      "published": "2025-10-07T16:40:06Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06106v1",
      "primary_area": "model_architecture",
      "secondary_focus": "['reasoning', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本论文从物理学视角研究深度学习，探讨数据与任务中的局部性和组合性理论。通过分析深度神经网络如何学习高维任务的内在潜在结构，揭示了局部性和组合性在数据表示与模型性能中的关键作用，为理解神经网络泛化能力与训练样本数量的定量关系提供理论框架。",
      "order": 94,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06106v1"
    },
    {
      "arxiv_id": "2510.06096v1",
      "title": "The Alignment Auditor: A Bayesian Framework for Verifying and Refining\n  LLM Objectives",
      "summary": "The objectives that Large Language Models (LLMs) implicitly optimize remain\ndangerously opaque, making trustworthy alignment and auditing a grand\nchallenge. While Inverse Reinforcement Learning (IRL) can infer reward\nfunctions from behaviour, existing approaches either produce a single,\noverconfident reward estimate or fail to address the fundamental ambiguity of\nthe task (non-identifiability). This paper introduces a principled auditing\nframework that re-frames reward inference from a simple estimation task to a\ncomprehensive process for verification. Our framework leverages Bayesian IRL to\nnot only recover a distribution over objectives but to enable three critical\naudit capabilities: (i) Quantifying and systematically reducing\nnon-identifiability by demonstrating posterior contraction over sequential\nrounds of evidence; (ii) Providing actionable, uncertainty-aware diagnostics\nthat expose spurious shortcuts and identify out-of-distribution prompts where\nthe inferred objective cannot be trusted; and (iii) Validating policy-level\nutility by showing that the refined, low-uncertainty reward can be used\ndirectly in RLHF to achieve training dynamics and toxicity reductions\ncomparable to the ground-truth alignment process. Empirically, our framework\nsuccessfully audits a detoxified LLM, yielding a well-calibrated and\ninterpretable objective that strengthens alignment guarantees. Overall, this\nwork provides a practical toolkit for auditors, safety teams, and regulators to\nverify what LLMs are truly trying to achieve, moving us toward more trustworthy\nand accountable AI.",
      "authors": [
        "Matthieu Bou",
        "Nyal Patel",
        "Arjun Jagota",
        "Satyapriya Krishna",
        "Sonali Parbhoo"
      ],
      "published": "2025-10-07T16:25:14Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06096v1",
      "primary_area": "text_models",
      "secondary_focus": "alignment",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出了一种基于贝叶斯逆强化学习的对齐审计框架，通过量化目标不确定性、提供可操作诊断和验证策略效用，解决大语言模型目标不透明问题。该框架能系统减少目标识别模糊性，在去毒任务中验证了其有效性，为AI安全审计提供实用工具。",
      "order": 95,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06096v1"
    },
    {
      "arxiv_id": "2510.06092v1",
      "title": "Learning from Failures: Understanding LLM Alignment through\n  Failure-Aware Inverse RL",
      "summary": "Reinforcement Learning from Human Feedback (RLHF) aligns Large Language\nModels (LLMs) with human preferences, yet the underlying reward signals they\ninternalize remain hidden, posing a critical challenge for interpretability and\nsafety. Existing approaches attempt to extract these latent incentives using\nInverse Reinforcement Learning (IRL), but treat all preference pairs equally,\noften overlooking the most informative signals: those examples the extracted\nreward model misclassifies or assigns nearly equal scores, which we term\n\\emph{failures}. We introduce a novel \\emph{failure-aware} IRL algorithm that\nfocuses on misclassified or difficult examples to recover the latent rewards\ndefining model behaviors. By learning from these failures, our failure-aware\nIRL extracts reward functions that better reflect the true objectives behind\nRLHF. We demonstrate that failure-aware IRL outperforms existing IRL baselines\nacross multiple metrics when applied to LLM detoxification, without requiring\nexternal classifiers or supervision. Crucially, failure-aware IRL yields\nrewards that better capture the true incentives learned during RLHF, enabling\nmore effective re-RLHF training than standard IRL. This establishes\nfailure-aware IRL as a robust, scalable method for auditing model alignment and\nreducing ambiguity in the IRL process.",
      "authors": [
        "Nyal Patel",
        "Matthieu Bou",
        "Arjun Jagota",
        "Satyapriya Krishna",
        "Sonali Parbhoo"
      ],
      "published": "2025-10-07T16:20:14Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06092v1",
      "primary_area": "text_models",
      "secondary_focus": "['alignment', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种故障感知逆向强化学习方法，通过重点关注RLHF过程中被误分类或难以判断的样本，更准确地提取大语言模型内化的奖励信号。相比传统IRL方法，该方法在模型去毒任务中表现更优，无需外部分类器即可提升对齐效果和可解释性。",
      "order": 96,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06092v1"
    },
    {
      "arxiv_id": "2510.06091v1",
      "title": "Learning Mixtures of Linear Dynamical Systems (MoLDS) via Hybrid\n  Tensor-EM Method",
      "summary": "Mixtures of linear dynamical systems (MoLDS) provide a path to model\ntime-series data that exhibit diverse temporal dynamics across trajectories.\nHowever, its application remains challenging in complex and noisy settings,\nlimiting its effectiveness for neural data analysis. Tensor-based moment\nmethods can provide global identifiability guarantees for MoLDS, but their\nperformance degrades under noise and complexity. Commonly used\nexpectation-maximization (EM) methods offer flexibility in fitting latent\nmodels but are highly sensitive to initialization and prone to poor local\nminima. Here, we propose a tensor-based method that provides identifiability\nguarantees for learning MoLDS, which is followed by EM updates to combine the\nstrengths of both approaches. The novelty in our approach lies in the\nconstruction of moment tensors using the input-output data to recover globally\nconsistent estimates of mixture weights and system parameters. These estimates\ncan then be refined through a Kalman EM algorithm, with closed-form updates for\nall LDS parameters. We validate our framework on synthetic benchmarks and\nreal-world datasets. On synthetic data, the proposed Tensor-EM method achieves\nmore reliable recovery and improved robustness compared to either pure tensor\nor randomly initialized EM methods. We then analyze neural recordings from the\nprimate somatosensory cortex while a non-human primate performs reaches in\ndifferent directions. Our method successfully models and clusters different\nconditions as separate subsystems, consistent with supervised single-LDS fits\nfor each condition. Finally, we apply this approach to another neural dataset\nwhere monkeys perform a sequential reaching task. These results demonstrate\nthat MoLDS provides an effective framework for modeling complex neural data,\nand that Tensor-EM is a reliable approach to MoLDS learning for these\napplications.",
      "authors": [
        "Lulu Gong",
        "Shreya Saxena"
      ],
      "published": "2025-10-07T16:17:52Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06091v1",
      "primary_area": "model_architecture",
      "secondary_focus": "training_optimization",
      "application_domain": "medical_ai",
      "tldr_zh": "本文提出一种混合张量-EM方法用于学习线性动态系统混合模型(MoLDS)，通过张量矩方法提供可识别性保证，再结合EM算法进行参数优化。该方法在合成数据和灵长类动物神经记录数据上验证了其鲁棒性和有效性，成功建模了不同运动条件下的神经动态模式。",
      "order": 97,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06091v1"
    },
    {
      "arxiv_id": "2510.06071v1",
      "title": "Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI\n  Models for Scatterplot-Related Tasks",
      "summary": "AI models are increasingly used for data analysis and visualization, yet\nbenchmarks rarely address scatterplot-specific tasks, limiting insight into\nperformance. To address this gap for one of the most common chart types, we\nintroduce a synthetic, annotated dataset of over 18,000 scatterplots from six\ndata generators and 17 chart designs, and a benchmark based on it. We evaluate\nproprietary models from OpenAI and Google using N-shot prompting on five\ndistinct tasks derived from annotations of cluster bounding boxes, their center\ncoordinates, and outlier coordinates. OpenAI models and Gemini 2.5 Flash,\nespecially when prompted with examples, are viable options for counting\nclusters and, in Flash's case, outliers (90%+ Accuracy). However, the results\nfor localization-related tasks are unsatisfactory: Precision and Recall are\nnear or below 50%, except for Flash in outlier identification (65.01%).\nFurthermore, the impact of chart design on performance appears to be a\nsecondary factor, but it is advisable to avoid scatterplots with wide aspect\nratios (16:9 and 21:9) or those colored randomly. Supplementary materials are\navailable at https://github.com/feedzai/biy-paper.",
      "authors": [
        "João Palmeiro",
        "Diogo Duarte",
        "Rita Costa",
        "Pedro Bizarro"
      ],
      "published": "2025-10-07T15:59:19Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06071v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "reasoning",
      "application_domain": "financial_ai",
      "tldr_zh": "本文提出BIY基准测试框架，构建包含1.8万+散点图的数据集，评估OpenAI和Google模型在聚类计数、异常值检测等五项任务上的表现。结果显示模型在计数任务上表现良好（准确率>90%），但定位任务表现欠佳（精确率/召回率≤50%），并发现宽高比和随机配色会降低模型性能。",
      "order": 98,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06071v1"
    },
    {
      "arxiv_id": "2510.06066v1",
      "title": "Analyzing the Effect of Embedding Norms and Singular Values to\n  Oversmoothing in Graph Neural Networks",
      "summary": "In this paper, we study the factors that contribute to the effect of\noversmoothing in deep Graph Neural Networks (GNNs). Specifically, our analysis\nis based on a new metric (Mean Average Squared Distance - $MASED$) to quantify\nthe extent of oversmoothing. We derive layer-wise bounds on $MASED$, which\naggregate to yield global upper and lower distance bounds. Based on this\nquantification of oversmoothing, we further analyze the importance of two\ndifferent properties of the model; namely the norms of the generated node\nembeddings, along with the largest and smallest singular values of the weight\nmatrices. Building on the insights drawn from the theoretical analysis, we show\nthat oversmoothing increases as the number of trainable weight matrices and the\nnumber of adjacency matrices increases. We also use the derived layer-wise\nbounds on $MASED$ to form a proposal for decoupling the number of hops (i.e.,\nadjacency depth) from the number of weight matrices. In particular, we\nintroduce G-Reg, a regularization scheme that increases the bounds, and\ndemonstrate through extensive experiments that by doing so node classification\naccuracy increases, achieving robustness at large depths. We further show that\nby reducing oversmoothing in deep networks, we can achieve better results in\nsome tasks than using shallow ones. Specifically, we experiment with a ``cold\nstart\" scenario, i.e., when there is no feature information for the unlabeled\nnodes. Finally, we show empirically the trade-off between receptive field size\n(i.e., number of weight matrices) and performance, using the $MASED$ bounds.\nThis is achieved by distributing adjacency hops across a small number of\ntrainable layers, avoiding the extremes of under- or over-parameterization of\nthe GNN.",
      "authors": [
        "Dimitrios Kelesis",
        "Dimitris Fotakis",
        "Georgios Paliouras"
      ],
      "published": "2025-10-07T15:55:28Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06066v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出MASED指标量化图神经网络中的过度平滑现象，通过分析节点嵌入范数和权重矩阵奇异值，揭示了深度GNN中过度平滑的成因。作者提出G-Reg正则化方案，成功实现邻接深度与权重矩阵数量的解耦，在深度网络中提升节点分类精度，并在冷启动场景下优于浅层网络，同时探索了感受野大小与性能的平衡。",
      "order": 99,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06066v1"
    },
    {
      "arxiv_id": "2510.06050v1",
      "title": "Edit-Based Flow Matching for Temporal Point Processes",
      "summary": "Temporal point processes (TPPs) are a fundamental tool for modeling event\nsequences in continuous time, but most existing approaches rely on\nautoregressive parameterizations that are limited by their sequential sampling.\nRecent non-autoregressive, diffusion-style models mitigate these issues by\njointly interpolating between noise and data through event insertions and\ndeletions in a discrete Markov chain. In this work, we generalize this\nperspective and introduce an Edit Flow process for TPPs that transports noise\nto data via insert, delete, and substitute edit operations. By learning the\ninstantaneous edit rates within a continuous-time Markov chain framework, we\nattain a flexible and efficient model that effectively reduces the total number\nof necessary edit operations during generation. Empirical results demonstrate\nthe generative flexibility of our unconditionally trained model in a wide range\nof unconditional and conditional generation tasks on benchmark TPPs.",
      "authors": [
        "David Lüdke",
        "Marten Lienen",
        "Marcel Kollovieh",
        "Stephan Günnemann"
      ],
      "published": "2025-10-07T15:44:12Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06050v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出了一种基于编辑操作的流匹配方法用于时序点过程，通过插入、删除和替换三种编辑操作在连续时间马尔可夫链框架中学习瞬时编辑率，有效减少了生成过程中所需的编辑操作次数，在多种无条件与条件生成任务中展现出优越性能。",
      "order": 100,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06050v1"
    },
    {
      "arxiv_id": "2510.06048v1",
      "title": "BLISS: A Lightweight Bilevel Influence Scoring Method for Data Selection\n  in Language Model Pretraining",
      "summary": "Effective data selection is essential for pretraining large language models\n(LLMs), enhancing efficiency and improving generalization to downstream tasks.\nHowever, existing approaches often require leveraging external pretrained\nmodels, making it difficult to disentangle the effects of data selection from\nthose of the external pretrained models. In addition, they often overlook the\nlong-term impact of selected data if the model is trained to convergence,\nprimarily due to the prohibitive cost of full-scale LLM pretraining. In this\npaper, we introduce BLISS (\\textbf{B}ileve\\textbf{L} \\textbf{I}nfluence\n\\textbf{S}coring method for data \\textbf{S}election): a lightweight data\nselection method that operates entirely \\emph{from scratch}, without relying on\nany external pretrained oracle models, while explicitly accounting for the\nlong-term impact of selected data. BLISS leverages a small proxy model as a\nsurrogate for the LLM and employs a score model to estimate the long-term\ninfluence of training samples if the proxy model is trained to convergence. We\nformulate data selection as a bilevel optimization problem, where the\nupper-level objective optimizes the score model to assign importance weights to\ntraining samples, ensuring that minimizing the lower-level objective (i.e.,\ntraining the proxy model over the weighted training loss until convergence)\nleads to best validation performance. Once optimized, the trained score model\npredicts influence scores for the dataset, enabling efficient selection of\nhigh-quality samples for LLM pretraining. We validate BLISS by pretraining\n410M/1B/2.8B Pythia and LLaMA-0.5B models on selected subsets of the C4\ndataset. Notably, under the 1B model setting, BLISS achieves $1.7\\times$\nspeedup in reaching the same performance as the state-of-the-art method,\ndemonstrating superior performance across multiple downstream tasks.",
      "authors": [
        "Jie Hao",
        "Rui Yu",
        "Wei Zhang",
        "Huixia Wang",
        "Jie Xu",
        "Mingrui Liu"
      ],
      "published": "2025-10-07T15:42:33Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06048v1",
      "primary_area": "text_models",
      "secondary_focus": "training_optimization",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出BLISS，一种轻量级双层优化数据选择方法，无需依赖外部预训练模型即可评估训练样本对语言模型预训练的长期影响。通过代理模型和评分模型的协同优化，在C4数据集上验证显示，相比现有方法可提速1.7倍达到同等性能，并在多个下游任务中表现优异。",
      "order": 101,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06048v1"
    },
    {
      "arxiv_id": "2510.06038v1",
      "title": "From Learning to Mastery: Achieving Safe and Efficient Real-World\n  Autonomous Driving with Human-In-The-Loop Reinforcement Learning",
      "summary": "Autonomous driving with reinforcement learning (RL) has significant\npotential. However, applying RL in real-world settings remains challenging due\nto the need for safe, efficient, and robust learning. Incorporating human\nexpertise into the learning process can help overcome these challenges by\nreducing risky exploration and improving sample efficiency. In this work, we\npropose a reward-free, active human-in-the-loop learning method called\nHuman-Guided Distributional Soft Actor-Critic (H-DSAC). Our method combines\nProxy Value Propagation (PVP) and Distributional Soft Actor-Critic (DSAC) to\nenable efficient and safe training in real-world environments. The key\ninnovation is the construction of a distributed proxy value function within the\nDSAC framework. This function encodes human intent by assigning higher expected\nreturns to expert demonstrations and penalizing actions that require human\nintervention. By extrapolating these labels to unlabeled states, the policy is\neffectively guided toward expert-like behavior. With a well-designed state\nspace, our method achieves real-world driving policy learning within practical\ntraining times. Results from both simulation and real-world experiments\ndemonstrate that our framework enables safe, robust, and sample-efficient\nlearning for autonomous driving.",
      "authors": [
        "Li Zeqiao",
        "Wang Yijing",
        "Wang Haoyu",
        "Li Zheng",
        "Li Peng",
        "Liu Wenfei",
        "Zuo Zhiqiang"
      ],
      "published": "2025-10-07T15:33:29Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06038v1",
      "primary_area": "vla_models",
      "secondary_focus": "['training_optimization', 'alignment']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种人机协同强化学习方法H-DSAC，通过构建分布式代理价值函数编码人类驾驶意图，在无需预设奖励函数的情况下实现安全高效的自动驾驶策略学习。该方法结合专家示范与人工干预信号，在仿真和实车实验中均展现出优异的样本效率与安全性。",
      "order": 102,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06038v1"
    },
    {
      "arxiv_id": "2510.06029v1",
      "title": "Fast Leave-One-Out Approximation from Fragment-Target Prevalence Vectors\n  (molFTP) : From Dummy Masking to Key-LOO for Leakage-Free Feature\n  Construction",
      "summary": "We introduce molFTP (molecular fragment-target prevalence), a compact\nrepresentation that delivers strong predictive performance. To prevent feature\nleakage across cross-validation folds, we implement a dummy-masking procedure\nthat removes information about fragments present in the held-out molecules. We\nfurther show that key leave-one-out (key-loo) closely approximates true\nmolecule-level leave-one-out (LOO), with deviation below 8% on our datasets.\nThis enables near full data training while preserving unbiased cross-validation\nestimates of model performance. Overall, molFTP provides a fast,\nleakage-resistant fragment-target prevalence vectorization with practical\nsafeguards (dummy masking or key-LOO) that approximate LOO at a fraction of its\ncost.",
      "authors": [
        "Guillaume Godin"
      ],
      "published": "2025-10-07T15:27:16Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06029v1",
      "primary_area": "text_models",
      "secondary_focus": "training_optimization",
      "application_domain": "medical_ai",
      "tldr_zh": "本文提出molFTP分子片段-靶点流行度向量化方法，通过虚拟掩码和关键留一法防止交叉验证中的特征泄露，在保持模型性能无偏估计的同时实现近似全数据训练，计算成本显著低于传统留一法。",
      "order": 103,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06029v1"
    },
    {
      "arxiv_id": "2510.06028v1",
      "title": "Generalization of Gibbs and Langevin Monte Carlo Algorithms in the\n  Interpolation Regime",
      "summary": "The paper provides data-dependent bounds on the test error of the Gibbs\nalgorithm in the overparameterized interpolation regime, where low training\nerrors are also obtained for impossible data, such as random labels in\nclassification. The bounds are stable under approximation with Langevin Monte\nCarlo algorithms. Experiments on the MNIST and CIFAR-10 datasets verify that\nthe bounds yield nontrivial predictions on true labeled data and correctly\nupper bound the test error for random labels. Our method indicates that\ngeneralization in the low-temperature, interpolation regime is already signaled\nby small training errors in the more classical high temperature regime.",
      "authors": [
        "Andreas Maurer",
        "Erfan Mirzaei",
        "Massimiliano Pontil"
      ],
      "published": "2025-10-07T15:25:56Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06028v1",
      "primary_area": "training_optimization",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文在过参数化插值区域为Gibbs算法提供了数据依赖的测试误差边界，证明该边界在Langevin蒙特卡洛算法近似下保持稳定。通过MNIST和CIFAR-10实验验证，这些边界能在真实标注数据上给出有效预测，并对随机标签正确上界测试误差。研究表明，低温插值区域的泛化性能可通过经典高温区域的小训练误差提前预示。",
      "order": 104,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06028v1"
    },
    {
      "arxiv_id": "2510.06025v1",
      "title": "Out-of-Distribution Detection from Small Training Sets using Bayesian\n  Neural Network Classifiers",
      "summary": "Out-of-Distribution (OOD) detection is critical to AI reliability and safety,\nyet in many practical settings, only a limited amount of training data is\navailable. Bayesian Neural Networks (BNNs) are a promising class of model on\nwhich to base OOD detection, because they explicitly represent epistemic (i.e.\nmodel) uncertainty. In the small training data regime, BNNs are especially\nvaluable because they can incorporate prior model information. We introduce a\nnew family of Bayesian posthoc OOD scores based on expected logit vectors, and\ncompare 5 Bayesian and 4 deterministic posthoc OOD scores. Experiments on MNIST\nand CIFAR-10 In-Distributions, with 5000 training samples or less, show that\nthe Bayesian methods outperform corresponding deterministic methods.",
      "authors": [
        "Kevin Raina",
        "Tanya Schmah"
      ],
      "published": "2025-10-07T15:23:05Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06025v1",
      "primary_area": "text_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种基于贝叶斯神经网络的小样本分布外检测方法，通过期望logit向量构建新型检测评分，在MNIST和CIFAR-10数据集上验证显示，贝叶斯方法在训练样本不足5000时显著优于确定性方法。",
      "order": 105,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06025v1"
    },
    {
      "arxiv_id": "2510.06020v1",
      "title": "RamPINN: Recovering Raman Spectra From Coherent Anti-Stokes Spectra\n  Using Embedded Physics",
      "summary": "Transferring the recent advancements in deep learning into scientific\ndisciplines is hindered by the lack of the required large-scale datasets for\ntraining. We argue that in these knowledge-rich domains, the established body\nof scientific theory provides reliable inductive biases in the form of\ngoverning physical laws. We address the ill-posed inverse problem of recovering\nRaman spectra from noisy Coherent Anti-Stokes Raman Scattering (CARS)\nmeasurements, as the true Raman signal here is suppressed by a dominating\nnon-resonant background. We propose RamPINN, a model that learns to recover\nRaman spectra from given CARS spectra. Our core methodological contribution is\na physics-informed neural network that utilizes a dual-decoder architecture to\ndisentangle resonant and non-resonant signals. This is done by enforcing the\nKramers-Kronig causality relations via a differentiable Hilbert transform loss\non the resonant and a smoothness prior on the non-resonant part of the signal.\nTrained entirely on synthetic data, RamPINN demonstrates strong zero-shot\ngeneralization to real-world experimental data, explicitly closing this gap and\nsignificantly outperforming existing baselines. Furthermore, we show that\ntraining with these physics-based losses alone, without access to any\nground-truth Raman spectra, still yields competitive results. This work\nhighlights a broader concept: formal scientific rules can act as a potent\ninductive bias, enabling robust, self-supervised learning in data-limited\nscientific domains.",
      "authors": [
        "Sai Karthikeya Vemuri",
        "Adithya Ashok Chalain Valapil",
        "Tim Büchner",
        "Joachim Denzler"
      ],
      "published": "2025-10-07T15:18:44Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06020v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "medical_ai",
      "tldr_zh": "本文提出RamPINN模型，通过双解码器架构和物理约束损失函数，从噪声CARS光谱中恢复拉曼光谱。该模型利用Kramers-Kronig因果关系和平滑性先验，仅使用合成数据训练即可实现零样本泛化到真实实验数据，在数据有限的科学领域展示了物理规则作为归纳偏置的有效性。",
      "order": 106,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06020v1"
    },
    {
      "arxiv_id": "2510.06007v1",
      "title": "Uncertainty in Machine Learning",
      "summary": "This book chapter introduces the principles and practical applications of\nuncertainty quantification in machine learning. It explains how to identify and\ndistinguish between different types of uncertainty and presents methods for\nquantifying uncertainty in predictive models, including linear regression,\nrandom forests, and neural networks. The chapter also covers conformal\nprediction as a framework for generating predictions with predefined confidence\nintervals. Finally, it explores how uncertainty estimation can be leveraged to\nimprove business decision-making, enhance model reliability, and support\nrisk-aware strategies.",
      "authors": [
        "Hans Weytjens",
        "Wouter Verbeke"
      ],
      "published": "2025-10-07T15:07:27Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.06007v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本章节系统介绍机器学习中的不确定性量化原理与实践应用，涵盖不同类型不确定性的识别区分方法，以及在线性回归、随机森林和神经网络等模型中的量化技术。重点讲解符合预测框架生成预设置信区间预测的方法，并探讨如何利用不确定性估计提升商业决策质量、增强模型可靠性及支持风险感知策略。",
      "order": 107,
      "papers_cool_url": "https://papers.cool/arxiv/2510.06007v1"
    },
    {
      "arxiv_id": "2510.05987v1",
      "title": "Sample Smart, Not Hard: Correctness-First Decoding for Better Reasoning\n  in LLMs",
      "summary": "Large Language Models (LLMs) are increasingly applied to complex tasks that\nrequire extended reasoning. In such settings, models often benefit from diverse\nchains-of-thought to arrive at multiple candidate solutions. This requires two\ncompeting objectives: to inject enough stochasticity to explore multiple\nreasoning chains, and to ensure sufficient accuracy and quality in each path.\nExisting works pursue the first objective by increasing exploration at highly\nuncertain steps with higher temperature or larger candidate token sets, while\nothers improve reliability by rejecting samples with low confidence\npost-generation, implying that low confidence correlates with low answer\nquality. These two lines of thought are in conflict, as they conflate different\nsources of uncertainty. To resolve this, we argue that the decoding rule should\nbe calibrated by correctness, not confidence alone. We should sample from\ntokens with higher estimated correctness, and reduce sampling where expected\ncorrectness is low. We propose simple strategies that achieve this goal:\nGreedy-Threshold makes sampling greedy at very low confidence steps.\nCalibrated-TopK and Calibrated-epsilon set truncation threshold based on\nestimated rank-wise correctness. Together, our findings challenge prevailing\nheuristics about decoding under uncertainty and show gains across math and\ngeneral reasoning benchmarks.",
      "authors": [
        "Xueyan Li",
        "Guinan Su",
        "Mrinmaya Sachan",
        "Jonas Geiping"
      ],
      "published": "2025-10-07T14:46:12Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05987v1",
      "primary_area": "text_models",
      "secondary_focus": "reasoning",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出'正确性优先解码'方法，通过贪婪阈值、校准TopK和校准epsilon等策略，在LLM推理任务中基于正确性而非置信度进行采样，解决了探索多样性与保证准确性之间的矛盾，在数学和通用推理基准上取得显著提升。",
      "order": 108,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05987v1"
    },
    {
      "arxiv_id": "2510.05949v1",
      "title": "Gaussian Embeddings: How JEPAs Secretly Learn Your Data Density",
      "summary": "Joint Embedding Predictive Architectures (JEPAs) learn representations able\nto solve numerous downstream tasks out-of-the-box. JEPAs combine two\nobjectives: (i) a latent-space prediction term, i.e., the representation of a\nslightly perturbed sample must be predictable from the original sample's\nrepresentation, and (ii) an anti-collapse term, i.e., not all samples should\nhave the same representation. While (ii) is often considered as an obvious\nremedy to representation collapse, we uncover that JEPAs' anti-collapse term\ndoes much more--it provably estimates the data density. In short, any\nsuccessfully trained JEPA can be used to get sample probabilities, e.g., for\ndata curation, outlier detection, or simply for density estimation. Our\ntheoretical finding is agnostic of the dataset and architecture used--in any\ncase one can compute the learned probabilities of sample $x$ efficiently and in\nclosed-form using the model's Jacobian matrix at $x$. Our findings are\nempirically validated across datasets (synthetic, controlled, and Imagenet) and\nacross different Self Supervised Learning methods falling under the JEPA family\n(I-JEPA and DINOv2) and on multimodal models, such as MetaCLIP. We denote the\nmethod extracting the JEPA learned density as {\\bf JEPA-SCORE}.",
      "authors": [
        "Randall Balestriero",
        "Nicolas Ballas",
        "Mike Rabbat",
        "Yann LeCun"
      ],
      "published": "2025-10-07T14:06:30Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05949v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文揭示了联合嵌入预测架构(JEPA)在训练过程中，其防坍缩项实际上能够学习数据密度分布。研究发现任何成功训练的JEPA模型均可通过雅可比矩阵高效计算样本概率，适用于数据筛选、异常检测和密度估计等任务。该方法被命名为JEPA-SCORE，并在合成数据、受控数据集及Imagenet上得到验证，适用于I-JEPA、DINOv2等自监督学习方法及多模态模型。",
      "order": 109,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05949v1"
    },
    {
      "arxiv_id": "2510.05935v1",
      "title": "LLM-FS-Agent: A Deliberative Role-based Large Language Model\n  Architecture for Transparent Feature Selection",
      "summary": "High-dimensional data remains a pervasive challenge in machine learning,\noften undermining model interpretability and computational efficiency. While\nLarge Language Models (LLMs) have shown promise for dimensionality reduction\nthrough feature selection, existing LLM-based approaches frequently lack\nstructured reasoning and transparent justification for their decisions. This\npaper introduces LLM-FS-Agent, a novel multi-agent architecture designed for\ninterpretable and robust feature selection. The system orchestrates a\ndeliberative \"debate\" among multiple LLM agents, each assigned a specific role,\nenabling collective evaluation of feature relevance and generation of detailed\njustifications. We evaluate LLM-FS-Agent in the cybersecurity domain using the\nCIC-DIAD 2024 IoT intrusion detection dataset and compare its performance\nagainst strong baselines, including LLM-Select and traditional methods such as\nPCA. Experimental results demonstrate that LLM-FS-Agent consistently achieves\nsuperior or comparable classification performance while reducing downstream\ntraining time by an average of 46% (statistically significant improvement, p =\n0.028 for XGBoost). These findings highlight that the proposed deliberative\narchitecture enhances both decision transparency and computational efficiency,\nestablishing LLM-FS-Agent as a practical and reliable solution for real-world\napplications.",
      "authors": [
        "Mohamed Bal-Ghaoui",
        "Fayssal Sabri"
      ],
      "published": "2025-10-07T13:46:06Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05935v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_architecture', 'reasoning']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出LLM-FS-Agent，一种基于角色分工的多智能体大语言模型架构，通过模拟'辩论'机制实现透明特征选择。在网络安全领域的实验表明，该方法在保持分类性能的同时显著降低46%训练时间，并提供了可解释的决策依据。",
      "order": 110,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05935v1"
    },
    {
      "arxiv_id": "2510.05930v1",
      "title": "Carré du champ flow matching: better quality-generalisation tradeoff\n  in generative models",
      "summary": "Deep generative models often face a fundamental tradeoff: high sample quality\ncan come at the cost of memorisation, where the model reproduces training data\nrather than generalising across the underlying data geometry. We introduce\nCarr\\'e du champ flow matching (CDC-FM), a generalisation of flow matching\n(FM), that improves the quality-generalisation tradeoff by regularising the\nprobability path with a geometry-aware noise. Our method replaces the\nhomogeneous, isotropic noise in FM with a spatially varying, anisotropic\nGaussian noise whose covariance captures the local geometry of the latent data\nmanifold. We prove that this geometric noise can be optimally estimated from\nthe data and is scalable to large data. Further, we provide an extensive\nexperimental evaluation on diverse datasets (synthetic manifolds, point clouds,\nsingle-cell genomics, animal motion capture, and images) as well as various\nneural network architectures (MLPs, CNNs, and transformers). We demonstrate\nthat CDC-FM consistently offers a better quality-generalisation tradeoff. We\nobserve significant improvements over standard FM in data-scarce regimes and in\nhighly non-uniformly sampled datasets, which are often encountered in AI for\nscience applications. Our work provides a mathematical framework for studying\nthe interplay between data geometry, generalisation and memorisation in\ngenerative models, as well as a robust and scalable algorithm that can be\nreadily integrated into existing flow matching pipelines.",
      "authors": [
        "Jacob Bamberger",
        "Iolo Jones",
        "Dennis Duncan",
        "Michael M. Bronstein",
        "Pierre Vandergheynst",
        "Adam Gosztolai"
      ],
      "published": "2025-10-07T13:41:33Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05930v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "['medical_ai', 'general_purpose']",
      "tldr_zh": "本文提出Carré du champ流匹配(CDC-FM)方法，通过引入几何感知噪声改进生成模型的质量-泛化权衡。该方法将传统流匹配中的均匀噪声替换为能捕捉数据流形局部几何特性的空间变化高斯噪声，在数据稀缺和非均匀采样场景下显著优于标准流匹配，适用于科学AI等多种领域。",
      "order": 111,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05930v1"
    },
    {
      "arxiv_id": "2510.05919v1",
      "title": "An Attention-Augmented VAE-BiLSTM Framework for Anomaly Detection in\n  12-Lead ECG Signals",
      "summary": "Anomaly detection in 12-lead electrocardiograms (ECGs) is critical for\nidentifying deviations associated with cardiovascular disease. This work\npresents a comparative analysis of three autoencoder-based architectures:\nconvolutional autoencoder (CAE), variational autoencoder with bidirectional\nlong short-term memory (VAE-BiLSTM), and VAE-BiLSTM with multi-head attention\n(VAE-BiLSTM-MHA), for unsupervised anomaly detection in ECGs. To the best of\nour knowledge, this study reports the first application of a VAE-BiLSTM-MHA\narchitecture to ECG anomaly detection. All models are trained on normal ECG\nsamples to reconstruct non-anomalous cardiac morphology and detect deviations\nindicative of disease. Using a unified preprocessing and evaluation pipeline on\nthe public China Physiological Signal Challenge (CPSC) dataset, the\nattention-augmented VAE achieves the best performance, with an AUPRC of 0.81\nand a recall of 0.85 on the held-out test set, outperforming the other\narchitectures. To support clinical triage, this model is further integrated\ninto an interactive dashboard that visualizes anomaly localization. In\naddition, a performance comparison with baseline models from the literature is\nprovided.",
      "authors": [
        "Marc Garreta Basora",
        "Mehmet Oguz Mulayim"
      ],
      "published": "2025-10-07T13:30:02Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05919v1",
      "primary_area": "audio_models",
      "secondary_focus": "model_architecture",
      "application_domain": "medical_ai",
      "tldr_zh": "本研究提出一种基于注意力增强的VAE-BiLSTM框架，用于12导联心电图信号的异常检测。通过对比三种自编码器架构，在CPSC公开数据集上验证了融合多头注意力的VAE-BiLSTM模型表现最佳（AUPRC 0.81，召回率0.85），并开发了可视化异常定位的交互式仪表板辅助临床分诊。",
      "order": 112,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05919v1"
    },
    {
      "arxiv_id": "2510.05901v1",
      "title": "Paying Attention to Hybrid Attention: Untangling the Issues with\n  Conversion Methods",
      "summary": "Transformers' quadratic computational complexity limits their scalability\ndespite remarkable performance. While linear attention reduces this to linear\ncomplexity, pre-training such models from scratch remains, in most cases,\nprohibitively expensive. Recent post-training linearisation methods convert\npre-trained Transformers to linear models efficiently, often using hybrid\napproaches that combine linear attention with sliding-window softmax. We\nidentify a critical flaw: existing hybrid methods inadvertently bypass the\nlinear component, relying almost entirely on SWA. Component-level diagnostics\nreveal this previously undetected behaviour stems from overlooked evaluation\npractices on common-sense benchmarks. We propose three solutions to ensure\nbalanced component usage: (i) inference-time hybridisation of linear-only\nconversions with sliding-window softmax; (ii) HedgeCATs, combining\nattention-weight transfer with targeted LoRA fine-tuning; and (iii) Scheduled\nSliding-window Dropout (SSD), which stochastically suppresses the softmax\nbranch during training to prevent component collapse. Our methods maintain\ncomputational efficiency while recovering most base model performance and\nensuring genuine linear attention adoption, restoring the validity of\nperformance attributions in hybrid conversions.",
      "authors": [
        "Martin Benfeghoul",
        "Teresa Delgado",
        "Adnan Oomerjee",
        "Haitham Bou Ammar",
        "Jun Wang",
        "Zafeirios Fountas"
      ],
      "published": "2025-10-07T13:11:13Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05901v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文揭示了Transformer后训练线性化方法中的关键缺陷：现有混合注意力方法实际上绕过了线性组件，过度依赖滑动窗口softmax。作者提出三种解决方案——推理时混合、HedgeCATs和计划滑动窗口丢弃(SSD)，在保持计算效率的同时恢复基础模型性能，确保真正的线性注意力采用。",
      "order": 113,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05901v1"
    },
    {
      "arxiv_id": "2510.05879v1",
      "title": "OBSR: Open Benchmark for Spatial Representations",
      "summary": "GeoAI is evolving rapidly, fueled by diverse geospatial datasets like traffic\npatterns, environmental data, and crowdsourced OpenStreetMap (OSM) information.\nWhile sophisticated AI models are being developed, existing benchmarks are\noften concentrated on single tasks and restricted to a single modality. As\nsuch, progress in GeoAI is limited by the lack of a standardized, multi-task,\nmodality-agnostic benchmark for their systematic evaluation. This paper\nintroduces a novel benchmark designed to assess the performance, accuracy, and\nefficiency of geospatial embedders. Our benchmark is modality-agnostic and\ncomprises 7 distinct datasets from diverse cities across three continents,\nensuring generalizability and mitigating demographic biases. It allows for the\nevaluation of GeoAI embedders on various phenomena that exhibit underlying\ngeographic processes. Furthermore, we establish a simple and intuitive\ntask-oriented model baselines, providing a crucial reference point for\ncomparing more complex solutions.",
      "authors": [
        "Julia Moska",
        "Oleksii Furman",
        "Kacper Kozaczko",
        "Szymon Leszkiewicz",
        "Jakub Polczyk",
        "Piotr Gramacki",
        "Piotr Szymański"
      ],
      "published": "2025-10-07T12:48:48Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05879v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出了OBSR——首个用于评估地理空间嵌入表示的开源基准测试，包含来自三大洲7个城市的多样化数据集，支持多任务、多模态评估，并建立了基础模型基准，旨在推动GeoAI领域的标准化发展。",
      "order": 114,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05879v1"
    },
    {
      "arxiv_id": "2510.05874v1",
      "title": "MaNGO - Adaptable Graph Network Simulators via Meta-Learning",
      "summary": "Accurately simulating physics is crucial across scientific domains, with\napplications spanning from robotics to materials science. While traditional\nmesh-based simulations are precise, they are often computationally expensive\nand require knowledge of physical parameters, such as material properties. In\ncontrast, data-driven approaches like Graph Network Simulators (GNSs) offer\nfaster inference but suffer from two key limitations: Firstly, they must be\nretrained from scratch for even minor variations in physical parameters, and\nsecondly they require labor-intensive data collection for each new parameter\nsetting. This is inefficient, as simulations with varying parameters often\nshare a common underlying latent structure. In this work, we address these\nchallenges by learning this shared structure through meta-learning, enabling\nfast adaptation to new physical parameters without retraining. To this end, we\npropose a novel architecture that generates a latent representation by encoding\ngraph trajectories using conditional neural processes (CNPs). To mitigate error\naccumulation over time, we combine CNPs with a novel neural operator\narchitecture. We validate our approach, Meta Neural Graph Operator (MaNGO), on\nseveral dynamics prediction tasks with varying material properties,\ndemonstrating superior performance over existing GNS methods. Notably, MaNGO\nachieves accuracy on unseen material properties close to that of an oracle\nmodel.",
      "authors": [
        "Philipp Dahlinger",
        "Tai Hoang",
        "Denis Blessing",
        "Niklas Freymuth",
        "Gerhard Neumann"
      ],
      "published": "2025-10-07T12:44:24Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05874v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出MaNGO框架，通过元学习解决图网络模拟器在物理参数变化时需要重新训练的问题。结合条件神经过程和新型神经算子架构，能够快速适应新材料属性，在多个动力学预测任务中表现优于现有方法，接近理想模型的精度。",
      "order": 115,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05874v1"
    },
    {
      "arxiv_id": "2510.05856v1",
      "title": "How to model Human Actions distribution with Event Sequence Data",
      "summary": "This paper studies forecasting of the future distribution of events in human\naction sequences, a task essential in domains like retail, finance, healthcare,\nand recommendation systems where the precise temporal order is often less\ncritical than the set of outcomes. We challenge the dominant autoregressive\nparadigm and investigate whether explicitly modeling the future distribution or\norder-invariant multi-token approaches outperform order-preserving methods. We\nanalyze local order invariance and introduce a KL-based metric to quantify\ntemporal drift. We find that a simple explicit distribution forecasting\nobjective consistently surpasses complex implicit baselines. We further\ndemonstrate that mode collapse of predicted categories is primarily driven by\ndistributional imbalance. This work provides a principled framework for\nselecting modeling strategies and offers practical guidance for building more\naccurate and robust forecasting systems.",
      "authors": [
        "Egor Surkov",
        "Dmitry Osin",
        "Evgeny Burnaev",
        "Egor Shvetsov"
      ],
      "published": "2025-10-07T12:24:54Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05856v1",
      "primary_area": "text_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文挑战了传统自回归范式，研究如何通过显式建模未来事件分布或顺序无关的多标记方法来预测人类行为序列的未来分布。研究发现简单的显式分布预测目标优于复杂隐式基线，并提出KL度量量化时间漂移，为构建更准确的预测系统提供理论框架。",
      "order": 116,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05856v1"
    },
    {
      "arxiv_id": "2510.05849v1",
      "title": "ESS-Flow: Training-free guidance of flow-based models as inference in\n  source space",
      "summary": "Guiding pretrained flow-based generative models for conditional generation or\nto produce samples with desired target properties enables solving diverse tasks\nwithout retraining on paired data. We present ESS-Flow, a gradient-free method\nthat leverages the typically Gaussian prior of the source distribution in\nflow-based models to perform Bayesian inference directly in the source space\nusing Elliptical Slice Sampling. ESS-Flow only requires forward passes through\nthe generative model and observation process, no gradient or Jacobian\ncomputations, and is applicable even when gradients are unreliable or\nunavailable, such as with simulation-based observations or quantization in the\ngeneration or observation process. We demonstrate its effectiveness on\ndesigning materials with desired target properties and predicting protein\nstructures from sparse inter-residue distance measurements.",
      "authors": [
        "Adhithyan Kalaivanan",
        "Zheng Zhao",
        "Jens Sjölund",
        "Fredrik Lindsten"
      ],
      "published": "2025-10-07T12:11:58Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05849v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "model_architecture",
      "application_domain": "medical_ai",
      "tldr_zh": "ESS-Flow提出一种无需训练的方法，利用流模型的高斯先验分布，在源空间通过椭圆切片采样进行贝叶斯推断。该方法仅需前向传播，无需梯度计算，适用于材料设计优化和蛋白质结构预测等场景。",
      "order": 117,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05849v1"
    },
    {
      "arxiv_id": "2510.05840v1",
      "title": "Multimodal Trajectory Representation Learning for Travel Time Estimation",
      "summary": "Accurate travel time estimation (TTE) plays a crucial role in intelligent\ntransportation systems. However, it remains challenging due to heterogeneous\ndata sources and complex traffic dynamics. Moreover, conventional approaches\ntypically convert trajectories into fixed-length representations, neglecting\nthe inherent variability of real-world trajectories, which often leads to\ninformation loss or feature redundancy. To address these challenges, this paper\nintroduces the Multimodal Dynamic Trajectory Integration (MDTI) framework--a\nnovel multimodal trajectory representation learning approach that integrates\nGPS sequences, grid trajectories, and road network constraints to enhance TTE\naccuracy. MDTI employs modality-specific encoders and a cross-modal interaction\nmodule to capture complementary spatial, temporal, and topological semantics,\nwhile a dynamic trajectory modeling mechanism adaptively regulates information\ndensity for trajectories of varying lengths. Two self-supervised pretraining\nobjectives, named contrastive alignment and masked language modeling, further\nstrengthen multimodal consistency and contextual understanding. Extensive\nexperiments on three real-world datasets demonstrate that MDTI consistently\noutperforms state-of-the-art baselines, confirming its robustness and strong\ngeneralization abilities. The code is publicly available at:\nhttps://github.com/freshhxy/MDTI/",
      "authors": [
        "Zhi Liu",
        "Xuyuan Hu",
        "Xiao Han",
        "Zhehao Dai",
        "Zhaolin Deng",
        "Guojiang Shen",
        "Xiangjie Kong"
      ],
      "published": "2025-10-07T12:04:16Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05840v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出MDTI多模态轨迹表示学习框架，通过整合GPS序列、网格轨迹和道路网络约束，采用模态特定编码器和跨模态交互模块捕捉时空拓扑语义，结合对比对齐和掩码语言建模预训练目标，在旅行时间估计任务上显著优于现有方法。",
      "order": 118,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05840v1"
    },
    {
      "arxiv_id": "2510.05825v1",
      "title": "Mitigating Premature Exploitation in Particle-based Monte Carlo for\n  Inference-Time Scaling",
      "summary": "Inference-Time Scaling (ITS) improves language models by allocating more\ncomputation at generation time. Particle Filtering (PF) has emerged as a strong\nITS method for complex mathematical reasoning tasks, but it is vulnerable when\nguided by process reward models, which often assign overconfident scores early\nin the reasoning process. This causes PF to suffer from premature exploitation:\nit myopically commits to locally promising trajectories, prunes potentially\ncorrect hypotheses, and converges to suboptimal solutions. This failure mode,\nknown as particle impoverishment, is especially severe under constrained\ncomputational budgets. To address this, we analyze the problem and identify two\nroot causes: a lack of diversity in the particle set due to overconfident\nresampling and consequent inability to assess the potential of a reasoning\npath. We introduce Entropic Particle Filtering (ePF), an algorithm that\nintegrates two new techniques to solve these issues. The first technique,\nEntropic Annealing (EA), directly mitigates particle impoverishment by\nmonitoring search diversity via entropy; when diversity drops, it intervenes by\ndynamically annealing the resampling distribution to preserve exploration. The\nsecond, an enhancement called Look-ahead Modulation (LaM), adds a predictive\nguide to evaluate a state's potential based on its successors. On several\nchallenging math benchmarks, ePF significantly outperforms strong baselines and\nachieves up to a 50 % relative improvement in task reward. Together, these\nmethods improve PF's resilience by balancing the exploration of diverse\nsolution spaces with the exploitation of high-reward regions, ultimately\nleading to higher-quality solutions.",
      "authors": [
        "Giorgio Giannone",
        "Guangxuan Xu",
        "Nikhil Shivakumar Nayak",
        "Rohan Mahesh Awhad",
        "Shivchander Sudalairaj",
        "Kai Xu",
        "Akash Srivastava"
      ],
      "published": "2025-10-07T11:48:32Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05825v1",
      "primary_area": "text_models",
      "secondary_focus": "reasoning",
      "application_domain": "general_purpose",
      "tldr_zh": "本文针对推理时扩展中的粒子滤波方法提出改进，解决过程奖励模型导致的过早利用问题。通过引入熵粒子滤波算法，结合熵退火和前瞻调制技术，在数学推理任务上实现高达50%的性能提升，有效平衡探索与利用。",
      "order": 119,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05825v1"
    },
    {
      "arxiv_id": "2510.05805v1",
      "title": "Improving Clinical Dataset Condensation with Mode Connectivity-based\n  Trajectory Surrogates",
      "summary": "Dataset condensation (DC) enables the creation of compact, privacy-preserving\nsynthetic datasets that can match the utility of real patient records,\nsupporting democratised access to highly regulated clinical data for developing\ndownstream clinical models. State-of-the-art DC methods supervise synthetic\ndata by aligning the training dynamics of models trained on real and those\ntrained on synthetic data, typically using full stochastic gradient descent\n(SGD) trajectories as alignment targets; however, these trajectories are often\nnoisy, high-curvature, and storage-intensive, leading to unstable gradients,\nslow convergence, and substantial memory overhead. We address these limitations\nby replacing full SGD trajectories with smooth, low-loss parametric surrogates,\nspecifically quadratic B\\'ezier curves that connect the initial and final model\nstates from real training trajectories. These mode-connected paths provide\nnoise-free, low-curvature supervision signals that stabilise gradients,\naccelerate convergence, and eliminate the need for dense trajectory storage. We\ntheoretically justify B\\'ezier-mode connections as effective surrogates for SGD\npaths and empirically show that the proposed method outperforms\nstate-of-the-art condensation approaches across five clinical datasets,\nyielding condensed datasets that enable clinically effective model development.",
      "authors": [
        "Pafue Christy Nganjimi",
        "Andrew Soltan",
        "Danielle Belgrave",
        "Lei Clifton",
        "David A. Clifton",
        "Anshul Thakur"
      ],
      "published": "2025-10-07T11:22:27Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05805v1",
      "primary_area": "training_optimization",
      "secondary_focus": "model_compression",
      "application_domain": "medical_ai",
      "tldr_zh": "本文提出一种基于模态连接轨迹代理的临床数据集压缩方法，用平滑的二次贝塞尔曲线替代传统噪声大、存储密集的SGD训练轨迹，在五个临床数据集上实现更稳定、高效的压缩效果，支持隐私保护的临床模型开发。",
      "order": 120,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05805v1"
    },
    {
      "arxiv_id": "2510.05777v1",
      "title": "DP-SNP-TIHMM: Differentially Private, Time-Inhomogeneous Hidden Markov\n  Models for Synthesizing Genome-Wide Association Datasets",
      "summary": "Single nucleotide polymorphism (SNP) datasets are fundamental to genetic\nstudies but pose significant privacy risks when shared. The correlation of SNPs\nwith each other makes strong adversarial attacks such as masked-value\nreconstruction, kin, and membership inference attacks possible. Existing\nprivacy-preserving approaches either apply differential privacy to statistical\nsummaries of these datasets or offer complex methods that require\npost-processing and the usage of a publicly available dataset to suppress or\nselectively share SNPs.\n  In this study, we introduce an innovative framework for generating synthetic\nSNP sequence datasets using samples derived from time-inhomogeneous hidden\nMarkov models (TIHMMs). To preserve the privacy of the training data, we ensure\nthat each SNP sequence contributes only a bounded influence during training,\nenabling strong differential privacy guarantees. Crucially, by operating on\nfull SNP sequences and bounding their gradient contributions, our method\ndirectly addresses the privacy risks introduced by their inherent correlations.\n  Through experiments conducted on the real-world 1000 Genomes dataset, we\ndemonstrate the efficacy of our method using privacy budgets of $\\varepsilon\n\\in [1, 10]$ at $\\delta=10^{-4}$. Notably, by allowing the transition models of\nthe HMM to be dependent on the location in the sequence, we significantly\nenhance performance, enabling the synthetic datasets to closely replicate the\nstatistical properties of non-private datasets. This framework facilitates the\nprivate sharing of genomic data while offering researchers exceptional\nflexibility and utility.",
      "authors": [
        "Shadi Rahimian",
        "Mario Fritz"
      ],
      "published": "2025-10-07T10:47:29Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05777v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "model_architecture",
      "application_domain": "medical_ai",
      "tldr_zh": "本文提出DP-SNP-TIHMM框架，使用时变隐马尔可夫模型结合差分隐私技术生成合成基因组关联数据集。该方法通过限制单核苷酸多态性序列的梯度贡献来保护训练数据隐私，在ε∈[1,10]的隐私预算下，能有效复制非私有数据集的统计特性，解决了基因组数据共享中的隐私风险问题。",
      "order": 121,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05777v1"
    },
    {
      "arxiv_id": "2510.05753v1",
      "title": "Empirical Comparison of Membership Inference Attacks in Deep Transfer\n  Learning",
      "summary": "With the emergence of powerful large-scale foundation models, the training\nparadigm is increasingly shifting from from-scratch training to transfer\nlearning. This enables high utility training with small, domain-specific\ndatasets typical in sensitive applications.Membership inference attacks (MIAs)\nprovide an empirical estimate of the privacy leakage by machine learning\nmodels. Yet, prior assessments of MIAs against models fine-tuned with transfer\nlearning rely on a small subset of possible attacks. We address this by\ncomparing performance of diverse MIAs in transfer learning settings to help\npractitioners identify the most efficient attacks for privacy risk evaluation.\nWe find that attack efficacy decreases with the increase in training data for\nscore-based MIAs. We find that there is no one MIA which captures all privacy\nrisks in models trained with transfer learning. While the Likelihood Ratio\nAttack (LiRA) demonstrates superior performance across most experimental\nscenarios, the Inverse Hessian Attack (IHA) proves to be more effective against\nmodels fine-tuned on PatchCamelyon dataset in high data regime.",
      "authors": [
        "Yuxuan Bai",
        "Gauri Pradhan",
        "Marlon Tobaben",
        "Antti Honkela"
      ],
      "published": "2025-10-07T10:21:05Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05753v1",
      "primary_area": "text_models",
      "secondary_focus": "training_optimization",
      "application_domain": "medical_ai",
      "tldr_zh": "本文在深度迁移学习背景下，系统比较了多种成员推断攻击方法的性能。研究发现，基于分数的攻击效果随训练数据增加而下降，且不存在单一最优攻击方法。虽然似然比攻击在多数场景表现最佳，但在PatchCamelyon医学数据集的高数据量场景中，逆海森攻击更为有效。",
      "order": 122,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05753v1"
    },
    {
      "arxiv_id": "2510.05750v1",
      "title": "Are Heterogeneous Graph Neural Networks Truly Effective? A Causal\n  Perspective",
      "summary": "Graph neural networks (GNNs) have achieved remarkable success in node\nclassification. Building on this progress, heterogeneous graph neural networks\n(HGNNs) integrate relation types and node and edge semantics to leverage\nheterogeneous information. Causal analysis for HGNNs is advancing rapidly,\naiming to separate genuine causal effects from spurious correlations. However,\nwhether HGNNs are intrinsically effective remains underexamined, and most\nstudies implicitly assume rather than establish this effectiveness. In this\nwork, we examine HGNNs from two perspectives: model architecture and\nheterogeneous information. We conduct a systematic reproduction across 21\ndatasets and 20 baselines, complemented by comprehensive hyperparameter\nretuning. To further disentangle the source of performance gains, we develop a\ncausal effect estimation framework that constructs and evaluates candidate\nfactors under standard assumptions through factual and counterfactual analyses,\nwith robustness validated via minimal sufficient adjustment sets, cross-method\nconsistency checks, and sensitivity analyses. Our results lead to two\nconclusions. First, model architecture and complexity have no causal effect on\nperformance. Second, heterogeneous information exerts a positive causal effect\nby increasing homophily and local-global distribution discrepancy, which makes\nnode classes more distinguishable. The implementation is publicly available at\nhttps://github.com/YXNTU/CausalHGNN.",
      "authors": [
        "Xiao Yang",
        "Xuejiao Zhao",
        "Zhiqi Shen"
      ],
      "published": "2025-10-07T10:12:21Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05750v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_architecture', 'reasoning']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文从因果视角系统评估异质图神经网络(HGNNs)的有效性，通过对21个数据集和20个基线的复现实验，结合因果效应估计框架发现：模型架构对性能无因果影响，而异质信息通过增强同配性和局部分布差异产生正向因果效应。",
      "order": 123,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05750v1"
    },
    {
      "arxiv_id": "2510.05748v1",
      "title": "Communication Enables Cooperation in LLM Agents: A Comparison with\n  Curriculum-Based Approaches",
      "summary": "Eliciting cooperation in multi-agent LLM systems is critical for AI\nalignment. We investigate two approaches: direct communication and curriculum\nlearning. In a 4-player Stag Hunt, a one-word \"cheap talk\" channel increases\ncooperation from 0% to 48.3%, demonstrating communication as a robust\ncoordination mechanism. In contrast, we find that curriculum learning is highly\nsensitive to design choices: our pedagogical curriculum through progressively\ncomplex games reduced agent payoffs by 27.4% in an Iterated Public Goods Game\nwith Punishment. Qualitative analysis reveals that curricula emphasizing\ndefection-equilibrium games can induce \"learned pessimism\" in agents. These\nfindings suggest that for coordination problems, simple communication protocols\nmay be more reliable than experience-based training, and that curriculum design\nfor social dilemmas requires careful attention to the strategic lessons\nembedded in game sequences.",
      "authors": [
        "Hachem Madmoun",
        "Salem Lahlou"
      ],
      "published": "2025-10-07T10:06:29Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05748v1",
      "primary_area": "text_models",
      "secondary_focus": "['alignment', 'reasoning']",
      "application_domain": "general_purpose",
      "tldr_zh": "本研究比较了多智能体LLM系统中的两种合作促进方法：直接通信与课程学习。在4玩家猎鹿博弈中，简单的单词语信通道将合作率从0%提升至48.3%，证明通信是有效的协调机制。而课程学习对设计极为敏感：在迭代公共物品惩罚博弈中，渐进式复杂游戏的课程设计反而使智能体收益下降27.4%。定性分析表明，强调背叛均衡的课程会导致智能体产生'习得性悲观'。研究建议在协调问题中，简单通信协议比经验训练更可靠，社会困境的课程设计需谨慎考虑游戏序列嵌入的战略教训。",
      "order": 124,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05748v1"
    },
    {
      "arxiv_id": "2510.05725v1",
      "title": "Improving Discrete Diffusion Unmasking Policies Beyond Explicit\n  Reference Policies",
      "summary": "Masked diffusion models (MDMs) have recently emerged as a novel framework for\nlanguage modeling. MDMs generate sentences by iteratively denoising masked\nsequences, filling in [MASK] tokens step by step. Although MDMs support\nany-order sampling, performance is highly sensitive to the choice of which\nposition to unmask next. Prior work typically relies on rule-based schedules\n(e.g., max-confidence, max-margin), which provide ad hoc improvements. In\ncontrast, we replace these heuristics with a learned scheduler. Specifically,\nwe cast denoising as a KL-regularized Markov decision process (MDP) with an\nexplicit reference policy and optimize a regularized objective that admits\npolicy improvement and convergence guarantees under standard assumptions. We\nprove that the optimized policy under this framework generates samples that\nmore closely match the data distribution than heuristic schedules. Empirically,\nacross four benchmarks, our learned policy consistently outperforms\nmax-confidence: for example, on SUDOKU, where unmasking order is critical, it\nyields a 20.1% gain over random and a 11.2% gain over max-confidence.",
      "authors": [
        "Chunsan Hong",
        "Seonho An",
        "Min-Soo Kim",
        "Jong Chul Ye"
      ],
      "published": "2025-10-07T09:44:24Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05725v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种基于KL正则化MDP框架的学习型调度器，替代传统掩码扩散模型中的启发式解掩策略。通过理论证明和四组基准实验验证，该策略在SUDOKU任务上相比随机策略提升20.1%，较最大置信度策略提升11.2%，能生成更贴合数据分布的文本。",
      "order": 125,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05725v1"
    },
    {
      "arxiv_id": "2510.05719v1",
      "title": "Neighborhood-Adaptive Generalized Linear Graph Embedding with Latent\n  Pattern Mining",
      "summary": "Graph embedding has been widely applied in areas such as network analysis,\nsocial network mining, recommendation systems, and bioinformatics. However,\ncurrent graph construction methods often require the prior definition of\nneighborhood size, limiting the effective revelation of potential structural\ncorrelations in the data. Additionally, graph embedding methods using linear\nprojection heavily rely on a singular pattern mining approach, resulting in\nrelative weaknesses in adapting to different scenarios. To address these\nchallenges, we propose a novel model, Neighborhood-Adaptive Generalized Linear\nGraph Embedding (NGLGE), grounded in latent pattern mining. This model\nintroduces an adaptive graph learning method tailored to the neighborhood,\neffectively revealing intrinsic data correlations. Simultaneously, leveraging a\nreconstructed low-rank representation and imposing $\\ell_{2,0}$ norm constraint\non the projection matrix allows for flexible exploration of additional pattern\ninformation. Besides, an efficient iterative solving algorithm is derived for\nthe proposed model. Comparative evaluations on datasets from diverse scenarios\ndemonstrate the superior performance of our model compared to state-of-the-art\nmethods.",
      "authors": [
        "S. Peng",
        "L. Hu",
        "W. Zhang",
        "B. Jie",
        "Y. Luo"
      ],
      "published": "2025-10-07T09:37:29Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05719v1",
      "primary_area": "model_architecture",
      "secondary_focus": "training_optimization",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种基于潜在模式挖掘的邻域自适应广义线性图嵌入模型(NGLGE)，通过自适应图学习方法揭示数据内在关联，并利用重构低秩表示与ℓ₂,₀范数约束灵活探索额外模式信息，在多种场景数据集上优于现有方法。",
      "order": 126,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05719v1"
    },
    {
      "arxiv_id": "2510.05717v1",
      "title": "DiffSDA: Unsupervised Diffusion Sequential Disentanglement Across\n  Modalities",
      "summary": "Unsupervised representation learning, particularly sequential\ndisentanglement, aims to separate static and dynamic factors of variation in\ndata without relying on labels. This remains a challenging problem, as existing\napproaches based on variational autoencoders and generative adversarial\nnetworks often rely on multiple loss terms, complicating the optimization\nprocess. Furthermore, sequential disentanglement methods face challenges when\napplied to real-world data, and there is currently no established evaluation\nprotocol for assessing their performance in such settings. Recently, diffusion\nmodels have emerged as state-of-the-art generative models, but no theoretical\nformalization exists for their application to sequential disentanglement. In\nthis work, we introduce the Diffusion Sequential Disentanglement Autoencoder\n(DiffSDA), a novel, modal-agnostic framework effective across diverse\nreal-world data modalities, including time series, video, and audio. DiffSDA\nleverages a new probabilistic modeling, latent diffusion, and efficient\nsamplers, while incorporating a challenging evaluation protocol for rigorous\ntesting. Our experiments on diverse real-world benchmarks demonstrate that\nDiffSDA outperforms recent state-of-the-art methods in sequential\ndisentanglement.",
      "authors": [
        "Hedi Zisling",
        "Ilan Naiman",
        "Nimrod Berman",
        "Supasorn Suwajanakorn",
        "Omri Azencot"
      ],
      "published": "2025-10-07T09:30:36Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05717v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出DiffSDA，一种基于扩散模型的无监督序列解缠框架，能够跨模态分离数据的静态与动态特征。该模型通过概率建模、潜在扩散和高效采样器，在时间序列、视频和音频等多种真实数据上优于现有方法，并建立了严格的评估协议。",
      "order": 127,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05717v1"
    },
    {
      "arxiv_id": "2510.05703v1",
      "title": "Primal-Dual Direct Preference Optimization for Constrained LLM Alignment",
      "summary": "The widespread application of Large Language Models (LLMs) imposes increasing\ndemands on safety, such as reducing harmful content and fake information, and\navoiding certain forbidden tokens due to rules and laws. While there have been\nseveral recent works studying safe alignment of LLMs, these works either\nrequire the training of reward and cost models and incur high memory and\ncomputational costs, or need prior knowledge about the optimal solution.\nMotivated by this fact, we study the problem of constrained alignment in LLMs,\ni.e., maximizing the output reward while restricting the cost due to\npotentially unsafe content to stay below a threshold. For this problem, we\npropose a novel primal-dual DPO approach, which first trains a model using\nstandard DPO on reward preference data to provide reward information, and then\nadopts a rearranged Lagrangian DPO objective utilizing the provided reward\ninformation to fine-tune LLMs on cost preference data. Our approach\nsignificantly reduces memory and computational costs, and does not require\nextra prior knowledge. Moreover, we establish rigorous theoretical guarantees\non the suboptimality and constraint violation of the output policy. We also\nextend our approach to an online data setting by incorporating exploration\nbonuses, which enables our approach to explore uncovered prompt-response space,\nand then provide theoretical results that get rid of the dependence on\npreference data coverage. Experimental results on the widely-used preference\ndataset PKU-SafeRLHF demonstrate the effectiveness of our approach.",
      "authors": [
        "Yihan Du",
        "Seo Taek Kong",
        "R. Srikant"
      ],
      "published": "2025-10-07T09:10:35Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05703v1",
      "primary_area": "text_models",
      "secondary_focus": "['alignment', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种原始-对偶直接偏好优化方法，用于约束条件下的大语言模型对齐。该方法无需训练奖励/成本模型，显著降低计算成本，通过重组拉格朗日DPO目标实现安全约束下的奖励最大化，并在PKU-SafeRLHF数据集上验证了有效性。",
      "order": 128,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05703v1"
    },
    {
      "arxiv_id": "2510.05688v1",
      "title": "vAttention: Verified Sparse Attention",
      "summary": "State-of-the-art sparse attention methods for reducing decoding latency fall\ninto two main categories: approximate top-$k$ (and its extension, top-$p$) and\nrecently introduced sampling-based estimation. However, these approaches are\nfundamentally limited in their ability to approximate full attention: they fail\nto provide consistent approximations across heads and query vectors and, most\ncritically, lack guarantees on approximation quality, limiting their practical\ndeployment. We observe that top-$k$ and random sampling are complementary:\ntop-$k$ performs well when attention scores are dominated by a few tokens,\nwhereas random sampling provides better estimates when attention scores are\nrelatively uniform. Building on this insight and leveraging the statistical\nguarantees of sampling, we introduce vAttention, the first practical sparse\nattention mechanism with user-specified $(\\epsilon, \\delta)$ guarantees on\napproximation accuracy (thus, verified). These guarantees make vAttention a\ncompelling step toward practical, reliable deployment of sparse attention at\nscale. By unifying top-k and sampling, vAttention outperforms both\nindividually, delivering a superior quality-efficiency trade-off. Our\nexperiments show that vAttention significantly improves the quality of sparse\nattention (e.g., $\\sim$4.5 percentage points for Llama-3.1-8B-Inst and\nDeepseek-R1-Distill-Llama-8B on RULER-HARD), and effectively bridges the gap\nbetween full and sparse attention (e.g., across datasets, it matches full model\nquality with upto 20x sparsity). We also demonstrate that it can be deployed in\nreasoning scenarios to achieve fast decoding without compromising model quality\n(e.g., vAttention achieves full model quality on AIME2024 at 10x sparsity with\nup to 32K token generations). Code is open-sourced at\nhttps://github.com/xAlg-ai/sparse-attention-hub.",
      "authors": [
        "Aditya Desai",
        "Kumar Krishna Agrawal",
        "Shuo Yang",
        "Alejandro Cuadron",
        "Luis Gaspar Schroeder",
        "Matei Zaharia",
        "Joseph E. Gonzalez",
        "Ion Stoica"
      ],
      "published": "2025-10-07T08:46:08Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05688v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_architecture', 'model_compression']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出vAttention，首个具有用户指定(ε,δ)精度保证的实用稀疏注意力机制。通过统一top-k和随机采样的优势，在Llama-3.1等模型上显著提升稀疏注意力质量（RULER-HARD提升约4.5个百分点），在32K生成长度下实现10倍稀疏度同时保持完整模型质量，为大规模可靠部署稀疏注意力迈出关键一步。",
      "order": 129,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05688v1"
    },
    {
      "arxiv_id": "2510.05683v1",
      "title": "QGraphLIME - Explaining Quantum Graph Neural Networks",
      "summary": "Quantum graph neural networks offer a powerful paradigm for learning on\ngraph-structured data, yet their explainability is complicated by\nmeasurement-induced stochasticity and the combinatorial nature of graph\nstructure. In this paper, we introduce QuantumGraphLIME (QGraphLIME), a\nmodel-agnostic, post-hoc framework that treats model explanations as\ndistributions over local surrogates fit on structure-preserving perturbations\nof a graph. By aggregating surrogate attributions together with their\ndispersion, QGraphLIME yields uncertainty-aware node and edge importance\nrankings for quantum graph models. The framework further provides a\ndistribution-free, finite-sample guarantee on the size of the surrogate\nensemble: a Dvoretzky-Kiefer-Wolfowitz bound ensures uniform approximation of\nthe induced distribution of a binary class probability at target accuracy and\nconfidence under standard independence assumptions. Empirical studies on\ncontrolled synthetic graphs with known ground truth demonstrate accurate and\nstable explanations, with ablations showing clear benefits of nonlinear\nsurrogate modeling and highlighting sensitivity to perturbation design.\nCollectively, these results establish a principled, uncertainty-aware, and\nstructure-sensitive approach to explaining quantum graph neural networks, and\nlay the groundwork for scaling to broader architectures and real-world\ndatasets, as quantum resources mature. Code is available at\nhttps://github.com/smlab-niser/qglime.",
      "authors": [
        "Haribandhu Jena",
        "Jyotirmaya Shivottam",
        "Subhankar Mishra"
      ],
      "published": "2025-10-07T08:39:13Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05683v1",
      "primary_area": "model_architecture",
      "secondary_focus": "reasoning",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出QGraphLIME框架，通过构建局部代理模型的分布来解释量子图神经网络，提供具有不确定性感知的节点和边重要性排序，并给出理论保证和实证验证。",
      "order": 130,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05683v1"
    },
    {
      "arxiv_id": "2510.05676v1",
      "title": "Inductive inference of gradient-boosted decision trees on graphs for\n  insurance fraud detection",
      "summary": "Graph-based methods are becoming increasingly popular in machine learning due\nto their ability to model complex data and relations. Insurance fraud is a\nprime use case, since false claims are often the result of organised criminals\nthat stage accidents or the same persons filing erroneous claims on multiple\npolicies. One challenge is that graph-based approaches struggle to find\nmeaningful representations of the data because of the high class imbalance\npresent in fraud data. Another is that insurance networks are heterogeneous and\ndynamic, given the changing relations among people, companies and policies.\nThat is why gradient boosted tree approaches on tabular data still dominate the\nfield. Therefore, we present a novel inductive graph gradient boosting machine\n(G-GBM) for supervised learning on heterogeneous and dynamic graphs. We show\nthat our estimator competes with popular graph neural network approaches in an\nexperiment using a variety of simulated random graphs. We demonstrate the power\nof G-GBM for insurance fraud detection using an open-source and a real-world,\nproprietary dataset. Given that the backbone model is a gradient boosting\nforest, we apply established explainability methods to gain better insights\ninto the predictions made by G-GBM.",
      "authors": [
        "Félix Vandervorst",
        "Bruno Deprez",
        "Wouter Verbeke",
        "Tim Verdonck"
      ],
      "published": "2025-10-07T08:35:12Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05676v1",
      "primary_area": "text_models",
      "secondary_focus": "model_architecture",
      "application_domain": "financial_ai",
      "tldr_zh": "本文提出一种新型归纳图梯度提升机(G-GBM)，用于异构动态图上的监督学习，专门解决保险欺诈检测中的类别不平衡和网络动态性问题。该方法结合梯度提升树与图结构建模，在模拟图和真实数据集上表现优于传统图神经网络，并保持梯度提升模型的可解释性优势。",
      "order": 131,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05676v1"
    },
    {
      "arxiv_id": "2510.05670v1",
      "title": "Quantifying the Accuracy-Interpretability Trade-Off in Concept-Based\n  Sidechannel Models",
      "summary": "Concept Bottleneck Models (CBNMs) are deep learning models that provide\ninterpretability by enforcing a bottleneck layer where predictions are based\nexclusively on human-understandable concepts. However, this constraint also\nrestricts information flow and often results in reduced predictive accuracy.\nConcept Sidechannel Models (CSMs) address this limitation by introducing a\nsidechannel that bypasses the bottleneck and carry additional task-relevant\ninformation. While this improves accuracy, it simultaneously compromises\ninterpretability, as predictions may rely on uninterpretable representations\ntransmitted through sidechannels. Currently, there exists no principled\ntechnique to control this fundamental trade-off. In this paper, we close this\ngap. First, we present a unified probabilistic concept sidechannel meta-model\nthat subsumes existing CSMs as special cases. Building on this framework, we\nintroduce the Sidechannel Independence Score (SIS), a metric that quantifies a\nCSM's reliance on its sidechannel by contrasting predictions made with and\nwithout sidechannel information. We propose SIS regularization, which\nexplicitly penalizes sidechannel reliance to improve interpretability. Finally,\nwe analyze how the expressivity of the predictor and the reliance of the\nsidechannel jointly shape interpretability, revealing inherent trade-offs\nacross different CSM architectures. Empirical results show that\nstate-of-the-art CSMs, when trained solely for accuracy, exhibit low\nrepresentation interpretability, and that SIS regularization substantially\nimproves their interpretability, intervenability, and the quality of learned\ninterpretable task predictors. Our work provides both theoretical and practical\ntools for developing CSMs that balance accuracy and interpretability in a\nprincipled manner.",
      "authors": [
        "David Debot",
        "Giuseppe Marra"
      ],
      "published": "2025-10-07T08:29:34Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05670v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_architecture', 'alignment']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出概念侧信道模型(CSMs)的统一概率框架，引入侧信道独立性评分(SIS)来量化模型在可解释性与准确性之间的权衡。通过SIS正则化方法，显著提升了现有CSM模型的可解释性、可干预性和学习质量，为平衡模型性能与可解释性提供了理论工具和实践方案。",
      "order": 132,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05670v1"
    },
    {
      "arxiv_id": "2510.05635v1",
      "title": "NEO: No-Optimization Test-Time Adaptation through Latent Re-Centering",
      "summary": "Test-Time Adaptation (TTA) methods are often computationally expensive,\nrequire a large amount of data for effective adaptation, or are brittle to\nhyperparameters. Based on a theoretical foundation of the geometry of the\nlatent space, we are able to significantly improve the alignment between source\nand distribution-shifted samples by re-centering target data embeddings at the\norigin. This insight motivates NEO -- a hyperparameter-free fully TTA method,\nthat adds no significant compute compared to vanilla inference. NEO is able to\nimprove the classification accuracy of ViT-Base on ImageNet-C from 55.6% to\n59.2% after adapting on just one batch of 64 samples. When adapting on 512\nsamples NEO beats all 7 TTA methods we compare against on ImageNet-C,\nImageNet-R and ImageNet-S and beats 6/7 on CIFAR-10-C, while using the least\namount of compute. NEO performs well on model calibration metrics and\nadditionally is able to adapt from 1 class to improve accuracy on 999 other\nclasses in ImageNet-C. On Raspberry Pi and Jetson Orin Nano devices, NEO\nreduces inference time by 63% and memory usage by 9% compared to baselines. Our\nresults based on 3 ViT architectures and 4 datasets show that NEO can be used\nefficiently and effectively for TTA.",
      "authors": [
        "Alexander Murphy",
        "Michal Danilowski",
        "Soumyajit Chatterjee",
        "Abhirup Ghosh"
      ],
      "published": "2025-10-07T07:35:55Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05635v1",
      "primary_area": "vla_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出NEO方法，一种无需优化的测试时自适应技术，通过潜在空间重中心化显著提升分布偏移下的分类准确率。该方法无需超参数调优，计算开销极低，在多个数据集上超越现有TTA方法，并在边缘设备上实现63%的推理加速和9%的内存节省。",
      "order": 133,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05635v1"
    },
    {
      "arxiv_id": "2510.05620v1",
      "title": "Monte Carlo-Type Neural Operator for Differential Equations",
      "summary": "The Monte Carlo-type Neural Operator (MCNO) introduces a framework for\nlearning solution operators of one-dimensional partial differential equations\n(PDEs) by directly learning the kernel function and approximating the\nassociated integral operator using a Monte Carlo-type approach. Unlike Fourier\nNeural Operators (FNOs), which rely on spectral representations and assume\ntranslation-invariant kernels, MCNO makes no such assumptions. The kernel is\nrepresented as a learnable tensor over sampled input-output pairs, and sampling\nis performed once, uniformly at random from a discretized grid. This design\nenables generalization across multiple grid resolutions without relying on\nfixed global basis functions or repeated sampling during training, while an\ninterpolation step maps between arbitrary input and output grids to further\nenhance flexibility. Experiments on standard 1D PDE benchmarks show that MCNO\nachieves competitive accuracy with efficient computational cost. We also\nprovide a theoretical analysis proving that the Monte Carlo estimator yields a\nbounded bias and variance under mild regularity assumptions. This result holds\nin any spatial dimension, suggesting that MCNO may extend naturally beyond\none-dimensional problems. More broadly, this work explores how Monte Carlo-type\nintegration can be incorporated into neural operator frameworks for\ncontinuous-domain PDEs, providing a theoretically supported alternative to\nspectral methods (such as FNO) and to graph-based Monte Carlo approaches (such\nas the Graph Kernel Neural Operator, GNO).",
      "authors": [
        "Salah Eddine Choutri",
        "Prajwal Chauhan",
        "Othmane Mazhar",
        "Saif Eddin Jabari"
      ],
      "published": "2025-10-07T07:07:04Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05620v1",
      "primary_area": "model_architecture",
      "secondary_focus": "reasoning",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出蒙特卡洛型神经算子(MCNO)，通过直接学习核函数并采用蒙特卡洛方法逼近积分算子来求解一维偏微分方程。与傅里叶神经算子不同，MCNO不依赖谱表示和平移不变性假设，通过可学习张量表示核函数，支持多网格分辨率泛化。实验显示其在标准基准测试中达到竞争性精度，理论分析证明其估计器具有有界偏差和方差，并具备向高维问题扩展的潜力。",
      "order": 134,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05620v1"
    },
    {
      "arxiv_id": "2510.05606v1",
      "title": "Riddled basin geometry sets fundamental limits to predictability and\n  reproducibility in deep learning",
      "summary": "Fundamental limits to predictability are central to our understanding of many\nphysical and computational systems. Here we show that, despite its remarkable\ncapabilities, deep learning exhibits such fundamental limits rooted in the\nfractal, riddled geometry of its basins of attraction: any initialization that\nleads to one solution lies arbitrarily close to another that leads to a\ndifferent one. We derive sufficient conditions for the emergence of riddled\nbasins by analytically linking features widely observed in deep learning,\nincluding chaotic learning dynamics and symmetry-induced invariant subspaces,\nto reveal a general route to riddling in realistic deep networks. The resulting\nbasins of attraction possess an infinitely fine-scale fractal structure\ncharacterized by an uncertainty exponent near zero, so that even large\nincreases in the precision of initial conditions yield only marginal gains in\noutcome predictability. Riddling thus imposes a fundamental limit on the\npredictability and hence reproducibility of neural network training, providing\na unified account of many empirical observations. These results reveal a\ngeneral organizing principle of deep learning with important implications for\noptimization and the safe deployment of artificial intelligence.",
      "authors": [
        "Andrew Ly",
        "Pulin Gong"
      ],
      "published": "2025-10-07T06:02:58Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05606v1",
      "primary_area": "training_optimization",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "本文揭示了深度学习训练中吸引盆的混沌分形几何结构会从根本上限制模型的可预测性与可复现性。研究表明，任何收敛到某个解的初始化参数都无限接近另一组会导致不同解的参数，这种'迷宫式吸引盆'结构使得即使大幅提高参数初始化精度，对训练结果的预测能力提升也微乎其微。该发现为理解深度学习优化过程提供了统一的理论框架，对AI安全部署具有重要意义。",
      "order": 135,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05606v1"
    },
    {
      "arxiv_id": "2510.05589v1",
      "title": "Deciphering Invariant Feature Decoupling in Source-free Time Series\n  Forecasting with Proxy Denoising",
      "summary": "The proliferation of mobile devices generates a massive volume of time series\nacross various domains, where effective time series forecasting enables a\nvariety of real-world applications. This study focuses on a new problem of\nsource-free domain adaptation for time series forecasting. It aims to adapt a\npretrained model from sufficient source time series to the sparse target time\nseries domain without access to the source data, embracing data protection\nregulations. To achieve this, we propose TimePD, the first source-free time\nseries forecasting framework with proxy denoising, where large language models\n(LLMs) are employed to benefit from their generalization capabilities.\nSpecifically, TimePD consists of three key components: (1) dual-branch\ninvariant disentangled feature learning that enforces representation- and\ngradient-wise invariance by means of season-trend decomposition; (2)\nlightweight, parameter-free proxy denoising that dynamically calibrates\nsystematic biases of LLMs; and (3) knowledge distillation that bidirectionally\naligns the denoised prediction and the original target prediction. Extensive\nexperiments on real-world datasets offer insight into the effectiveness of the\nproposed TimePD, outperforming SOTA baselines by 9.3% on average.",
      "authors": [
        "Kangjia Yan",
        "Chenxi Liu",
        "Hao Miao",
        "Xinle Wu",
        "Yan Zhao",
        "Chenjuan Guo",
        "Bin Yang"
      ],
      "published": "2025-10-07T05:29:18Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05589v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出首个源数据自由的时序预测框架TimePD，通过三重创新解决隐私保护下的跨域预测难题：基于季节-趋势分解的双分支不变特征解耦、轻量级LLM代理去噪动态校准系统偏差、双向知识蒸馏对齐预测结果。在真实数据集上平均性能超越现有最佳方法9.3%，为移动设备时序数据分析提供隐私合规新方案。",
      "order": 136,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05589v1"
    },
    {
      "arxiv_id": "2510.05583v1",
      "title": "When Does Global Attention Help? A Unified Empirical Study on Atomistic\n  Graph Learning",
      "summary": "Graph neural networks (GNNs) are widely used as surrogates for costly\nexperiments and first-principles simulations to study the behavior of compounds\nat atomistic scale, and their architectural complexity is constantly increasing\nto enable the modeling of complex physics. While most recent GNNs combine more\ntraditional message passing neural networks (MPNNs) layers to model short-range\ninteractions with more advanced graph transformers (GTs) with global attention\nmechanisms to model long-range interactions, it is still unclear when global\nattention mechanisms provide real benefits over well-tuned MPNN layers due to\ninconsistent implementations, features, or hyperparameter tuning. We introduce\nthe first unified, reproducible benchmarking framework - built on HydraGNN -\nthat enables seamless switching among four controlled model classes: MPNN, MPNN\nwith chemistry/topology encoders, GPS-style hybrids of MPNN with global\nattention, and fully fused local - global models with encoders. Using seven\ndiverse open-source datasets for benchmarking across regression and\nclassification tasks, we systematically isolate the contributions of message\npassing, global attention, and encoder-based feature augmentation. Our study\nshows that encoder-augmented MPNNs form a robust baseline, while fused\nlocal-global models yield the clearest benefits for properties governed by\nlong-range interaction effects. We further quantify the accuracy - compute\ntrade-offs of attention, reporting its overhead in memory. Together, these\nresults establish the first controlled evaluation of global attention in\natomistic graph learning and provide a reproducible testbed for future model\ndevelopment.",
      "authors": [
        "Arindam Chowdhury",
        "Massimiliano Lupo Pasini"
      ],
      "published": "2025-10-07T05:01:19Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05583v1",
      "primary_area": "multimodal_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "medical_ai",
      "tldr_zh": "本研究首次系统评估了全局注意力机制在原子图学习中的作用，提出了统一的可复现基准框架HydraGNN，通过七大数据集对比了四种模型架构。研究发现：编码器增强的MPNN构成稳健基线，而融合局部-全局的模型在长程相互作用主导的性质中表现最佳，同时量化了注意力机制的计算开销与内存占用。",
      "order": 137,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05583v1"
    },
    {
      "arxiv_id": "2510.05582v1",
      "title": "(Token-Level) \\textbf{InfoRMIA}: Stronger Membership Inference and\n  Memorization Assessment for LLMs",
      "summary": "Machine learning models are known to leak sensitive information, as they\ninevitably memorize (parts of) their training data. More alarmingly, large\nlanguage models (LLMs) are now trained on nearly all available data, which\namplifies the magnitude of information leakage and raises serious privacy\nrisks. Hence, it is more crucial than ever to quantify privacy risk before the\nrelease of LLMs. The standard method to quantify privacy is via membership\ninference attacks, where the state-of-the-art approach is the Robust Membership\nInference Attack (RMIA). In this paper, we present InfoRMIA, a principled\ninformation-theoretic formulation of membership inference. Our method\nconsistently outperforms RMIA across benchmarks while also offering improved\ncomputational efficiency.\n  In the second part of the paper, we identify the limitations of treating\nsequence-level membership inference as the gold standard for measuring leakage.\nWe propose a new perspective for studying membership and memorization in LLMs:\ntoken-level signals and analyses. We show that a simple token-based InfoRMIA\ncan pinpoint which tokens are memorized within generated outputs, thereby\nlocalizing leakage from the sequence level down to individual tokens, while\nachieving stronger sequence-level inference power on LLMs. This new scope\nrethinks privacy in LLMs and can lead to more targeted mitigation, such as\nexact unlearning.",
      "authors": [
        "Jiashu Tao",
        "Reza Shokri"
      ],
      "published": "2025-10-07T04:59:49Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05582v1",
      "primary_area": "text_models",
      "secondary_focus": "['alignment', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出InfoRMIA方法，基于信息论改进成员推理攻击，在LLM隐私风险评估中超越现有最佳方法RMIA。论文创新性地引入词元级分析，能精确定位生成文本中的记忆词元，从序列层面到词元层面定位信息泄露，为针对性隐私保护（如精确遗忘）提供新思路。",
      "order": 138,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05582v1"
    },
    {
      "arxiv_id": "2510.05581v1",
      "title": "Power Mechanism: Private Tabular Representation Release for Model\n  Agnostic Consumption",
      "summary": "Traditional collaborative learning approaches are based on sharing of model\nweights between clients and a server. However, there are advantages to resource\nefficiency through schemes based on sharing of embeddings (activations) created\nfrom the data. Several differentially private methods were developed for\nsharing of weights while such mechanisms do not exist so far for sharing of\nembeddings. We propose Ours to learn a privacy encoding network in conjunction\nwith a small utility generation network such that the final embeddings\ngenerated from it are equipped with formal differential privacy guarantees.\nThese privatized embeddings are then shared with a more powerful server, that\nlearns a post-processing that results in a higher accuracy for machine learning\ntasks. We show that our co-design of collaborative and private learning results\nin requiring only one round of privatized communication and lesser compute on\nthe client than traditional methods. The privatized embeddings that we share\nfrom the client are agnostic to the type of model (deep learning, random\nforests or XGBoost) used on the server in order to process these activations to\ncomplete a task.",
      "authors": [
        "Praneeth Vepakomma",
        "Kaustubh Ponkshe"
      ],
      "published": "2025-10-07T04:55:38Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05581v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种名为'Power Mechanism'的隐私保护方法，通过联合训练隐私编码网络和轻量级效用生成网络，为嵌入表示提供差分隐私保证。该方法只需单轮私有通信，客户端计算开销低于传统方案，且生成的私有嵌入可适配服务器端的任意模型类型（如深度学习、随机森林或XGBoost），实现模型无关的高精度机器学习任务。",
      "order": 139,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05581v1"
    },
    {
      "arxiv_id": "2510.05569v1",
      "title": "Efficient Learning-based Graph Simulation for Temporal Graphs",
      "summary": "Graph simulation has recently received a surge of attention in graph\nprocessing and analytics. In real-life applications, e.g. social science,\nbiology, and chemistry, many graphs are composed of a series of evolving graphs\n(i.e., temporal graphs). While most of the existing graph generators focus on\nstatic graphs, the temporal information of the graphs is ignored. In this\npaper, we focus on simulating temporal graphs, which aim to reproduce the\nstructural and temporal properties of the observed real-life temporal graphs.\nIn this paper, we first give an overview of the existing temporal graph\ngenerators, including recently emerged learning-based approaches. Most of these\nlearning-based methods suffer from one of the limitations: low efficiency in\ntraining or slow generating, especially for temporal random walk-based methods.\nTherefore, we propose an efficient learning-based approach to generate graph\nsnapshots, namely temporal graph autoencoder (TGAE). Specifically, we propose\nan attention-based graph encoder to encode temporal and structural\ncharacteristics on sampled ego-graphs. And we proposed an ego-graph decoder\nthat can achieve a good trade-off between simulation quality and efficiency in\ntemporal graph generation. Finally, the experimental evaluation is conducted\namong our proposed TGAE and representative temporal graph generators on\nreal-life temporal graphs and synthesized graphs. It is reported that our\nproposed approach outperforms the state-of-the-art temporal graph generators by\nmeans of simulation quality and efficiency.",
      "authors": [
        "Sheng Xiang",
        "Chenhao Xu",
        "Dawei Cheng",
        "Xiaoyang Wang",
        "Ying Zhang"
      ],
      "published": "2025-10-07T04:22:24Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05569v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "['model_architecture', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种高效的基于学习的时序图模拟方法TGAE，通过注意力图编码器和自我图解码器，在保持模拟质量的同时显著提升时序图生成的效率，在真实和合成数据集上均优于现有方法。",
      "order": 140,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05569v1"
    },
    {
      "arxiv_id": "2510.05562v1",
      "title": "Generative Dynamic Graph Representation Learning for Conspiracy Spoofing\n  Detection",
      "summary": "Spoofing detection in financial trading is crucial, especially for\nidentifying complex behaviors such as conspiracy spoofing. Traditional\nmachine-learning approaches primarily focus on isolated node features, often\noverlooking the broader context of interconnected nodes. Graph-based\ntechniques, particularly Graph Neural Networks (GNNs), have advanced the field\nby leveraging relational information effectively. However, in real-world\nspoofing detection datasets, trading behaviors exhibit dynamic, irregular\npatterns. Existing spoofing detection methods, though effective in some\nscenarios, struggle to capture the complexity of dynamic and diverse, evolving\ninter-node relationships. To address these challenges, we propose a novel\nframework called the Generative Dynamic Graph Model (GDGM), which models\ndynamic trading behaviors and the relationships among nodes to learn\nrepresentations for conspiracy spoofing detection. Specifically, our approach\nincorporates the generative dynamic latent space to capture the temporal\npatterns and evolving market conditions. Raw trading data is first converted\ninto time-stamped sequences. Then we model trading behaviors using the neural\nordinary differential equations and gated recurrent units, to generate the\nrepresentation incorporating temporal dynamics of spoofing patterns.\nFurthermore, pseudo-label generation and heterogeneous aggregation techniques\nare employed to gather relevant information and enhance the detection\nperformance for conspiratorial spoofing behaviors. Experiments conducted on\nspoofing detection datasets demonstrate that our approach outperforms\nstate-of-the-art models in detection accuracy. Additionally, our spoofing\ndetection system has been successfully deployed in one of the largest global\ntrading markets, further validating the practical applicability and performance\nof the proposed method.",
      "authors": [
        "Sheng Xiang",
        "Yidong Jiang",
        "Yunting Chen",
        "Dawei Cheng",
        "Guoping Zhao",
        "Changjun Jiang"
      ],
      "published": "2025-10-07T04:16:12Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05562v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "model_architecture",
      "application_domain": "financial_ai",
      "tldr_zh": "本文提出生成式动态图模型(GDGM)，通过神经微分方程和门控循环单元捕捉交易行为的时序动态特征，结合伪标签生成和异质聚合技术，在金融共谋欺骗检测中显著优于现有方法，并已在全球最大交易市场成功部署。",
      "order": 141,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05562v1"
    },
    {
      "arxiv_id": "2510.05554v1",
      "title": "Critical attention scaling in long-context transformers",
      "summary": "As large language models scale to longer contexts, attention layers suffer\nfrom a fundamental pathology: attention scores collapse toward uniformity as\ncontext length $n$ increases, causing tokens to cluster excessively, a\nphenomenon known as rank-collapse. While $\\textit{attention scaling}$\neffectively addresses this deficiency by rescaling attention scores with a\npolylogarithmic factor $\\beta_n$, theoretical justification for this approach\nremains lacking.\n  We analyze a simplified yet tractable model that magnifies the effect of\nattention scaling. In this model, attention exhibits a phase transition\ngoverned by the scaling factor $\\beta_n$: insufficient scaling collapses all\ntokens to a single direction, while excessive scaling reduces attention to\nidentity, thereby eliminating meaningful interactions between tokens. Our main\nresult identifies the critical scaling $\\beta_n \\asymp \\log n$ and provides a\nrigorous justification for attention scaling in YaRN and Qwen, clarifying why\nlogarithmic scaling maintains sparse, content-adaptive attention at large\ncontext lengths.",
      "authors": [
        "Shi Chen",
        "Zhengjiang Lin",
        "Yury Polyanskiy",
        "Philippe Rigollet"
      ],
      "published": "2025-10-07T03:51:57Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05554v1",
      "primary_area": "text_models",
      "secondary_focus": "['long_context', 'model_architecture']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文研究长上下文Transformer中的注意力缩放问题。当上下文长度增加时，注意力分数会趋于均匀化导致表征崩溃。通过理论分析发现注意力缩放存在相变现象：缩放不足会使所有token坍缩，过度缩放则使注意力退化为单位矩阵。研究确定了临界缩放因子β_n ∝ log n，为YaRN和Qwen等模型中的对数缩放提供了理论依据，证明其能在长上下文中保持稀疏且内容自适应的注意力机制。",
      "order": 142,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05554v1"
    },
    {
      "arxiv_id": "2510.05535v1",
      "title": "Permutation-Invariant Representation Learning for Robust and\n  Privacy-Preserving Feature Selection",
      "summary": "Feature selection eliminates redundancy among features to improve downstream\ntask performance while reducing computational overhead. Existing methods often\nstruggle to capture intricate feature interactions and adapt across diverse\napplication scenarios. Recent advances employ generative intelligence to\nalleviate these drawbacks. However, these methods remain constrained by\npermutation sensitivity in embedding and reliance on convexity assumptions in\ngradient-based search. To address these limitations, our initial work\nintroduces a novel framework that integrates permutation-invariant embedding\nwith policy-guided search. Although effective, it still left opportunities to\nadapt to realistic distributed scenarios. In practice, data across local\nclients is highly imbalanced, heterogeneous and constrained by strict privacy\nregulations, limiting direct sharing. These challenges highlight the need for a\nframework that can integrate feature selection knowledge across clients without\nexposing sensitive information. In this extended journal version, we advance\nthe framework from two perspectives: 1) developing a privacy-preserving\nknowledge fusion strategy to derive a unified representation space without\nsharing sensitive raw data. 2) incorporating a sample-aware weighting strategy\nto address distributional imbalance among heterogeneous local clients.\nExtensive experiments validate the effectiveness, robustness, and efficiency of\nour framework. The results further demonstrate its strong generalization\nability in federated learning scenarios. The code and data are publicly\navailable: https://anonymous.4open.science/r/FedCAPS-08BF.",
      "authors": [
        "Rui Liu",
        "Tao Zhe",
        "Yanjie Fu",
        "Feng Xia",
        "Ted Senator",
        "Dongjie Wang"
      ],
      "published": "2025-10-07T02:53:32Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05535v1",
      "primary_area": "model_architecture",
      "secondary_focus": "['training_optimization', 'model_compression']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出一种联邦学习场景下的隐私保护特征选择框架，通过置换不变表示学习和策略引导搜索，结合隐私保护知识融合与样本感知加权策略，有效处理数据异构性和分布不平衡问题，在保持隐私的同时提升特征选择性能。",
      "order": 143,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05535v1"
    },
    {
      "arxiv_id": "2510.05530v1",
      "title": "LATTA: Langevin-Anchored Test-Time Adaptation for Enhanced Robustness\n  and Stability",
      "summary": "Test-time adaptation (TTA) aims to adapt a pretrained model to distribution\nshifts using only unlabeled test data. While promising, existing methods like\nTent suffer from instability and can catastrophically forget the source\nknowledge, especially with small batch sizes or challenging corruptions. We\nargue that this arises from overly deterministic updates on a complex loss\nsurface. In this paper, we introduce Langevin-Anchored Test-Time Adaptation\n(LATTA), a novel approach that regularizes adaptation through two key\nmechanisms: (1) a noisy weight perturbation inspired by Stochastic Gradient\nLangevin Dynamics (SGLD) to explore the local parameter space and escape poor\nlocal minima, and (2) a stable weight anchor that prevents the model from\ndiverging from its robust source pre-training. This combination allows LATTA to\nadapt effectively without sacrificing stability. Unlike prior Bayesian TTA\nmethods, LATTA requires no architectural changes or expensive Monte Carlo\npasses. We conduct extensive experiments on standard benchmarks, including\nRotated-MNIST and the more challenging CIFAR-10-C. Our results demonstrate that\nLATTA significantly outperforms existing methods, including Tent, CoTTA, and\nEATA, setting a new state of the art for self-supervised TTA by improving\naverage accuracy on CIFAR-10-C by over 2% while simultaneously reducing\nperformance variance.",
      "authors": [
        "Harshil Vejendla"
      ],
      "published": "2025-10-07T02:39:39Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05530v1",
      "primary_area": "text_models",
      "secondary_focus": "training_optimization",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出LATTA方法，通过朗之万动力学噪声扰动和稳定权重锚点机制，解决测试时自适应中的不稳定性和灾难性遗忘问题。在CIFAR-10-C等基准测试中显著优于现有方法，准确率提升2%以上且性能更稳定。",
      "order": 144,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05530v1"
    },
    {
      "arxiv_id": "2510.05528v1",
      "title": "ARMOR: High-Performance Semi-Structured Pruning via Adaptive Matrix\n  Factorization",
      "summary": "Large language models (LLMs) present significant deployment challenges due to\ntheir immense computational and memory requirements. While semi-structured\npruning, particularly 2:4 sparsity, offers a path to practical hardware\nacceleration, existing methods often incur substantial performance degradation.\nTo bridge this gap, we introduce ARMOR: (Adaptive Representation with\nMatrix-factORization), a novel one-shot post-training pruning algorithm.\nInstead of directly pruning weights, ARMOR factorizes each weight matrix into a\n2:4 sparse core wrapped by two low-overhead, block diagonal matrices. These\nwrappers act as efficient pre and post-transformation error correctors,\noffering greater flexibility to preserve model quality compared to conventional\n2:4 pruning techniques. The sparse core and block diagonal wrappers are chosen\nthrough a block coordinate descent algorithm that minimizes a layer-wise proxy\nloss. We theoretically prove this optimization is guaranteed to converge to a\nsolution with a proxy loss less than or equal to state-of-the-art pruning\nalgorithms. Experiments on Llama (Touvron et al., 2023; Dubey et al., 2024) and\nQwen (Yang et al., 2025) model families demonstrate that ARMOR consistently and\nsignificantly outperforms state-of-the-art 2:4 pruning methods across a wide\nrange of downstream tasks and perplexity evaluations. ARMOR achieves this\nsuperior performance while retaining the inference speedups and substantial\nmemory usage reductions of 2:4 pruning, establishing a more effective trade-off\nbetween model compression and task accuracy",
      "authors": [
        "Lawrence Liu",
        "Alexander Liu",
        "Mengdi Wang",
        "Tuo Zhao",
        "Lin F. Yang"
      ],
      "published": "2025-10-07T02:39:20Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05528v1",
      "primary_area": "text_models",
      "secondary_focus": "model_compression",
      "application_domain": "general_purpose",
      "tldr_zh": "ARMOR提出了一种基于自适应矩阵分解的高性能半结构化剪枝方法，通过将权重矩阵分解为2:4稀疏核心和两个低开销块对角矩阵，在保持2:4剪枝推理加速和内存节省优势的同时，显著减少了模型性能损失。该方法在Llama和Qwen模型系列上验证了其优越性。",
      "order": 145,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05528v1"
    },
    {
      "arxiv_id": "2510.05527v1",
      "title": "Transfer Learning on Edge Connecting Probability Estimation under\n  Graphon Model",
      "summary": "Graphon models provide a flexible nonparametric framework for estimating\nlatent connectivity probabilities in networks, enabling a range of downstream\napplications such as link prediction and data augmentation. However, accurate\ngraphon estimation typically requires a large graph, whereas in practice, one\noften only observes a small-sized network. One approach to addressing this\nissue is to adopt a transfer learning framework, which aims to improve\nestimation in a small target graph by leveraging structural information from a\nlarger, related source graph. In this paper, we propose a novel method, namely\nGTRANS, a transfer learning framework that integrates neighborhood smoothing\nand Gromov-Wasserstein optimal transport to align and transfer structural\npatterns between graphs. To prevent negative transfer, GTRANS includes an\nadaptive debiasing mechanism that identifies and corrects for target-specific\ndeviations via residual smoothing. We provide theoretical guarantees on the\nstability of the estimated alignment matrix and demonstrate the effectiveness\nof GTRANS in improving the accuracy of target graph estimation through\nextensive synthetic and real data experiments. These improvements translate\ndirectly to enhanced performance in downstream applications, such as the graph\nclassification task and the link prediction task.",
      "authors": [
        "Yuyao Wang",
        "Yu-Hung Cheng",
        "Debarghya Mukherjee",
        "Huimin Cheng"
      ],
      "published": "2025-10-07T02:37:12Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05527v1",
      "primary_area": "model_architecture",
      "secondary_focus": "training_optimization",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出GTRANS迁移学习框架，通过邻域平滑和Gromov-Wasserstein最优传输在Graphon模型下实现图结构对齐与迁移，包含自适应去偏机制防止负迁移，理论证明对齐矩阵稳定性并在图分类和链接预测任务中验证有效性。",
      "order": 146,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05527v1"
    },
    {
      "arxiv_id": "2510.05526v1",
      "title": "Provably Mitigating Corruption, Overoptimization, and Verbosity\n  Simultaneously in Offline and Online RLHF/DPO Alignment",
      "summary": "Reinforcement learning from human feedback (RLHF) and direct preference\noptimization (DPO) are important techniques to align large language models\n(LLM) with human preference. However, the quality of RLHF and DPO training is\nseriously compromised by \\textit{\\textbf{C}orrupted} preference, reward\n\\textit{\\textbf{O}veroptimization}, and bias towards\n\\textit{\\textbf{V}erbosity}. To our knowledge, most existing works tackle only\none of these important issues, and the few other works require much computation\nto estimate multiple reward models and lack theoretical guarantee of\ngeneralization ability. In this work, we propose RLHF-\\textbf{COV} and\nDPO-\\textbf{COV} algorithms that can simultaneously mitigate these three\nissues, in both offline and online settings. This ability is theoretically\ndemonstrated by obtaining length-regularized generalization error rates for our\nDPO-COV algorithms trained on corrupted data, which match the best-known rates\nfor simpler cases with clean data and without length regularization. Moreover,\nour DPO-COV algorithm is simple to implement without reward estimation, and is\nproved to be equivalent to our RLHF-COV algorithm, which directly implies the\nequivalence between the vanilla RLHF and DPO algorithms. Experiments\ndemonstrate the effectiveness of our DPO-COV algorithms under both offline and\nonline settings.",
      "authors": [
        "Ziyi Chen",
        "Junyi Li",
        "Peiran Yu",
        "Heng Huang"
      ],
      "published": "2025-10-07T02:32:47Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05526v1",
      "primary_area": "text_models",
      "secondary_focus": "['alignment', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出RLHF-COV和DPO-COV算法，可同时解决RLHF/DPO对齐中的三大问题：偏好数据污染、奖励过优化和冗长性偏差。该算法在离线和在线场景下均有效，具备理论保证的泛化能力，且无需复杂奖励估计，实验验证了其优越性能。",
      "order": 147,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05526v1"
    },
    {
      "arxiv_id": "2510.05516v1",
      "title": "NeST-BO: Fast Local Bayesian Optimization via Newton-Step Targeting of\n  Gradient and Hessian Information",
      "summary": "Bayesian optimization (BO) is effective for expensive black-box problems but\nremains challenging in high dimensions. We propose NeST-BO, a local BO method\nthat targets the Newton step by jointly learning gradient and Hessian\ninformation with Gaussian process surrogates, and selecting evaluations via a\none-step lookahead bound on Newton-step error. We show that this bound (and\nhence the step error) contracts with batch size, so NeST-BO directly inherits\ninexact-Newton convergence: global progress under mild stability assumptions\nand quadratic local rates once steps are sufficiently accurate. To scale, we\noptimize the acquisition in low-dimensional subspaces (e.g., random embeddings\nor learned sparse subspaces), reducing the dominant cost of learning curvature\nfrom $O(d^2)$ to $O(m^2)$ with $m \\ll d$ while preserving step targeting.\nAcross high-dimensional synthetic and real-world problems, including cases with\nthousands of variables and unknown active subspaces, NeST-BO consistently\nyields faster convergence and lower regret than state-of-the-art local and\nhigh-dimensional BO baselines.",
      "authors": [
        "Wei-Ting Tang",
        "Akshay Kudva",
        "Joel A. Paulson"
      ],
      "published": "2025-10-07T02:09:00Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05516v1",
      "primary_area": "training_optimization",
      "secondary_focus": "model_architecture",
      "application_domain": "general_purpose",
      "tldr_zh": "NeST-BO是一种高效的局部贝叶斯优化方法，通过高斯过程代理模型联合学习梯度和海森矩阵信息，利用牛顿步误差的一步前瞻边界选择评估点。该方法在高维问题上展现出快速收敛和低遗憾特性，通过低维子空间优化将计算成本从O(d²)降至O(m²)，在包含数千变量的合成和真实问题中均优于现有方法。",
      "order": 148,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05516v1"
    },
    {
      "arxiv_id": "2510.05511v1",
      "title": "EEG-Based Acute Pain Classification: Machine Learning Model Comparison\n  and Real-Time Clinical Feasibility",
      "summary": "Current pain assessment within hospitals often relies on self-reporting or\nnon-specific EKG vital signs. This system leaves critically ill, sedated, and\ncognitively impaired patients vulnerable to undertreated pain and opioid\noveruse. Electroencephalography (EEG) offers a noninvasive method of measuring\nbrain activity. This technology could potentially be applied as an assistive\ntool to highlight nociceptive processing in order to mitigate this issue. In\nthis study, we compared machine learning models for classifying high-pain\nversus low/no-pain EEG epochs using data from fifty-two healthy adults exposed\nto laser-evoked pain at three intensities (low, medium, high). Each four-second\nepoch was transformed into a 537-feature vector spanning spectral power, band\nratios, Hjorth parameters, entropy measures, coherence, wavelet energies, and\npeak-frequency metrics. Nine traditional machine learning models were evaluated\nwith leave-one-participant-out cross-validation. A support vector machine with\nradial basis function kernel achieved the best offline performance with 88.9%\naccuracy and sub-millisecond inference time (1.02 ms). Our Feature importance\nanalysis was consistent with current canonical pain physiology, showing\ncontralateral alpha suppression, midline theta/alpha enhancement, and frontal\ngamma bursts. The real-time XGBoost model maintained an end-to-end latency of\nabout 4 ms and 94.2% accuracy, demonstrating that an EEG-based pain monitor is\ntechnically feasible within a clinical setting and provides a pathway towards\nclinical validation.",
      "authors": [
        "Aavid Mathrawala",
        "Dhruv Kurup",
        "Josie Lau"
      ],
      "published": "2025-10-07T01:57:36Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05511v1",
      "primary_area": "audio_models",
      "secondary_focus": "model_compression",
      "application_domain": "medical_ai",
      "tldr_zh": "本研究比较了九种机器学习模型在脑电图(EEG)疼痛分类中的表现，通过52名健康成人的激光诱发疼痛实验数据，开发出能实时监测疼痛的EEG系统。支持向量机模型在离线测试中达到88.9%准确率，XGBoost实时模型延迟仅4毫秒且准确率达94.2%，为临床疼痛监测提供了可行方案。特征分析结果与疼痛生理机制一致，展示了EEG技术在解决危重患者疼痛评估难题中的应用潜力。",
      "order": 149,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05511v1"
    },
    {
      "arxiv_id": "2510.05494v1",
      "title": "Fundamental Limits of Crystalline Equivariant Graph Neural Networks: A\n  Circuit Complexity Perspective",
      "summary": "Graph neural networks (GNNs) have become a core paradigm for learning on\nrelational data. In materials science, equivariant GNNs (EGNNs) have emerged as\na compelling backbone for crystalline-structure prediction, owing to their\nability to respect Euclidean symmetries and periodic boundary conditions.\nDespite strong empirical performance, their expressive power in periodic,\nsymmetry-constrained settings remains poorly understood. This work\ncharacterizes the intrinsic computational and expressive limits of EGNNs for\ncrystalline-structure prediction through a circuit-complexity lens. We analyze\nthe computations carried out by EGNN layers acting on node features, atomic\ncoordinates, and lattice matrices, and prove that, under polynomial precision,\nembedding width $d=O(n)$ for $n$ nodes, $O(1)$ layers, and $O(1)$-depth,\n$O(n)$-width MLP instantiations of the message/update/readout maps, these\nmodels admit a simulation by a uniform $\\mathsf{TC}^0$ threshold-circuit family\nof polynomial size (with an explicit constant-depth bound). Situating EGNNs\nwithin $\\mathsf{TC}^0$ provides a concrete ceiling on the decision and\nprediction problems solvable by such architectures under realistic resource\nconstraints and clarifies which architectural modifications (e.g., increased\ndepth, richer geometric primitives, or wider layers) are required to transcend\nthis regime. The analysis complements Weisfeiler-Lehman style results that do\nnot directly transfer to periodic crystals, and offers a complexity-theoretic\nfoundation for symmetry-aware graph learning on crystalline systems.",
      "authors": [
        "Yang Cao",
        "Zhao Song",
        "Jiahao Zhang",
        "Jiale Zhao"
      ],
      "published": "2025-10-07T01:24:15Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05494v1",
      "primary_area": "model_architecture",
      "secondary_focus": "reasoning",
      "application_domain": "general_purpose",
      "tldr_zh": "本文从电路复杂度角度分析了晶体等变图神经网络(EGNN)的表达能力极限，证明在多项式精度和特定参数约束下，EGNN可被恒定深度的阈值电路族模拟，属于TC^0复杂度类。研究为周期性晶体系统的对称感知图学习提供了复杂性理论基础，并指出了突破现有计算能力限制所需的架构改进方向。",
      "order": 150,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05494v1"
    },
    {
      "arxiv_id": "2510.05492v1",
      "title": "High-Fidelity Synthetic ECG Generation via Mel-Spectrogram Informed\n  Diffusion Training",
      "summary": "The development of machine learning for cardiac care is severely hampered by\nprivacy restrictions on sharing real patient electrocardiogram (ECG) data.\nAlthough generative AI offers a promising solution, the real-world use of\nexisting model-synthesized ECGs is limited by persistent gaps in\ntrustworthiness and clinical utility. In this work, we address two major\nshortcomings of current generative ECG methods: insufficient morphological\nfidelity and the inability to generate personalized, patient-specific\nphysiological signals. To address these gaps, we build on a conditional\ndiffusion-based Structured State Space Model (SSSD-ECG) with two principled\ninnovations: (1) MIDT-ECG (Mel-Spectrogram Informed Diffusion Training), a\nnovel training paradigm with time-frequency domain supervision to enforce\nphysiological structural realism, and (2) multi-modal demographic conditioning\nto enable patient-specific synthesis. We comprehensively evaluate our approach\non the PTB-XL dataset, assessing the synthesized ECG signals on fidelity,\nclinical coherence, privacy preservation, and downstream task utility. MIDT-ECG\nachieves substantial gains: it improves morphological coherence, preserves\nstrong privacy guarantees with all metrics evaluated exceeding the baseline by\n4-8%, and notably reduces the interlead correlation error by an average of 74%,\nwhile demographic conditioning enhances signal-to-noise ratio and\npersonalization. In critical low-data regimes, a classifier trained on datasets\nsupplemented with our synthetic ECGs achieves performance comparable to a\nclassifier trained solely on real data. Together, we demonstrate that ECG\nsynthesizers, trained with the proposed time-frequency structural\nregularization scheme, can serve as personalized, high-fidelity,\nprivacy-preserving surrogates when real data are scarce, advancing the\nresponsible use of generative AI in healthcare.",
      "authors": [
        "Zhuoyi Huang",
        "Nutan Sahoo",
        "Anamika Kumari",
        "Girish Kumar",
        "Kexuan Cai",
        "Shixing Cao",
        "Yue Kang",
        "Tian Xia",
        "Somya Chatterjee",
        "Nicholas Hausman",
        "Aidan Jay",
        "Eric S. Rosenthal",
        "Soundar Srinivasan",
        "Sadid Hasan",
        "Alex Fedorov",
        "Sulaiman Vesal",
        "Soundar Srinivasan",
        "Sadid Hasan",
        "Alex Fedorov",
        "Sulaiman Vesal"
      ],
      "published": "2025-10-07T01:14:53Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05492v1",
      "primary_area": "diffusion_models",
      "secondary_focus": "['training_optimization', 'model_architecture']",
      "application_domain": "medical_ai",
      "tldr_zh": "本文提出MIDT-ECG方法，通过梅尔频谱引导的扩散训练生成高保真合成心电图。该方法结合时频域监督和人口统计条件化，显著提升心电信号的形态保真度和个性化生成能力，在PTB-XL数据集上验证了其在隐私保护、临床效用和下游任务中的优越性能。",
      "order": 151,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05492v1"
    },
    {
      "arxiv_id": "2510.05491v1",
      "title": "NorMuon: Making Muon more efficient and scalable",
      "summary": "The choice of optimizer significantly impacts the training efficiency and\ncomputational costs of large language models (LLMs). Recently, the Muon\noptimizer has demonstrated promising results by orthogonalizing parameter\nupdates, improving optimization geometry through better conditioning. Despite\nMuon's emergence as a candidate successor to Adam, the potential for jointly\nleveraging their strengths has not been systematically explored. In this work,\nwe bridge this gap by proposing NorMuon (Neuron-wise Normalized Muon), an\noptimizer that synergistically combines orthogonalization with neuron-level\nadaptive learning rates. Our analysis reveals that while Muon effectively\nreduces condition numbers, the resulting updates exhibit highly non-uniform\nneuron norms, causing certain neurons to dominate the optimization process.\nNorMuon addresses this imbalance by maintaining second-order momentum\nstatistics for each neuron and applying row-wise normalization after\northogonalization, ensuring balanced parameter utilization while preserving\nMuon's conditioning benefits. To enable practical deployment at scale, we\ndevelop an efficient distributed implementation under the FSDP2 framework that\nstrategically distributes orthogonalization computations across devices.\nExperiments across multiple model scales demonstrate that NorMuon consistently\noutperforms both Adam and Muon, achieving 21.74% better training efficiency\nthan Adam and 11.31% improvement over Muon on 1.1 B pretraining setting, while\nmaintaining a comparable memory footprint to Muon. Our findings suggest that\northogonalization and adaptive learning rates are complementary rather than\ncompeting approaches, opening new avenues for optimizer design in large-scale\ndeep learning.",
      "authors": [
        "Zichong Li",
        "Liming Liu",
        "Chen Liang",
        "Weizhu Chen",
        "Tuo Zhao"
      ],
      "published": "2025-10-07T01:13:41Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05491v1",
      "primary_area": "text_models",
      "secondary_focus": "training_optimization",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出NorMuon优化器，通过将正交化更新与神经元级自适应学习率相结合，解决了Muon优化器中神经元更新范数不均衡的问题。在FSDP2框架下实现高效分布式部署，实验表明在1.1B参数预训练中，相比Adam和Muon分别提升21.74%和11.31%的训练效率，且内存占用与Muon相当。",
      "order": 152,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05491v1"
    },
    {
      "arxiv_id": "2510.05489v1",
      "title": "The Method of Infinite Descent",
      "summary": "Training - the optimisation of complex models - is traditionally performed\nthrough small, local, iterative updates [D. E. Rumelhart, G. E. Hinton, R. J.\nWilliams, Nature 323, 533-536 (1986)]. Approximating solutions through\ntruncated gradients is a paradigm dating back to Cauchy [A.-L. Cauchy, Comptes\nRendus Math\\'ematique 25, 536-538 (1847)] and Newton [I. Newton, The Method of\nFluxions and Infinite Series (Henry Woodfall, London, 1736)]. This work\nintroduces the Method of Infinite Descent, a semi-analytic optimisation\nparadigm that reformulates training as the direct solution to the first-order\noptimality condition. By analytical resummation of its Taylor expansion, this\nmethod yields an exact, algebraic equation for the update step. Realisation of\nthe infinite Taylor tower's cascading resummation is formally derived, and an\nexploitative algorithm for the direct solve step is proposed.\n  This principle is demonstrated with the herein-introduced AION (Analytic,\nInfinitely-Optimisable Network) architecture. AION is a model designed\nexpressly to satisfy the algebraic closure required by Infinite Descent. In a\nsimple test problem, AION reaches the optimum in a single descent step.\nTogether, this optimiser-model pair exemplify how analytic structure enables\nexact, non-iterative convergence. Infinite Descent extends beyond this example,\napplying to any appropriately closed architecture. This suggests a new class of\nsemi-analytically optimisable models: the \\emph{Infinity Class}; sufficient\nconditions for class membership are discussed. This offers a pathway toward\nnon-iterative learning.",
      "authors": [
        "Reza T. Batley",
        "Sourav Saha"
      ],
      "published": "2025-10-07T01:09:20Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05489v1",
      "primary_area": "model_architecture",
      "secondary_focus": "training_optimization",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出'无限下降法'——一种半解析优化范式，将模型训练重新表述为直接求解一阶最优性条件。通过泰勒展开的解析重求和，该方法得到精确的代数更新方程。配合专门设计的AION架构，在简单测试问题中仅需单步下降即可达到最优解，展示了非迭代收敛的潜力，并定义了'无限类'模型的新概念。",
      "order": 153,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05489v1"
    },
    {
      "arxiv_id": "2510.05482v1",
      "title": "ATOM: A Pretrained Neural Operator for Multitask Molecular Dynamics",
      "summary": "Molecular dynamics (MD) simulations underpin modern computational drug dis-\ncovery, materials science, and biochemistry. Recent machine learning models\nprovide high-fidelity MD predictions without the need to repeatedly solve\nquantum mechanical forces, enabling significant speedups over conventional\npipelines. Yet many such methods typically enforce strict equivariance and rely\non sequential rollouts, thus limiting their flexibility and simulation\nefficiency. They are also com- monly single-task, trained on individual\nmolecules and fixed timeframes, which restricts generalization to unseen\ncompounds and extended timesteps. To address these issues, we propose Atomistic\nTransformer Operator for Molecules (ATOM), a pretrained transformer neural\noperator for multitask molecular dynamics. ATOM adopts a quasi-equivariant\ndesign that requires no explicit molecular graph and employs a temporal\nattention mechanism, allowing for the accurate parallel decod- ing of multiple\nfuture states. To support operator pretraining across chemicals and timescales,\nwe curate TG80, a large, diverse, and numerically stable MD dataset with over\n2.5 million femtoseconds of trajectories across 80 compounds. ATOM achieves\nstate-of-the-art performance on established single-task benchmarks, such as\nMD17, RMD17 and MD22. After multitask pretraining on TG80, ATOM shows\nexceptional zero-shot generalization to unseen molecules across varying time\nhori- zons. We believe ATOM represents a significant step toward accurate,\nefficient, and transferable molecular dynamics models",
      "authors": [
        "Luke Thompson",
        "Davy Guan",
        "Dai Shi",
        "Slade Matthews",
        "Junbin Gao",
        "Andi Han"
      ],
      "published": "2025-10-07T00:56:39Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05482v1",
      "primary_area": "model_architecture",
      "secondary_focus": "['training_optimization', 'reasoning']",
      "application_domain": "medical_ai",
      "tldr_zh": "本文提出ATOM，一种用于多任务分子动力学的预训练Transformer神经算子。该模型采用准等变设计，无需显式分子图，通过时间注意力机制实现多未来状态的并行解码。在包含80种化合物、250万飞秒轨迹的TG80数据集上预训练后，ATOM在MD17等基准测试中达到SOTA，并在未见分子上展现出卓越的零样本泛化能力，为计算药物发现和材料科学提供了更准确高效的分子动力学模型。",
      "order": 154,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05482v1"
    },
    {
      "arxiv_id": "2510.05468v1",
      "title": "AMAQ: Adaptive Mixed-bit Activation Quantization for Collaborative\n  Parameter Efficient Fine-tuning",
      "summary": "Large Language Models (LLMs) are scaling rapidly, creating significant\nchallenges for collaborative server client distributed training, particularly\nin terms of communication efficiency and computational overheads. To address\nthese challenges, we implement Parameter-efficient Split Learning, which\neffectively balances efficiency and performance for collaborative training on\nlow-resource devices.\n  To reduce communication overhead in collaborative training, we introduce\nAdaptive Mixed bit Activation Quantization (AMAQ), a strategy that\nprogressively compresses activations and gradients from high precision (6 to 8\nbits) to low precision (3 to 4 bits). AMAQ achieves this by effectively\nallocating bit budgets across channels based on feature wise and layer wise\nimportance using bit regularization.\n  Under the same bit budgets, AMAQ outperforms fixed-precision approaches,\ndelivering about 2.5% higher generation accuracy and about 1.3% better\nclassification accuracy for models like LLaMA3 8B and Qwen2.5 7B. In addition,\nit significantly enhances training stability and reducing ultra-low bit\nrepresentation collapse during the training.\n  Experiments demonstrate that AMAQ integrates effectively into practical\nmulti-machine collaborative training setups, offering superior inference\naccuracy with only a modest communication overhead for bits adaptation during\ntraining. This trade off makes AMAQ a practical and effective solution for\ncollaborative training with minimal communication cost.",
      "authors": [
        "Yurun Song",
        "Zhuoyi Yang",
        "Ian G. Harris",
        "Sangeetha Abdu Jyothi"
      ],
      "published": "2025-10-07T00:05:16Z",
      "primary_category": "cs.LG",
      "arxiv_url": "https://arxiv.org/abs/2510.05468v1",
      "primary_area": "text_models",
      "secondary_focus": "['model_compression', 'training_optimization']",
      "application_domain": "general_purpose",
      "tldr_zh": "本文提出AMAQ自适应混合位激活量化方法，通过动态调整激活值和梯度的量化精度（6-8位到3-4位），在协作式参数高效微调中显著降低通信开销。相比固定精度方法，在相同比特预算下，LLaMA3 8B和Qwen2.5 7B模型生成准确率提升约2.5%，分类准确率提升约1.3%，同时增强训练稳定性并避免超低位表示崩溃。",
      "order": 155,
      "papers_cool_url": "https://papers.cool/arxiv/2510.05468v1"
    }
  ],
  "archive_files": [
    "data\\paper_database\\text-models\\reasoning-model-architecture-training-optimization\\financial-ai\\2510-06217v1.json",
    "data\\paper_database\\text-models\\reasoning\\general-purpose\\2510-06189v1.json",
    "data\\paper_database\\text-models\\reasoning\\general-purpose\\2510-06135v1.json",
    "data\\paper_database\\text-models\\alignment\\general-purpose\\2510-06105v1.json",
    "data\\paper_database\\text-models\\alignment-reasoning\\medical-ai\\2510-06093v1.json",
    "data\\paper_database\\text-models\\reasoning-model-architecture\\general-purpose\\2510-06078v1.json",
    "data\\paper_database\\text-models\\reasoning-model-architecture\\general-purpose\\2510-06198v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture-training-optimization\\general-purpose\\2510-06195v1.json",
    "data\\paper_database\\audio-models\\dialogue-systems-model-architecture\\general-purpose\\2510-06188v1.json",
    "data\\paper_database\\text-models\\reasoning\\code-generation\\2510-06186v1.json",
    "data\\paper_database\\text-models\\reasoning-model-architecture\\general-purpose\\2510-06182v1.json",
    "data\\paper_database\\text-models\\model-compression-long-context-reasoning\\general-purpose\\2510-06175v1.json",
    "data\\paper_database\\text-models\\training-optimization\\general-purpose\\2510-06143v1.json",
    "data\\paper_database\\diffusion-models\\model-architecture-training-optimization\\general-purpose\\2510-06133v1.json",
    "data\\paper_database\\text-models\\model-architecture\\general-purpose\\2510-06128v1.json",
    "data\\paper_database\\text-models\\model-architecture-reasoning\\general-purpose\\2510-06107v1.json",
    "data\\paper_database\\text-models\\model-compression-reasoning-training-optimization\\code-generation\\2510-06101v1.json",
    "data\\paper_database\\text-models\\alignment-training-optimization\\general-purpose\\2510-06084v1.json",
    "data\\paper_database\\text-models\\training-optimization-reasoning\\code-generation-general-purpose\\2510-06062v1.json",
    "data\\paper_database\\text-models\\training-optimization-reasoning\\general-purpose\\2510-06039v1.json",
    "data\\paper_database\\text-models\\reasoning\\general-purpose\\2510-06018v1.json",
    "data\\paper_database\\text-models\\model-architecture-training-optimization\\general-purpose\\2510-06005v1.json",
    "data\\paper_database\\text-models\\reasoning\\general-purpose\\2510-06001v1.json",
    "data\\paper_database\\text-models\\reasoning\\general-purpose\\2510-05972v1.json",
    "data\\paper_database\\text-models\\reasoning\\education-ai\\2510-05969v1.json",
    "data\\paper_database\\text-models\\alignment-reasoning\\general-purpose\\2510-05942v1.json",
    "data\\paper_database\\text-models\\alignment\\general-purpose\\2510-05931v1.json",
    "data\\paper_database\\text-models\\dialogue-systems-reasoning\\general-purpose\\2510-05921v1.json",
    "data\\paper_database\\text-models\\alignment\\general-purpose\\2510-05869v1.json",
    "data\\paper_database\\text-models\\long-context-alignment\\general-purpose\\2510-05864v1.json",
    "data\\paper_database\\text-models\\long-context-training-optimization\\general-purpose\\2510-05862v1.json",
    "data\\paper_database\\text-models\\alignment\\legal-ai\\2510-05860v1.json",
    "data\\paper_database\\text-models\\training-optimization-dialogue-systems\\general-purpose\\2510-05858v1.json",
    "data\\paper_database\\text-models\\training-optimization-model-compression\\general-purpose\\2510-05846v1.json",
    "data\\paper_database\\text-models\\training-optimization-reasoning\\general-purpose\\2510-05837v1.json",
    "data\\paper_database\\audio-models\\training-optimization-alignment\\general-purpose\\2510-05799v1.json",
    "data\\paper_database\\text-models\\model-architecture-model-compression\\general-purpose\\2510-05781v1.json",
    "data\\paper_database\\text-models\\model-architecture\\general-purpose\\2510-05769v1.json",
    "data\\paper_database\\text-models\\training-optimization\\general-purpose\\2510-05767v1.json",
    "data\\paper_database\\text-models\\reasoning\\general-purpose\\2510-05744v1.json",
    "data\\paper_database\\text-models\\training-optimization-model-architecture\\general-purpose\\2510-05691v1.json",
    "data\\paper_database\\text-models\\reasoning-model-architecture\\general-purpose\\2510-05678v1.json",
    "data\\paper_database\\text-models-audio-models\\training-optimization\\general-purpose\\2510-05644v1.json",
    "data\\paper_database\\multimodal-models\\reasoning-model-architecture\\general-purpose\\2510-05611v1.json",
    "data\\paper_database\\text-models\\training-optimization-reasoning\\general-purpose\\2510-05608v1.json",
    "data\\paper_database\\text-models\\reasoning-model-architecture\\general-purpose\\2510-05577v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture\\education-ai\\2510-05571v1.json",
    "data\\paper_database\\multimodal-models\\model-compression\\general-purpose\\2510-05544v1.json",
    "data\\paper_database\\text-models\\alignment-training-optimization\\general-purpose\\2510-05534v1.json",
    "data\\paper_database\\text-models\\model-compression-long-context\\general-purpose\\2510-05529v1.json",
    "data\\paper_database\\text-models\\reasoning-model-architecture\\general-purpose\\2510-05524v1.json",
    "data\\paper_database\\text-models\\long-context-model-architecture\\general-purpose\\2510-05520v1.json",
    "data\\paper_database\\text-models\\reasoning-model-architecture\\general-purpose\\2510-05498v1.json",
    "data\\paper_database\\text-models\\model-compression-dialogue-systems\\general-purpose\\2510-05490v1.json",
    "data\\paper_database\\text-models\\reasoning\\general-purpose\\2510-05486v1.json",
    "data\\paper_database\\text-models\\training-optimization\\general-purpose\\2510-05485v1.json",
    "data\\paper_database\\video-models\\model-architecture-training-optimization\\general-purpose\\2510-06219v1.json",
    "data\\paper_database\\multimodal-models\\reasoning-model-architecture\\general-purpose\\2510-06218v1.json",
    "data\\paper_database\\vla-models\\model-architecture\\general-purpose\\2510-06216v1.json",
    "data\\paper_database\\diffusion-models\\model-architecture\\general-purpose\\2510-06215v1.json",
    "data\\paper_database\\video-models\\model-architecture-training-optimization\\general-purpose\\2510-06209v1.json",
    "data\\paper_database\\video-models\\model-architecture\\general-purpose\\2510-06208v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture-training-optimization\\general-purpose\\2510-06145v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture-video-models\\general-purpose\\2510-06139v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture-diffusion-models\\medical-ai\\2510-06131v1.json",
    "data\\paper_database\\diffusion-models\\training-optimization-model-architecture\\medical-ai\\2510-06123v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture\\medical-ai\\2510-06113v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture-training-optimization\\general-purpose\\2510-06098v1.json",
    "data\\paper_database\\multimodal-models\\tech-reports\\medical-ai\\2510-06090v1.json",
    "data\\paper_database\\video-models\\reasoning-model-architecture\\general-purpose\\2510-06077v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture\\general-purpose\\2510-06070v1.json",
    "data\\paper_database\\multimodal-models\\reasoning\\general-purpose\\2510-06067v1.json",
    "data\\paper_database\\vla-models\\model-architecture\\medical-ai\\2510-06064v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture-training-optimization\\general-purpose\\2510-06046v1.json",
    "data\\paper_database\\video-models\\model-architecture-reasoning-long-context\\general-purpose\\2510-06040v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture-training-optimization\\general-purpose\\2510-06035v1.json",
    "data\\paper_database\\video-models\\alignment\\legal-ai\\2510-06026v1.json",
    "data\\paper_database\\multimodal-models\\training-optimization-model-architecture\\general-purpose\\2510-06009v1.json",
    "data\\paper_database\\text-models\\training-optimization\\general-purpose\\2510-06214v1.json",
    "data\\paper_database\\text-models\\model-compression-training-optimization\\general-purpose\\2510-06213v1.json",
    "data\\paper_database\\vla-models\\model-architecture\\general-purpose\\2510-06203v1.json",
    "data\\paper_database\\diffusion-models\\model-architecture-reasoning\\general-purpose-code-generation\\2510-06190v1.json",
    "data\\paper_database\\model-architecture\\training-optimization-reasoning\\general-purpose\\2510-06181v1.json",
    "data\\paper_database\\diffusion-models\\model-architecture\\general-purpose\\2510-06174v1.json",
    "data\\paper_database\\text-models\\model-architecture\\general-purpose\\2510-06165v1.json",
    "data\\paper_database\\text-models\\training-optimization-model-architecture\\medical-ai\\2510-06162v1.json",
    "data\\paper_database\\text-models\\reasoning\\general-purpose\\2510-06151v1.json",
    "data\\paper_database\\training-optimization\\model-architecture\\general-purpose\\2510-06141v1.json",
    "data\\paper_database\\vla-models\\model-architecture-training-optimization\\general-purpose\\2510-06138v1.json",
    "data\\paper_database\\text-models\\model-compression-training-optimization\\general-purpose\\2510-06126v1.json",
    "data\\paper_database\\text-models\\model-compression-alignment\\general-purpose\\2510-06125v1.json",
    "data\\paper_database\\diffusion-models\\model-architecture\\general-purpose\\2510-06122v1.json",
    "data\\paper_database\\text-models\\reasoning-training-optimization\\general-purpose\\2510-06108v1.json",
    "data\\paper_database\\model-architecture\\reasoning-training-optimization\\general-purpose\\2510-06106v1.json",
    "data\\paper_database\\text-models\\alignment\\general-purpose\\2510-06096v1.json",
    "data\\paper_database\\text-models\\alignment-training-optimization\\general-purpose\\2510-06092v1.json",
    "data\\paper_database\\model-architecture\\training-optimization\\medical-ai\\2510-06091v1.json",
    "data\\paper_database\\multimodal-models\\reasoning\\financial-ai\\2510-06071v1.json",
    "data\\paper_database\\text-models\\model-architecture-training-optimization\\general-purpose\\2510-06066v1.json",
    "data\\paper_database\\diffusion-models\\model-architecture\\general-purpose\\2510-06050v1.json",
    "data\\paper_database\\text-models\\training-optimization\\general-purpose\\2510-06048v1.json",
    "data\\paper_database\\vla-models\\training-optimization-alignment\\general-purpose\\2510-06038v1.json",
    "data\\paper_database\\text-models\\training-optimization\\medical-ai\\2510-06029v1.json",
    "data\\paper_database\\training-optimization\\model-architecture\\general-purpose\\2510-06028v1.json",
    "data\\paper_database\\text-models\\model-architecture\\general-purpose\\2510-06025v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture-training-optimization\\medical-ai\\2510-06020v1.json",
    "data\\paper_database\\text-models\\model-architecture-training-optimization\\general-purpose\\2510-06007v1.json",
    "data\\paper_database\\text-models\\reasoning\\general-purpose\\2510-05987v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture-training-optimization\\general-purpose\\2510-05949v1.json",
    "data\\paper_database\\text-models\\model-architecture-reasoning\\general-purpose\\2510-05935v1.json",
    "data\\paper_database\\diffusion-models\\model-architecture-training-optimization\\medical-ai-general-purpose\\2510-05930v1.json",
    "data\\paper_database\\audio-models\\model-architecture\\medical-ai\\2510-05919v1.json",
    "data\\paper_database\\text-models\\model-architecture-training-optimization\\general-purpose\\2510-05901v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture\\general-purpose\\2510-05879v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture-training-optimization\\general-purpose\\2510-05874v1.json",
    "data\\paper_database\\text-models\\model-architecture\\general-purpose\\2510-05856v1.json",
    "data\\paper_database\\diffusion-models\\model-architecture\\medical-ai\\2510-05849v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture-training-optimization\\general-purpose\\2510-05840v1.json",
    "data\\paper_database\\text-models\\reasoning\\general-purpose\\2510-05825v1.json",
    "data\\paper_database\\training-optimization\\model-compression\\medical-ai\\2510-05805v1.json",
    "data\\paper_database\\diffusion-models\\model-architecture\\medical-ai\\2510-05777v1.json",
    "data\\paper_database\\text-models\\training-optimization\\medical-ai\\2510-05753v1.json",
    "data\\paper_database\\text-models\\model-architecture-reasoning\\general-purpose\\2510-05750v1.json",
    "data\\paper_database\\text-models\\alignment-reasoning\\general-purpose\\2510-05748v1.json",
    "data\\paper_database\\diffusion-models\\model-architecture\\general-purpose\\2510-05725v1.json",
    "data\\paper_database\\model-architecture\\training-optimization\\general-purpose\\2510-05719v1.json",
    "data\\paper_database\\diffusion-models\\model-architecture-training-optimization\\general-purpose\\2510-05717v1.json",
    "data\\paper_database\\text-models\\alignment-training-optimization\\general-purpose\\2510-05703v1.json",
    "data\\paper_database\\text-models\\model-architecture-model-compression\\general-purpose\\2510-05688v1.json",
    "data\\paper_database\\model-architecture\\reasoning\\general-purpose\\2510-05683v1.json",
    "data\\paper_database\\text-models\\model-architecture\\financial-ai\\2510-05676v1.json",
    "data\\paper_database\\text-models\\model-architecture-alignment\\general-purpose\\2510-05670v1.json",
    "data\\paper_database\\vla-models\\model-architecture-training-optimization\\general-purpose\\2510-05635v1.json",
    "data\\paper_database\\model-architecture\\reasoning\\general-purpose\\2510-05620v1.json",
    "data\\paper_database\\training-optimization\\model-architecture\\general-purpose\\2510-05606v1.json",
    "data\\paper_database\\text-models\\model-architecture-training-optimization\\general-purpose\\2510-05589v1.json",
    "data\\paper_database\\multimodal-models\\model-architecture-training-optimization\\medical-ai\\2510-05583v1.json",
    "data\\paper_database\\text-models\\alignment-training-optimization\\general-purpose\\2510-05582v1.json",
    "data\\paper_database\\text-models\\model-architecture-training-optimization\\general-purpose\\2510-05581v1.json",
    "data\\paper_database\\diffusion-models\\model-architecture-training-optimization\\general-purpose\\2510-05569v1.json",
    "data\\paper_database\\diffusion-models\\model-architecture\\financial-ai\\2510-05562v1.json",
    "data\\paper_database\\text-models\\long-context-model-architecture\\general-purpose\\2510-05554v1.json",
    "data\\paper_database\\model-architecture\\training-optimization-model-compression\\general-purpose\\2510-05535v1.json",
    "data\\paper_database\\text-models\\training-optimization\\general-purpose\\2510-05530v1.json",
    "data\\paper_database\\text-models\\model-compression\\general-purpose\\2510-05528v1.json",
    "data\\paper_database\\model-architecture\\training-optimization\\general-purpose\\2510-05527v1.json",
    "data\\paper_database\\text-models\\alignment-training-optimization\\general-purpose\\2510-05526v1.json",
    "data\\paper_database\\training-optimization\\model-architecture\\general-purpose\\2510-05516v1.json",
    "data\\paper_database\\audio-models\\model-compression\\medical-ai\\2510-05511v1.json",
    "data\\paper_database\\model-architecture\\reasoning\\general-purpose\\2510-05494v1.json",
    "data\\paper_database\\diffusion-models\\training-optimization-model-architecture\\medical-ai\\2510-05492v1.json",
    "data\\paper_database\\text-models\\training-optimization\\general-purpose\\2510-05491v1.json",
    "data\\paper_database\\model-architecture\\training-optimization\\general-purpose\\2510-05489v1.json",
    "data\\paper_database\\model-architecture\\training-optimization-reasoning\\medical-ai\\2510-05482v1.json",
    "data\\paper_database\\text-models\\model-compression-training-optimization\\general-purpose\\2510-05468v1.json"
  ]
}