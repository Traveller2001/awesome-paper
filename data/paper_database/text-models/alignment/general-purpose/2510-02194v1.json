{
  "arxiv_id": "2510.02194v1",
  "title": "UpSafe$^\\circ$C: Upcycling for Controllable Safety in Large Language\n  Models",
  "summary": "Large Language Models (LLMs) have achieved remarkable progress across a wide\nrange of tasks, but remain vulnerable to safety risks such as harmful content\ngeneration and jailbreak attacks. Existing safety techniques -- including\nexternal guardrails, inference-time guidance, and post-training alignment --\neach face limitations in balancing safety, utility, and controllability. In\nthis work, we propose UpSafe$^\\circ$C, a unified framework for enhancing LLM\nsafety through safety-aware upcycling. Our approach first identifies\nsafety-critical layers and upcycles them into a sparse Mixture-of-Experts (MoE)\nstructure, where the router acts as a soft guardrail that selectively activates\noriginal MLPs and added safety experts. We further introduce a two-stage SFT\nstrategy to strengthen safety discrimination while preserving general\ncapabilities. To enable flexible control at inference time, we introduce a\nsafety temperature mechanism, allowing dynamic adjustment of the trade-off\nbetween safety and utility. Experiments across multiple benchmarks, base model,\nand model scales demonstrate that UpSafe$^\\circ$C achieves robust safety\nimprovements against harmful and jailbreak inputs, while maintaining\ncompetitive performance on general tasks. Moreover, analysis shows that safety\ntemperature provides fine-grained inference-time control that achieves the\nPareto-optimal frontier between utility and safety. Our results highlight a new\ndirection for LLM safety: moving from static alignment toward dynamic, modular,\nand inference-aware control.",
  "authors": [
    "Yuhao Sun",
    "Zhuoer Xu",
    "Shiwen Cui",
    "Kun Yang",
    "Lingyun Yu",
    "Yongdong Zhang",
    "Hongtao Xie"
  ],
  "published": "2025-10-02T16:43:33Z",
  "primary_category": "cs.AI",
  "arxiv_url": "https://arxiv.org/abs/2510.02194v1",
  "primary_area": "text_models",
  "secondary_focus": "alignment",
  "application_domain": "general_purpose",
  "tldr_zh": "UpSafe°C提出了一种通过安全感知升级增强大语言模型安全性的统一框架。该方法识别安全关键层并将其升级为稀疏混合专家结构，引入安全温度机制实现推理时安全性与实用性的动态权衡控制，在保持通用能力的同时显著提升对有害内容和越狱攻击的防御能力。",
  "order": 727,
  "papers_cool_url": "https://papers.cool/arxiv/2510.02194v1"
}