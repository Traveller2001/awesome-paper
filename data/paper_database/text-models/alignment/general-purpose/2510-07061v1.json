{
  "arxiv_id": "2510.07061v1",
  "title": "Revisiting Metric Reliability for Fine-grained Evaluation of Machine\n  Translation and Summarization in Indian Languages",
  "summary": "While automatic metrics drive progress in Machine Translation (MT) and Text\nSummarization (TS), existing metrics have been developed and validated almost\nexclusively for English and other high-resource languages. This narrow focus\nleaves Indian languages, spoken by over 1.5 billion people, largely overlooked,\ncasting doubt on the universality of current evaluation practices. To address\nthis gap, we introduce ITEM, a large-scale benchmark that systematically\nevaluates the alignment of 26 automatic metrics with human judgments across six\nmajor Indian languages, enriched with fine-grained annotations. Our extensive\nevaluation, covering agreement with human judgments, sensitivity to outliers,\nlanguage-specific reliability, inter-metric correlations, and resilience to\ncontrolled perturbations, reveals four central findings: (1) LLM-based\nevaluators show the strongest alignment with human judgments at both segment\nand system levels; (2) outliers exert a significant impact on metric-human\nagreement; (3) in TS, metrics are more effective at capturing content fidelity,\nwhereas in MT, they better reflect fluency; and (4) metrics differ in their\nrobustness and sensitivity when subjected to diverse perturbations.\nCollectively, these findings offer critical guidance for advancing metric\ndesign and evaluation in Indian languages.",
  "authors": [
    "Amir Hossein Yari",
    "Kalmit Kulkarni",
    "Ahmad Raza Khan",
    "Fajri Koto"
  ],
  "published": "2025-10-08T14:27:02Z",
  "primary_category": "cs.CL",
  "arxiv_url": "https://arxiv.org/abs/2510.07061v1",
  "primary_area": "text_models",
  "secondary_focus": "alignment",
  "application_domain": "general_purpose",
  "tldr_zh": "本研究针对印度语言机器翻译与文本摘要评估，构建了ITEM大规模基准测试，系统评估了26种自动指标与人工标注的一致性。关键发现包括：基于大语言模型的评估器与人类判断最契合、异常值显著影响指标可靠性、不同任务中指标侧重不同（摘要重内容忠实度，翻译重流畅度），为印度语言评估指标设计提供了重要指导。",
  "order": 56,
  "papers_cool_url": "https://papers.cool/arxiv/2510.07061v1"
}