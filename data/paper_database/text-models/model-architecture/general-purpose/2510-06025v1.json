{
  "arxiv_id": "2510.06025v1",
  "title": "Out-of-Distribution Detection from Small Training Sets using Bayesian\n  Neural Network Classifiers",
  "summary": "Out-of-Distribution (OOD) detection is critical to AI reliability and safety,\nyet in many practical settings, only a limited amount of training data is\navailable. Bayesian Neural Networks (BNNs) are a promising class of model on\nwhich to base OOD detection, because they explicitly represent epistemic (i.e.\nmodel) uncertainty. In the small training data regime, BNNs are especially\nvaluable because they can incorporate prior model information. We introduce a\nnew family of Bayesian posthoc OOD scores based on expected logit vectors, and\ncompare 5 Bayesian and 4 deterministic posthoc OOD scores. Experiments on MNIST\nand CIFAR-10 In-Distributions, with 5000 training samples or less, show that\nthe Bayesian methods outperform corresponding deterministic methods.",
  "authors": [
    "Kevin Raina",
    "Tanya Schmah"
  ],
  "published": "2025-10-07T15:23:05Z",
  "primary_category": "cs.LG",
  "arxiv_url": "https://arxiv.org/abs/2510.06025v1",
  "primary_area": "text_models",
  "secondary_focus": "model_architecture",
  "application_domain": "general_purpose",
  "tldr_zh": "本文提出一种基于贝叶斯神经网络的小样本分布外检测方法，通过期望logit向量构建新型检测评分，在MNIST和CIFAR-10数据集上验证显示，贝叶斯方法在训练样本不足5000时显著优于确定性方法。",
  "order": 105,
  "papers_cool_url": "https://papers.cool/arxiv/2510.06025v1"
}