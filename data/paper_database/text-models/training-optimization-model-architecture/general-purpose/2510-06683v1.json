{
  "arxiv_id": "2510.06683v1",
  "title": "Distributed Algorithms for Multi-Agent Multi-Armed Bandits with\n  Collision",
  "summary": "We study the stochastic Multiplayer Multi-Armed Bandit (MMAB) problem, where\nmultiple players select arms to maximize their cumulative rewards. Collisions\noccur when two or more players select the same arm, resulting in no reward, and\nare observed by the players involved. We consider a distributed setting without\ncentral coordination, where each player can only observe their own actions and\ncollision feedback. We propose a distributed algorithm with an adaptive,\nefficient communication protocol. The algorithm achieves near-optimal group and\nindividual regret, with a communication cost of only $\\mathcal{O}(\\log\\log T)$.\nOur experiments demonstrate significant performance improvements over existing\nbaselines. Compared to state-of-the-art (SOTA) methods, our approach achieves a\nnotable reduction in individual regret. Finally, we extend our approach to a\nperiodic asynchronous setting, proving the lower bound for this problem and\npresenting an algorithm that achieves logarithmic regret.",
  "authors": [
    "Daoyuan Zhou",
    "Xuchuang Wang",
    "Lin Yang",
    "Yang Gao"
  ],
  "published": "2025-10-08T06:12:59Z",
  "primary_category": "cs.LG",
  "arxiv_url": "https://arxiv.org/abs/2510.06683v1",
  "primary_area": "text_models",
  "secondary_focus": "['training_optimization', 'model_architecture']",
  "application_domain": "general_purpose",
  "tldr_zh": "æœ¬æ–‡ç ”ç©¶åˆ†å¸ƒå¼å¤šæ™ºèƒ½ä½“å¤šè‡‚è€è™æœºé—®é¢˜ï¼Œæå‡ºä¸€ç§å…·æœ‰è‡ªé€‚åº”é«˜æ•ˆé€šä¿¡åè®®çš„åˆ†å¸ƒå¼ç®—æ³•ã€‚è¯¥ç®—æ³•åœ¨æ— ä¸­å¿ƒåè°ƒç¯å¢ƒä¸‹ï¼Œä»…éœ€ğ’ª(log log T)é€šä¿¡æˆæœ¬å³å¯å®ç°æ¥è¿‘æœ€ä¼˜çš„ç¾¤ä½“ä¸ä¸ªä½“é—æ†¾ï¼Œå®éªŒæ˜¾ç¤ºå…¶æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶æ‰©å±•è‡³å‘¨æœŸæ€§å¼‚æ­¥åœºæ™¯ã€‚",
  "order": 220,
  "papers_cool_url": "https://papers.cool/arxiv/2510.06683v1"
}