{
  "arxiv_id": "2510.01051v1",
  "title": "GEM: A Gym for Agentic LLMs",
  "summary": "The training paradigm for large language models (LLMs) is moving from static\ndatasets to experience-based learning, where agents acquire skills via\ninteracting with complex environments. To facilitate this transition we\nintroduce GEM (General Experience Maker), an open-source environment simulator\ndesigned for the age of LLMs. Analogous to OpenAI-Gym for traditional\nreinforcement learning (RL), GEM provides a standardized framework for the\nenvironment-agent interface, including asynchronous vectorized execution for\nhigh throughput, and flexible wrappers for easy extensibility. GEM also\nfeatures a diverse suite of environments, robust integrated tools, and\nsingle-file example scripts demonstrating using GEM with five popular RL\ntraining frameworks. Along with this, we also provide a set of baselines across\n24 environments using REINFORCE with Return Batch Normalization (ReBN), which\n-- unlike GRPO -- is compatible with the full RL setting of dense per-turn\nrewards and offers better credit assignment. We further conduct apple-to-apple\nbenchmarking of PPO, GRPO and REINFORCE in both single- and multi-turn settings\nusing GEM to shed light on the algorithmic designs. Lastly, GEM also functions\nas a convenient evaluation toolkit besides a training environment. We hope this\nframework can help accelerate future agentic LLM research.",
  "authors": [
    "Zichen Liu",
    "Anya Sims",
    "Keyu Duan",
    "Changyu Chen",
    "Simon Yu",
    "Xiangxin Zhou",
    "Haotian Xu",
    "Shaopan Xiong",
    "Bo Liu",
    "Chenmien Tan",
    "Chuen Yang Beh",
    "Weixun Wang",
    "Hao Zhu",
    "Weiyan Shi",
    "Diyi Yang",
    "Michael Shieh",
    "Yee Whye Teh",
    "Wee Sun Lee",
    "Min Lin"
  ],
  "published": "2025-10-01T15:55:57Z",
  "primary_category": "cs.LG",
  "arxiv_url": "https://arxiv.org/abs/2510.01051v1",
  "primary_area": "text_models",
  "secondary_focus": "training_optimization",
  "application_domain": "general_purpose",
  "tldr_zh": "GEM是一个专为大型语言模型设计的开源环境模拟器，类似于传统强化学习中的OpenAI-Gym。它提供标准化的环境-代理接口、异步向量化执行、多样化环境套件和集成工具，支持与五种主流RL训练框架集成。论文还通过基准测试比较了PPO、GRPO和REINFORCE算法在不同设置下的性能，旨在加速未来智能LLM代理的研究发展。",
  "order": 430,
  "papers_cool_url": "https://papers.cool/arxiv/2510.01051v1"
}