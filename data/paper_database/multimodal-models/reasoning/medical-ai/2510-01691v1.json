{
  "arxiv_id": "2510.01691v1",
  "title": "MedQ-Bench: Evaluating and Exploring Medical Image Quality Assessment\n  Abilities in MLLMs",
  "summary": "Medical Image Quality Assessment (IQA) serves as the first-mile safety gate\nfor clinical AI, yet existing approaches remain constrained by scalar,\nscore-based metrics and fail to reflect the descriptive, human-like reasoning\nprocess central to expert evaluation. To address this gap, we introduce\nMedQ-Bench, a comprehensive benchmark that establishes a perception-reasoning\nparadigm for language-based evaluation of medical image quality with\nMulti-modal Large Language Models (MLLMs). MedQ-Bench defines two complementary\ntasks: (1) MedQ-Perception, which probes low-level perceptual capability via\nhuman-curated questions on fundamental visual attributes; and (2)\nMedQ-Reasoning, encompassing both no-reference and comparison reasoning tasks,\naligning model evaluation with human-like reasoning on image quality. The\nbenchmark spans five imaging modalities and over forty quality attributes,\ntotaling 2,600 perceptual queries and 708 reasoning assessments, covering\ndiverse image sources including authentic clinical acquisitions, images with\nsimulated degradations via physics-based reconstructions, and AI-generated\nimages. To evaluate reasoning ability, we propose a multi-dimensional judging\nprotocol that assesses model outputs along four complementary axes. We further\nconduct rigorous human-AI alignment validation by comparing LLM-based judgement\nwith radiologists. Our evaluation of 14 state-of-the-art MLLMs demonstrates\nthat models exhibit preliminary but unstable perceptual and reasoning skills,\nwith insufficient accuracy for reliable clinical use. These findings highlight\nthe need for targeted optimization of MLLMs in medical IQA. We hope that\nMedQ-Bench will catalyze further exploration and unlock the untapped potential\nof MLLMs for medical image quality evaluation.",
  "authors": [
    "Jiyao Liu",
    "Jinjie Wei",
    "Wanying Qu",
    "Chenglong Ma",
    "Junzhi Ning",
    "Yunheng Li",
    "Ying Chen",
    "Xinzhe Luo",
    "Pengcheng Chen",
    "Xin Gao",
    "Ming Hu",
    "Huihui Xu",
    "Xin Wang",
    "Shujian Gao",
    "Dingkang Yang",
    "Zhongying Deng",
    "Jin Ye",
    "Lihao Liu",
    "Junjun He",
    "Ningsheng Xu"
  ],
  "published": "2025-10-02T05:42:00Z",
  "primary_category": "cs.CV",
  "arxiv_url": "https://arxiv.org/abs/2510.01691v1",
  "primary_area": "multimodal_models",
  "secondary_focus": "reasoning",
  "application_domain": "medical_ai",
  "tldr_zh": "MedQ-Bench是首个针对多模态大语言模型的医学图像质量评估基准，包含感知和推理两大任务，涵盖5种成像模态和40多个质量属性。评估显示现有模型具备初步但不稳定的医学图像质量评估能力，尚无法满足临床可靠性要求，需进一步优化。",
  "order": 551,
  "papers_cool_url": "https://papers.cool/arxiv/2510.01691v1"
}