{
  "arxiv_id": "2510.01004v1",
  "title": "TextCAM: Explaining Class Activation Map with Text",
  "summary": "Deep neural networks (DNNs) have achieved remarkable success across domains\nbut remain difficult to interpret, limiting their trustworthiness in\nhigh-stakes applications. This paper focuses on deep vision models, for which a\ndominant line of explainability methods are Class Activation Mapping (CAM) and\nits variants working by highlighting spatial regions that drive predictions. We\nfigure out that CAM provides little semantic insight into what attributes\nunderlie these activations. To address this limitation, we propose TextCAM, a\nnovel explanation framework that enriches CAM with natural languages. TextCAM\ncombines the precise spatial localization of CAM with the semantic alignment of\nvision-language models (VLMs). Specifically, we derive channel-level semantic\nrepresentations using CLIP embeddings and linear discriminant analysis, and\naggregate them with CAM weights to produce textual descriptions of salient\nvisual evidence. This yields explanations that jointly specify where the model\nattends and what visual attributes likely support its decision. We further\nextend TextCAM to generate feature channels into semantically coherent groups,\nenabling more fine-grained visual-textual explanations. Experiments on\nImageNet, CLEVR, and CUB demonstrate that TextCAM produces faithful and\ninterpretable rationales that improve human understanding, detect spurious\ncorrelations, and preserve model fidelity.",
  "authors": [
    "Qiming Zhao",
    "Xingjian Li",
    "Xiaoyu Cao",
    "Xiaolong Wu",
    "Min Xu"
  ],
  "published": "2025-10-01T15:11:14Z",
  "primary_category": "cs.CV",
  "arxiv_url": "https://arxiv.org/abs/2510.01004v1",
  "primary_area": "multimodal_models",
  "secondary_focus": "reasoning",
  "application_domain": "general_purpose",
  "tldr_zh": "TextCAM是一种新颖的可解释性框架，通过将传统类激活图(CAM)与视觉语言模型结合，生成包含空间定位和语义描述的解释。该方法利用CLIP嵌入和线性判别分析获取通道级语义表示，与CAM权重聚合产生文本描述，在ImageNet等数据集上验证了其能提供忠实可理解的决策依据，检测虚假相关性并保持模型保真度。",
  "order": 608,
  "papers_cool_url": "https://papers.cool/arxiv/2510.01004v1"
}